#!/usr/bin/env bash
# shellcheck disable=SC2001
# shellcheck disable=SC2120
# shellcheck disable=SC2155
# set -x

# Bin aliases
alias manssh='docker run -t --rm -v ~/.ssh/config:/root/.ssh/config "jtz-reg/jtz/manssh"'

# === Docs / Reusable Selection Lists ===
docs() {
	if [[ -d "$DOCS_DIR" ]]; then
		(
			cd "$DOCS_DIR" || return
			"$EDITOR" .
		)
	else
		open  "https://docs.joshuatz.com/"
	fi
}

fuzzy_preview() {
	local search_dir="$1"
	local search_pattern="$2"

	if ! [[ -d "$search_dir" ]]; then
		return 1
	fi

	local RG_ARGS=(
		"$search_dir"
		"--glob"
		'!**/node_modules/'
	)

	results=$(rg --files-with-matches -e "$search_pattern" "${RG_ARGS[@]}")

	if [[ -z "$ONLY_CONTENT" ]]; then
		# Check filenames too
		local filename_results=$(rg --files --glob "$search_pattern" "${RG_ARGS[@]}")
		if [[ -z "$results" ]]; then
			results="$filename_results"
		elif [[ -n "$filename_results" ]]; then
			results="$results\n$filename_results"
		fi
	fi

	if [[ -z "$results" ]]; then
		return 1
	fi

	# Display results with FZF, with a fancy preview pane
	echo "$results" | fzf --reverse --preview-window=wrap --preview "rg --with-filename --line-number --context=10 --no-heading --column --color=always --smart-case -e $search_pattern {}"
}

docs_fuzzy() {
	if ! [[ -d "$DOCS_DIR" ]]; then
		echo "DOCS_DIR is unset!"
		return 1
	fi
	fuzzy_preview "$DOCS_DIR" "$@"
}

SIGNALS_PICK_LIST=$(cat << "EOF"
9	KILL	(non-catchable, non-ignorable kill)
---	---	---
1	HUP	(hang up)
2	INT	(interrupt)
3	QUIT	(quit)
6	ABRT	(abort)
9	KILL	(non-catchable, non-ignorable kill)
14	ALRM	(alarm clock)
15	TERM	(software termination signal)
EOF
)

docs_signals() {
	echo "$SIGNALS_PICK_LIST"
}

# === Styling ===
# For ANSI, this is a helpful guide - https://gist.github.com/fnky/458719343aabd01cfb17a3a4f7296797
# However, `tput` seems to be generally preferred over ANSI escape sequences now

# A style reset can take many different forms:
# \033[0m = reset _all_ attributes
# \e[0m = Reset all attributes
# \e[39m = Reset text color
# \e[49m = Reset background color
if (which tput >/dev/null) && [[ -n $TERM ]]; then
	TERM_STYLE_RESET="$(tput sgr0)"
fi

colorize_text() {
	local hex_code=$1
	local text=$2
	echo -e "\e[38;2;${hex_code}m${text}\e[0m"
}

# === /Styling ===

get_shell_type() {
	# Make sure bash check comes first, to reduce issues when using subshells
	if [[ -n "$BASH_VERSION" ]] || echo $SHELL | grep --silent -E "\/bash$"; then
		echo "BASH"
	elif [[ -n "$ZSH_VERSION" ]] || echo $SHELL | grep --silent -E "\/zsh$"; then
		echo "ZSH"
		return
	fi
}
SHELL_TYPE=$(get_shell_type)

# You can use this to parse version strings and then use the resulting number for comparison
# Example:
#     if [[ $(parse_version_string $(git --version | grep -E -o "\d+\.\d+.\d+$")) -ge $(parse_version_string "2.39.0") ]]
# https://stackoverflow.com/a/37939589/11447682
function parse_version_string { echo "$@" | awk -F. '{ printf("%d%03d%03d%03d\n", $1,$2,$3,$4); }'; }

parse_version_string_extra() {
	parse_version_string "$(echo $1 | sed -E 's/^([0-9]+(\.[0-9]+)*)[^0-9]*.*/\1/')"
}


ARRAY_INDEX_START=0
if [[ "$SHELL_TYPE" == "ZSH" ]]; then
	# cmon y'all, can't we just agree on things for once?
	ARRAY_INDEX_START=1
	ZSH_VERSION_NUM=$ZSH_VERSION
elif [[ "$SHELL_TYPE" == "BASH" ]]; then
	BASH_VERSION_NUM=$(parse_version_string "$BASH_VERSION")
fi

# Useful for splitting with non-printable char, etc.
UNIT_SEPARATOR_CHAR=$'\x1F'

IS_MAC=0
if [[ "$OSTYPE" == "darwin"* ]]; then
	IS_MAC=1
fi
IS_WAYLAND=0
if [[ $IS_MAC -ne 1 ]] && (loginctl show-session "$(loginctl | grep $(whoami) | awk '{print $1}')" -p Type | grep -q wayland); then
	IS_WAYLAND=1
fi

# Expand ~
expand_path() {
	local INPUT_PATH=$1
	if [[ -z "$INPUT_PATH" ]]; then
		echo "ERROR: No path provided"
		return 1
	fi
	INPUT_PATH="${INPUT_PATH/#\~/$HOME}"
	echo "$INPUT_PATH"
}

resolve_symlink() {
	if [[ $IS_MAC -eq 1 ]]; then
		greadlink -f "$1"
		return
	fi
	readlink -f "$1"
}
alias symlink_resolve="resolve_symlink"

resolve_alias() {
	local ALIAS="$1"
	shift
	if (check_args_for_value "--all" "$*"); then
		type -a "$ALIAS"
		return 0
	fi
	# The last line should be something like `${final_entry_name} is ${bin_path}`
	local final_alias_path=$(type -a "$ALIAS" | tail -n 1 | sed -rn 's#^.+ is (.+)$#\1#p')
	# The final entry could still be a symlink (which is actually very likely with applications,
	# like on mac, `/usr/local/bin/code` is a symlink to the VS Code installed bin,
	# under the normal applications folder
	if (check_args_for_value "--no-follow" "$*"); then
		echo "$final_alias_path"
		return 0
	fi
	symlink_resolve "$final_alias_path"
}
alias alias_resolve="resolve_alias"

# Not perfect across all OSes, but a "good enough" approach for most
get_computer_name() {
	if (which scutil > /dev/null); then
		scutil --get ComputerName
		return 0
	fi
	uname -n | sed -e 's/\.local$//'
}

pretty_path() {
	echo "$PATH" | tr ':' '\n'
}

augment_path() {
	local extra_path=$1
	shift
	local cmd=$*
	(
		PATH="$extra_path:$PATH"
		$SHELL -c "$cmd"
	)
}

# Make sure that you call with "$@", not "$*"
check_args_for_value() {
	local search_value="$1"
	shift
	for arg in "$@"; do
		# Note: -x is to force exact whole-line match
		if (echo "$arg" | grep -qx -- "$search_value"); then
			return 0
		fi
	done
	return 1
}

# TODO / WARNING: Both `get_var_value` and `set_var_value` are
# portable in their inner implementation, but overall
# non-portable because the syntax is checked before
# actual execution.
# If you try to source this file right now in bash, it
# will throw an expansion error on the zsh-specific lines
#
# I think an optimal solution here might be to make `.functions` agnostic
# and then have separate `.functions__zsh` and `.functions__bash`
# (or some naming schema along those lines) for shell-specific
# implementations)

# A way to get the value from a dynamic variable name
# I.e., dereference from pointer to variable held as string name
# https://mywiki.wooledge.org/BashFAQ/006#Indirection
# https://stackoverflow.com/q/16553089/11447682
get_var_value() {
	local VAR_NAME="$1"
	if [[ "$SHELL_TYPE" == "ZSH" ]]; then
		# shellcheck disable=SC2296
		echo "${(P)VAR_NAME}"
	elif [[ "$SHELL_TYPE" == "BASH" ]]; then
		echo "${!VAR_NAME}"
	else
		echo "Not sure how to handle $SHELL_TYPE"
		exit 1
	fi
}

# https://mywiki.wooledge.org/BashFAQ/006#Indirection
# https://stackoverflow.com/q/16553089/11447682
set_var_value() {
	local VAR_NAME="$1"
	local VAR_VALUE=$2
	if [[ "$SHELL_TYPE" == "ZSH" ]]; then
		# shellcheck disable=SC2296
		# shellcheck disable=SC2086
		: ${(P)VAR_NAME::=$VAR_VALUE}
	elif [[ "$SHELL_TYPE" == "BASH" ]]; then
		if [[ $BASH_VERSION_NUM -gt $(parse_version_string "4.2") ]]; then
			declare -g "${VAR_NAME}=$VAR_VALUE"
		elif [[ $BASH_VERSION_NUM -gt $(parse_version_string "3.1") ]]; then
			printf -v "$VAR_NAME" %s "$VAR_VALUE"
		else
			declare -- "${VAR_NAME}=$VAR_VALUE"
		fi
	else
		echo "Not sure how to handle $SHELL_TYPE"
		exit 1
	fi
}

debug_separator_ifs() {
	IFS_CHARS=$(printf '%s' "$IFS" | cat -e | head -n 1)
	echo "$IFS_CHARS"
}

trim_whitespace() {
	echo "$1" | awk 'NF{$1=$1;print}'
}

# RegEx replacer, using Node's RegExp implementation
# Example:
# regex_replace $'Item A\nItem B 2\nItem C' "/Item A\n.*\d/gim" "Items A & B"
# > Items A & B
#   Item C
regex_replace() {
	ORIGINAL_STRING="$1" PATTERN="$2" REPLACEMENT="$3" node <<-"EOF"
		function strToRegExp(strPattern){
			// Test for "/{pattern}/{flags}" input
			const regLikePatt = /^\/(.*)\/([igmuy]{0,5})$/;
			if (regLikePatt.test(strPattern)){
				const pattern = regLikePatt.exec(strPattern)[1];
				const flags = regLikePatt.exec(strPattern)[2];
				return new RegExp(pattern,flags);
			}
			else {
				return new RegExp(strPattern);
			}
		}
		const originalStr = process.env.ORIGINAL_STRING;
		const pattern = process.env.PATTERN;
		const replacement = process.env.REPLACEMENT || '';
		console.log(originalStr.replace(strToRegExp(pattern), replacement));
	EOF
}

remove_first_line() {
	echo "$1" | sed -r '1d;'
}

remove_last_line() {
	echo "$1" | sed -r '$d'
}

remove_first_and_last_line() {
	echo "$1" | sed -r '1d;$d'
}

reload() {
	if [[ $SHELL_TYPE == "ZSH" ]]; then
		# Note: Don't use source ~/.zshrc
		# See: https://github.com/ohmyzsh/ohmyzsh/wiki/FAQ#how-do-i-reload-the-zshrc-file
		exec zsh
	elif [[ $SHELL_TYPE == "BASH" ]]; then
		source ~/.bash_profile
	else
		echo "Not sure how to reload this shell"
	fi
}

alert() {
	msg="$1"
	# Hello? Is anyone home? It's me, your terminal.
	echo -e "\a"
	if [[ -n "$msg" ]]; then
		if (is_in_tmux); then
			tmux display-message "$1"
			return 0
		fi
		# TODO: Add styling
		echo "$1"
	fi
}

get_clipboard_contents() {
	if (which pbpaste > /dev/null); then
		pbpaste
	elif (which xclip > /dev/null); then
		xclip -selection clipboard -o
	elif (which wl-paste > /dev/null); then
		wl-paste
	else
		echo "ERROR: Could not find a clipboard utility"
	fi
}

get_clipboard_html() {
	if [[ $IS_MAC -ne 1 ]]; then
		# TODO: Linux support
		return 1
	fi

	# https://stackoverflow.com/a/24132171/11447682
	# The Perl part of this is to convert the hex string to a readable string
	osascript -e 'the clipboard as «class HTML»' | perl -ne 'print chr foreach unpack("C*",pack("H*",substr($_,11,-3)))'
}

_copy_to_clipboard() {
	if (which pbcopy > /dev/null); then
		pbcopy
	elif (which xclip > /dev/null); then
		xclip -selection clipboard
	elif (which wl-copy > /dev/null); then
		wl-copy
	else
		echo "ERROR: Could not find a clipboard utility"
	fi
}

# shellcheck disable=SC2120
copy_to_clipboard() {
	if [[ -n "$1" ]]; then
		# Suppress trailing line break while piping
		echo -n "$1" | _copy_to_clipboard
	else
		_copy_to_clipboard
	fi
}

# This only overwrites clipboard content if the selection is NOT empty
# It always return 0, so that it can be conveniently used with places
# that expect a copy command to always work
copy_to_clipboard_if_not_empty() {
	text="$1"
	# make sure to remove both space AND trailing line breaks
	if [[ -z $(trim_whitespace "$1") ]]; then
		alert "Empty Selection"
		return 0
	fi
	echo "$text" | copy_to_clipboard
	alert "Copied to clipboard"
}

copy_html_to_clipboard() {
	html="$1"
	plaintext="$2"
	# Fallback to HTML as plaintext if not set
	if [[ -z "$plaintext" ]]; then
		plaintext="$html"
	fi
	if [[ $IS_MAC -eq 1 ]]; then
		# If HTML is not prefixed with meta charset tag, add it
		if [[ -z "$NO_WRAP" ]] && (! echo "$html" | grep -q -E "^<meta charset"); then
			html="<meta charset=\"utf-8\">${html}"
		fi

		# https://stackoverflow.com/a/11089226/11447682
		# https://aaron.cc/copying-the-current-safari-tab-as-a-to-the-clipboard-as-a-clickable-link/
		html_hex=$(echo -n "$html" | hexdump -ve '1/1 "%.2x"')
		if [[ -n "$NO_PLAIN" ]]; then
			osascript <<- EOF
				set the clipboard to «data HTML${html_hex}»
			EOF
			return
		fi
		# Need to escape any inner double-quotes inside `plaintext` string, since
		# we are using`string:"${plaintext}"` as wrapper, or else this will error out.
		# E.g.: 6216:6226: syntax error: Expected “,” or “}” but found identifier. (-2741)
		local plaintext_escaped=$(echo "$plaintext" | sed 's/"/\\"/g')
		if ! (osascript <<- EOF
			set the clipboard to {«class HTML»:«data HTML${html_hex}», string:"${plaintext_escaped}"}
		EOF
		); then
			echo "AppleScript failed to set HTML"
			return 1
		fi
	else
		echo "$html" | xclip -selection clipboard -t text/html
	fi
}

copy_tab_to_clipboard() {
	printf "\t" | copy_to_clipboard
}

copy_last_command_to_clipboard() {
	last_command=$(fc -ln -1)
	echo "$last_command" | copy_to_clipboard
}

markdown_to_html() {
	local md="$1"
	if (which pandoc > /dev/null); then
		echo "$md" | pandoc -f gfm -t html
		return
	else
		npx marked --gfm -s "$md"
		return
	fi
}

html_to_markdown() {
	local html="$1"
	echo "$html" | pandoc --from html --to gfm
}

markdown_to_html_clipboard() {
	local md="$1"
	# If no arg, grab from clipboard
	if [[ -z "$md" ]]; then
		md="$(get_clipboard_contents)"
	fi
	html=$(markdown_to_html "$md")
	copy_html_to_clipboard "$html" "$md"
	echo "✅ HTML copied to clipboard"
}

clipboard_md_to_html() {
	markdown_to_html_clipboard "$(get_clipboard_contents)"
}
alias convert_clipboard_md_to_html="clipboard_md_to_html"

clipboard_to_plaintext() {
	# Takes the clipboard contents and converts it to plaintext, in-place
	text=$(get_clipboard_contents)
	echo "$text" | copy_to_clipboard
}
alias convert_clipboard_to_plaintext="clipboard_to_plaintext"

clipboard_html_to_md() {
	html=$(get_clipboard_html)
	echo "$html" | pandoc --from html --to gfm | copy_to_clipboard
}
alias convert_clipboard_html_to_md="clipboard_html_to_md"

spreadsheet_to_markdown() {
	local filepath="$1"
	filepath=$filepath python << "EOF"
import os
import sys
import csv

filepath = os.environ.get("filepath")
if not filepath:
	print("❌ No filepath provided")
	sys.exit(1)

delimiter = '\t' if filepath.endswith('.tsv') else ','

try:
	with open(filepath, 'r') as file:
		reader = csv.reader(file, delimiter=delimiter)
		rows = list(reader)
except Exception as e:
	print(f"❌ Error reading file: {e}")
	sys.exit(1)

if not rows:
	print("❌ No content to convert")
	sys.exit(1)

headers = rows[0]
markdown_table = [
	f"| {' | '.join(headers)} |",
	f"| {' | '.join(['---'] * len(headers))} |",
	*[f"| {' | '.join(row)} |" for row in rows[1:]]
]
markdown_table_str = '\n'.join(markdown_table)

print(markdown_table_str)
EOF
}

spreadsheet_to_json() {
	SPREADSHEET_FILE_PATH="$1" python << "EOF"
import json
import os
import string
import sys
import csv

filepath = os.environ.get("SPREADSHEET_FILE_PATH")
if not filepath:
	print("❌ No filepath provided")
	sys.exit(1)

delimiter = '\t' if filepath.endswith('.tsv') else ','

try:
	with open(filepath, 'r') as file:
		reader = csv.reader(file, delimiter=delimiter)
		rows = list(reader)
except Exception as e:
	print(f"❌ Error reading file: {e}")
	sys.exit(1)

if not rows:
	print("❌ No content to convert")
	sys.exit(1)

headers = [v.strip() for v in rows[0]]
# Strip non-printable
headers = list(map(lambda v: ''.join(filter(lambda x: x in string.printable, v)), headers))
only_keys = list(headers)
only_keys_str = os.environ.get("ONLY_KEYS")
if only_keys_str:
	only_keys = only_keys_str.split(',')

output_list = []
for row in rows[1:]:
	row_dict = {}
	for c_index, val in enumerate(row):
		if headers[c_index] not in only_keys:
			continue
		row_dict[headers[c_index]] = val.strip()
	output_list.append(row_dict)

indent_spaces_str = os.environ.get("INDENT_SPACES", "2")
indent_spaces = int(indent_spaces_str)
print(json.dumps(output_list, indent=indent_spaces))
EOF
}

firefox() {
	if [[ "IS_MAC" -eq 1 ]]; then
		/Applications/Firefox.app/Contents/MacOS/firefox "$@"
		return 0
	fi
	return 1
}

firefox_get_profile_dir() {
	local firefox_db_location=""
	if [[ $IS_MAC -eq 1 ]]; then
		firefox_db_location=$(rg \
			--files \
			--no-ignore \
			--glob "**/Profiles/*.default-release/places.sqlite" \
			~/Library/Application\ Support/Firefox 2>/dev/null)
	else
		firefox_db_location=$(find ~/snap/firefox -iname "places.sqlite" -type f 2>/dev/null)
	fi
	# Error out on no matches, or greater than 1 match
	if [[ -z "$firefox_db_location" ]]; then
		echo "ERROR: Could not find Firefox DB location"
		return 1
	fi
	if [[ $(echo "$firefox_db_location" | wc -l) -gt 1 ]]; then
		# TODO: Support multiple profiles?
		echo "ERROR: Found more than one Firefox DB location"
		return 1
	fi
	dirname "$firefox_db_location"
}

# Convert Mozilla's non-standard LZ4 files (jsonlz4 or mozlz4) to JSON
# The special things about moz's lz4 implementation are:
# - Non-standard header - first 8 bytes, magic `mozLz40\0`
# - Uses blocks instead of frame (making it incompatible, as-is, with the
#   lz4 CLI)
moz_lz4json_to_json() {
	local mozlz4_file="$1"
	if ! [[ -f $mozlz4_file ]]; then
		echo "File $mozlz4_file does not exist"
		return 1
	fi
	# Check for magic header bytes
	if ! [[ $(head -c 7 "$mozlz4_file") == "mozLz40" ]]; then
		echo "Not a Mozilla LZ4 JSON file"
		return 1
	fi
	# Make sure mozlz4_file is full path
	mozlz4_file=$(realpath "$mozlz4_file")
	# Check for required python package
	ensure_pkg_in_dotfiles_venv "lz4"

	python_script=$(cat <<- EOF
	import lz4.block
	import json
	with open("$mozlz4_file", "rb") as f:
	    f.seek(8)
	    decompressed = lz4.block.decompress(f.read())
	    decoded = decompressed.decode("utf-8")
	    parsed_json = json.loads(decoded)
	    print(json.dumps(parsed_json, indent=2))
	EOF
	)

	mozlz4_file="$mozlz4_file" run_raw_python_in_dotfiles_venv "$python_script"
}

# WARNING: This produces a *huge* (multi-MB) JSON file
firefox_dump_restore_file() {
	local OUT_DIR="$(pwd)"
	while true; do
		printf "Where to export? ENTER / [Pp]wd dir, [Tt]emp dir?\n"
		read -r answer
		case $answer in
			[Pp]*) break ;;
			"") break ;;
			[Tt]*) OUT_DIR="$(mktemp -d)"
		esac
	done

	local firefox_profile_dir=$(firefox_get_profile_dir)
	if [[ $? -ne 0 ]] || [[ -z "$firefox_profile_dir" ]]; then
		return 1
	fi
	local firefox_recovery_file_path="${firefox_profile_dir}/sessionstore-backups/recovery.jsonlz4"

	cp "$firefox_recovery_file_path" "$OUT_DIR/"
	local OUT_FILE="$OUT_DIR/$(date_iso)__firefox_recovery.json"
	moz_lz4json_to_json "$OUT_DIR/recovery.jsonlz4" > "$OUT_FILE"
	echo "💾 Backed up: $firefox_recovery_file_path"
	echo "    -> To: $OUT_FILE"
}

firefox_run_backups() {
	local MAX_BACKUPS=${FF_MAX_BACKUPS:=6}
	# TODO
}

firefox_get_tabs() {
	:
	# TODO
}

# Copies the Firefox DB (`places.sqlite`) to a temp dir,
# to avoid lock issues / concurrency / corruption
firefox_get_temp_db_copy() {
	local VERBOSE=0
	if [[ $* == *--verbose* ]]; then
		VERBOSE=1
	fi
	local firefox_profile_dir=$(firefox_get_profile_dir)
	if [[ $? -ne 0 ]] || [[ -z "$firefox_profile_dir" ]]; then
		return 1
	fi
	local firefox_db_location="$firefox_profile_dir/places.sqlite"
	[[ $VERBOSE -eq 1 ]] && echo "Firefox DB location(s) = $firefox_db_location"

	# Copy database to a temp directory to avoid lock issues / concurrency / corruption
	local temp_dir=$(mktemp -d)
	local temp_db_copy="$temp_dir/places.sqlite"
	[[ $VERBOSE -eq 1 ]] && echo "💾 Creating temporary copy of FF DB"
	cp "$firefox_db_location" "$temp_db_copy"

	echo "$temp_db_copy"
}

firefox_db_interact() {
	local VERBOSE=0
	if [[ $* == *--verbose* ]]; then
		VERBOSE=1
	fi
	local callback=$1
	if [[ -z "$callback" ]]; then
		echo "ERROR: No callback provided"
		return 1
	fi
	shift
	local temp_db_copy=$(firefox_get_temp_db_copy)

	# Call our callback with the temporary db, to let it do whatever it wants
	$callback "$temp_db_copy"

	# Cleanup!
	[[ $VERBOSE -eq 1 ]] && echo "🗑️ Cleaning up temp DB copy"
	rm -f "$temp_db_copy"
	[[ $VERBOSE -eq 1 ]] && echo "✅ Firefox DB interaction complete"

}

# Get members of a firefox bookmarks group by group ID or name
# Returns joined rows as JSON
firefox_get_bookmark_group_members() {
	if ! (which sqlite3 > /dev/null); then
		echo "ERROR: sqlite3 not found"
		return 1
	fi
	local temp_db_copy=$(firefox_get_temp_db_copy)
	bookmark_group_name_or_id=$1
	GROUP_ID=$1
	IS_ID=$(echo "$bookmark_group_name_or_id" | grep -E -q "^[0-9]+$" && echo "true" || echo "false")
	if [[ "$IS_ID" == "false" ]]; then
		GROUP_ID=$(sqlite3 "$temp_db_copy" "SELECT id FROM moz_bookmarks WHERE title = '$bookmark_group_name_or_id';")
		if [[ -z "$GROUP_ID" ]]; then
			echo "ERROR: Could not find bookmark group '$bookmark_group_name_or_id'"
			return 1
		fi
	fi
	sqlite3 \
		"$temp_db_copy" \
		".mode json" \
		"SELECT * FROM moz_bookmarks JOIN moz_places ON moz_bookmarks.fk = moz_places.id WHERE moz_bookmarks.parent = '$GROUP_ID';"
	rm -f "$temp_db_copy"
}

chrome() {
	if [[ "IS_MAC" -eq 1 ]]; then
		: "${CHROME_BIN:="/Applications/Google Chrome.app/Contents/MacOS/Google Chrome"}"
		"$CHROME_BIN" "$@"
		return 0
	fi
	return 1
}

# Opens firefox, with each URL passed at the end, as a new tab
# Currently, with tree style tabs, the first URL becomes the root tab
# and any subsequent new tabs are loaded as children
# (TODO: Make this more flexible)
# See: http://kb.mozillazine.org/Command_line_arguments
firefox_with_tabs() {
	args=("-new-window")
	for arg in "$@"; do
		args+=("-new-tab" "-url" "$arg")
	done
	firefox "${args[@]}"
}

# Opens Chrome, with each URL passed at the end, as a new tab
# See: https://peter.sh/experiments/chromium-command-line-switches/
chrome_with_tabs() {
	args=("--new-window")
	for arg in "$@"; do
		args+=("$arg")
	done
	chrome "${args[@]}"
}

# This opens a new browser with a preset group of tabs, based on stdin JSON
# that matches the `browser-group.json` schema.
# See [browser-groups.json](./schemas/browser-groups.json).
# It defaults to Firefox - use `--chrome` to launch with Chrome instead.
open_browser_group_url() {
	local JSON=$1
	shift
	local BROWSER="firefox"
	if (check_args_for_value "--chrome" "$*"); then
		BROWSER="chrome"
	fi
	local OPEN_ALL=0
	if (check_args_for_value "--all" "$*"); then
		OPEN_ALL=1
	fi

	# Pass the list of tabs (URLS) to the browser
	local TAB_URLS=($(echo "$JSON" | jq -r ".tabs[].url"))
	# Check for empty array
	if [[ ${#TAB_URLS[@]} -eq 0 ]]; then
		echo "ERROR: No tabs found"
		return 1
	fi

	if [[ $OPEN_ALL -eq 1 ]]; then
		if [[ "$BROWSER" == "firefox" ]]; then
			firefox_with_tabs "${TAB_URLS[@]}"
		elif [[ "$BROWSER" == "chrome" ]]; then
			chrome_with_tabs "${TAB_URLS[@]}"
		fi
		return 0
	fi

	local SELECTED_TAB_URL=$(echo "$JSON" | jq -r '.tabs[] | "\(.notes) || \(.url)"' | fzf | awk -F '\\|\\|' '{print $2}')
	if [[ -n "$SELECTED_TAB_URL" ]]; then
		if [[ "$BROWSER" == "firefox" ]]; then
			firefox "$SELECTED_TAB_URL"
		elif [[ "$BROWSER" == "chrome" ]]; then
			chrome "$SELECTED_TAB_URL"
		fi
		return 0
	fi

	return 1
}

# Get nested workspace JSON by name, or with TUI selector
get_workspace_json() {
	local WORKSPACE_NAME=$1
	local CONSIDER_ONLY_ACTIVE_WORKSPACES=$(
		{ [[ -n "$ALL_WORKSPACES" ]] || [[ $* == *--all* ]]; } && echo "y" || echo "n"
	)
	local workspaces_file=~/.workspaces.json
	if ! [[ -f "$workspaces_file" ]]; then
		echo "ERROR: Could not find workspaces file at $workspaces_file"
		return 1
	fi
	local JSON=$(cat "$workspaces_file")
	local NAME_KEYS=()
	local NAME_KEYS_STR=$(echo "$JSON" | jq -r 'del(."$schema") | keys[]' 2>/dev/null)
	while IFS='' read -r line; do NAME_KEYS+=("$line"); done < <(echo "$NAME_KEYS_STR")
	# Check if WORKSPACE_NAME is valid (in list of keys)
	local FOUND_KEY=0
	for key in "${NAME_KEYS[@]}"; do
		if [[ "$key" == "$WORKSPACE_NAME" ]]; then
			FOUND_KEY=1
			break
		fi
	done

	# If key was not found, offer a selector TUI (preview is group config)
	if [[ $FOUND_KEY -eq 0 ]]; then
		if [[ "$CONSIDER_ONLY_ACTIVE_WORKSPACES" == "n" ]]; then
			NAME_KEYS_STR=$(echo "$JSON" | jq -r 'del(."$schema") | with_entries(select(.value.active == true)) | keys[]' 2>/dev/null)
		fi
		WORKSPACE_NAME=$(echo "$NAME_KEYS_STR" | fzf --preview "jq '.\"{}\"' $workspaces_file")
	fi

	if [[ -z "$WORKSPACE_NAME" ]]; then
		return 1
	fi

	echo "$JSON" | jq -r "$(printf '."%s"' "$WORKSPACE_NAME")"
}

open_workspace() {
	local WORKSPACE_NAME=$1
	local WORKSPACE_JSON=$(get_workspace_json "$WORKSPACE_NAME")

	if [[ -z "$WORKSPACE_JSON" ]]; then
		return 1
	fi

	# Don't open slack by default - require `--with-slack`
	if (check_args_for_value "--with-slack"); then
		local first_slack_channel=$(echo "$WORKSPACE_JSON" | jq -r ".slackChannels[0]")
		if [[ "$first_slack_channel" != "null" ]]; then
			local TEAM_ID=$(echo "$first_slack_channel" | jq -r '.teamId')
			local CHANNEL_ID=$(echo "$first_slack_channel" | jq -r '.channelId')
			open "slack://channel?team=${TEAM_ID}&id=${CHANNEL_ID}"
		fi
	fi

	local first_ide_project_root=$(echo "$WORKSPACE_JSON" | jq -r ".ideProjectRoots[0]")
	if [[ "$first_ide_project_root" != "null" ]]; then
		code "$(expand_path "$first_ide_project_root")"
	fi

	local first_browser_group_json=$(echo "$WORKSPACE_JSON" | jq -r ".browserGroups[0]")
	if [[ "$first_browser_group_json" != "null" ]]; then
		open_browser_group_url "$first_browser_group_json" "--$BROWSER" --all
	fi

	local tmux_session_name=$(echo "$WORKSPACE_JSON" | jq -r ".preferredTmuxSessionName")
	if [[ "$tmux_session_name" != "null" ]]; then
		# Note: tmux_auto_open already gracefully handles if session is already open
		tmux_auto_open "$tmux_session_name"
	fi
}

open_workspace_url() {
	local WORKSPACE_NAME=""
	local PASS_THROUGH_ARGS=()
	while [[ ! $# -eq 0 ]]
	do
		case "$1" in
			-w|--workspace)
				WORKSPACE_NAME=$2
				shift
				shift
				;;
			*)
				PASS_THROUGH_ARGS+=("$1")
				shift
				;;
		esac
	done
	local WORKSPACE_JSON=$(get_workspace_json "$WORKSPACE_NAME")
	local first_browser_group_json=$(echo "$WORKSPACE_JSON" | jq -r ".browserGroups[0]" 2>/dev/null)
	if [[ $? -eq 0 ]] && [[ "$first_browser_group_json" != "null" ]]; then
		open_browser_group_url "$first_browser_group_json" "${PASS_THROUGH_ARGS[@]}"
	else
		echo "Could not fetch browserGroups. Is it configured in the JSON config?"
		return 1
	fi
}

date_iso() {
	# 2020-11-28T12:11:28Z
	date -u +"%Y-%m-%dT%H:%M:%SZ"
}

date_ms() {
	if which gdate > /dev/null; then
		gdate +%s%3N
	else
		date +%s000
		# echo "WARNING: gdate not found; faking millseconds from seconds"
	fi
}

# Like `touch` + `mkdir -p`: creates intermediate directories if they don't exist yet
make_file() {
	file_path=$1
	if [[ -e $file_path ]]; then
		echo "File already exists"
	else
		mkdir -p "$(dirname "$file_path")"
		touch "$file_path"
	fi
}

get_cpu_throttle_info() {
	if [[ $* == *--watch* ]]; then
		pmset -g thermlog
		return
	fi
	pmset -g therm
}

make_venv() {
	VENV_PATH=./.venv
	echo "Where should the virtual environment be created? (press enter to default to .venv)"
	read -r INPUT
	if [[ $INPUT != "" ]]; then
		VENV_PATH=$INPUT
	fi
	if [[ -d $VENV_PATH ]]; then
		echo "${VENV_PATH} already exists"
	else
		echo "Preparing virtual environment in ${VENV_PATH}"
		python3 -m venv $VENV_PATH
		source $VENV_PATH/bin/activate
	fi
}

check_venv() {
	which python | grep "$PWD"
}

# Generates the poetry named environment string
# Although this _can_ be used to check that the correct virtual environment is
# activated, it is generally much easier to just use a regular venv and point
# poetry to it (because then you can just do something like `which python | grep $PWD`)
# For implementation reference see
#   https://github.com/python-poetry/poetry/blob/7c86992909257caa4f51a50c001f5894bfe5065e/src/poetry/utils/env.py#L635
#   https://github.com/python-poetry/poetry/blob/7c86992909257caa4f51a50c001f5894bfe5065e/src/poetry/utils/env.py#L1212-L1220
generate_poetry_env_name_str() {
	PROJECT_NAME=$(basename "$PWD")
	if [[ -f pyproject.toml ]]; then
		PROJECT_NAME=$(poetry version | sed -E -n 's/(.+) [.0-9]+$/\1/p')
	fi
	PROJECT_NAME=$PROJECT_NAME python << "EOF"
import base64
import os
import re
import hashlib

# shim - re-implement poetry encode method
def encode(string: str):
	if isinstance(string, bytes):
		return string
	return string.encode("utf-8")

def generate_env_name(package_name: str, cwd: str) -> str:
	package_name = package_name.lower()
	sanitized_name = re.sub(r'[ $`!*@"\\\r\n\t]', "_", package_name)[:42]
	normalized_cwd = os.path.normcase(os.path.realpath(cwd))
	h_bytes = hashlib.sha256(encode(normalized_cwd)).digest()
	h_str = base64.urlsafe_b64encode(h_bytes).decode()[:8]
	return f"{sanitized_name}-{h_str}"

cwd = os.getcwd()
print(generate_env_name(os.environ["PROJECT_NAME"], cwd))
# Should print something like `project-name-ABCD1a-Z`
EOF
}

# Search for, and activate, a local python virtual environment
# @TODO - if python env is *already* activated, check if path matches, and if not
# 	deactivate and then activate
# @TODO - handle Poetry
activate() {
	fail=1
	possible_envs=(./venv ./.venv ./env ./.env)
	for env_dir in "${possible_envs[@]}"; do
		if [[ -e "$env_dir/bin/activate" ]]; then
			source "$env_dir/bin/activate"
			fail=0
			break
		fi
	done
	return $fail
}
# TODO set up auto-activate on every shell start

pip_upgrade() {
	python3 -m pip install --upgrade pip
}

# Like clear, but extra space to pad the start
wipe() {
	for run in {1..10}; do
		echo $'\n'
	done
	clear
}

render_image() {
	IMAGE_PATH=$1

	# Wezterm
	if (which wezterm > /dev/null) && (is_in_wezterm); then
		wezterm imgcat "$IMAGE_PATH"
		return
	fi

	# ImageMagick
	if (which display > /dev/null); then
		# Sometimes can be installed, but misconfigured. Can use a simple` --version`
		# check to verify
		if (display --version > /dev/null 2>&1); then
			display "$IMAGE_PATH"
			return
		else
			echo "WARNING: ImageMagick installed, but not configured correctly"
		fi
	fi

	if (which chafa > /dev/null); then
		chafa "$IMAGE_PATH"
		return
	fi

	echo "ERROR: Could not find a suitable image viewer"
	return 1
}

render_table() {
	local horizontal_scroll="true"
	if [[ $* == *--no-h-scroll* ]]; then
		horizontal_scroll="false"
	fi
	if (run_raw_cmd_in_dotfiles_venv 'pip show rich' > /dev/null); then
		# ellipsis (default) | fold | crop
		local overflow="ellipsis"
		if [[ $* == *--fold* ]] || [[ $horizontal_scroll == "true" ]]; then
			overflow="fold"
		fi
		local table_string="$1"
		local python_script=$(cat <<-EOF
		import os
		from rich.console import Console
		from rich.table import Table

		table_string = """$table_string"""
		rows = table_string.splitlines()
		header_row = rows[0]
		header_row_cells = rows[0].split('\t')
		rows = rows[1:]

		console_args = {}

		if "$horizontal_scroll" == "true":
		    # If horizontal scroll is on, we need to manually set shell args,
		    # since we lose them piping through less
		    console_args["color_system"] = "256"

		    # This is kind of hackish, but rich doesn't seem to have something
		    # like width=max, so this is a workaround
		    # Use actual total header char length, plus padding
		    header_row_char_length = sum(len(h_cell) for h_cell in header_row_cells) + (len(header_row_cells) * 8)
		    console_args["width"] = header_row_char_length


		console = Console(**console_args)


		table = Table(show_header=True, header_style="bold magenta")

		for header_cell in header_row_cells:
		    column_args = {"overflow": "$overflow"}
		    if "$horizontal_scroll" == "true":
		        # This is kind of hackish, but rich doesn't seem to have something
		        # like width=max, so this is a workaround
		        column_args["min_width"] = len(header_cell) + 2
		    table.add_column(header_cell, **column_args)
		for row in rows:
		    table.add_row(*row.split('\t'))
		console.print(table)
		EOF
		)
		if [[ $horizontal_scroll == "true" ]]; then
			run_raw_python_in_dotfiles_venv "$python_script" | less -R -S
		else
			run_raw_python_in_dotfiles_venv "$python_script"
		fi
		return 0
	fi

	if [[ $horizontal_scroll == "true" ]]; then
		echo "$table_string" | column -ts $'\t' | less -R -S
	else
		echo "$table_string" | column -ts $'\t'
	fi
}

render_json_as_table() {
	local json_string_or_file="$1"
	local json_string="$1"
	shift
	local ends_with_dot_json=$( (echo "$json_string_or_file" | grep -E '.*\.json$') && echo "true" || echo "false" )
	if [[ $ends_with_dot_json == "true" ]] && [[ -f "$json_string_or_file" ]]; then
		json_string=$(cat "$json_string_or_file")
	fi
	local json_as_table=$(echo "$json_string" | jq -r 'map( with_entries(  .value |= tostring  ) ) | (map(keys) | add | unique) as $cols | map(. as $row | $cols | map($row[.])) as $rows | $cols, $rows[] | @tsv')
	render_table "$json_as_table" "$@"
}

# For rendering text adjacent / to the right of a dynamically shaped block of text
# E.g., for scripting a display like neofetch, with ANSI color escape codes used
# This is hacky, but can mostly get the job done
# TODO: make this more ergonomic, with some sort of arg parser
render_text_overlay() {
	local _NO_TRUNCATE="${NO_TRUNCATE:=0}"

	TERM_STYLE_RESET=$TERM_STYLE_RESET TERM_LINES=$LINES TERM_COLUMNS=$COLUMNS LEFT_TEXT=$1 RIGHT_TEXT=$2 MAX_LEFT_COLUMN_COUNT=$3 PAD_TOP=$4 NO_TRUNCATE=$_NO_TRUNCATE node <<-"EOF"
	const stripAnsi = (s) => s.replace(/\x1b\[([0-9]{1,2}(;[0-9]{1,2})?)?[m|K]/g, '');

	const TERM_STYLE_RESET=process.env.TERM_STYLE_RESET || '';
	const TERM_COLUMNS = parseInt(process.env.TERM_COLUMNS);
	const TERM_LINES = parseInt(process.env.TERM_LINES);
	const LEFT_LINES = process.env.LEFT_TEXT.split('\n');
	const RIGHT_LINES = process.env.RIGHT_TEXT.split('\n');
	let PAD_TOP = parseInt(process.env.PAD_TOP);
	if (isNaN(PAD_TOP)) {
		PAD_TOP = 0;
	}
	let LEFT_COLUMN_COUNT = parseInt(process.env.MAX_LEFT_COLUMN_COUNT);
	const longestLeftColumnCount = LEFT_LINES.reduce((max, line) => {
		return Math.max(max, stripAnsi(line).length);
	}, 0);
	if (isNaN(LEFT_COLUMN_COUNT) || LEFT_COLUMN_COUNT <= 0) {
		LEFT_COLUMN_COUNT = longestLeftColumnCount;
	}
	let MAX_LINES_OUT = Math.max(RIGHT_LINES.length + PAD_TOP, LEFT_LINES.length);
	if (process.env.NO_TRUNCATE == '0') {
		// Cap at number of terminal lines
		MAX_LINES_OUT = Math.min(MAX_LINES_OUT, TERM_LINES);
	}

	let i = 0;
	while (i < MAX_LINES_OUT) {
		let leftLine = LEFT_LINES[i] || '';
		let rightLine = '';
		// Subtract padding from current index, since a positive padding
		// should delay when we start outputting right lines
		let rightLineIndex = i - PAD_TOP;
		if (i >= PAD_TOP && RIGHT_LINES[rightLineIndex]) {
			rightLine = RIGHT_LINES[rightLineIndex]
		}
		const leftLineLength = stripAnsi(leftLine);
		if (leftLineLength > LEFT_COLUMN_COUNT) {
			// Clip left line if it's too long (completely clip, not ellipses)
			leftLine = leftLine.slice(0, LEFT_COLUMN_COUNT);
		} else {
			// If too short, pad-right to justify with other rows
			leftLine = leftLine + ' '.repeat(LEFT_COLUMN_COUNT - leftLineLength)
		}
		leftLine += TERM_STYLE_RESET;
		let lineToRender = `${leftLine} | ${rightLine}`;
		// If line is now over terminal width, then split the right part into a new chunk, and indent with space
		const numColumnsOverTermWidth = stripAnsi(lineToRender).length - TERM_COLUMNS;
		if (numColumnsOverTermWidth > 0) {
			// Slice off excess, and insert for next loop
			const rightLineToInsert = rightLine.slice(-numColumnsOverTermWidth);
			RIGHT_LINES.splice(rightLineIndex + 1, 0, rightLineToInsert);
			// Reset current line, with truncation
			lineToRender = `${leftLine} | ${rightLine.slice(0, -numColumnsOverTermWidth)}`;
		}
		i++;

		console.log(lineToRender);
	}
	EOF
}

# Note: This is ZSH specific; todo - make agnostic?
reload_func() {
	unfunction "_$1" && compinit
}

normalize_name() {
	input_name="$1"
	# SPACE -> `-`
	# (anything else, non alpha-numeric) -> REMOVED
	echo "$input_name" | tr ' ' '-' | tr -cd '[:alnum:]-'
}

project_name() {
	project_dir=$1
	if [[ -z "$project_dir" ]]; then
		project_dir="$PWD"
	fi
	project_dirname=$(basename "$project_dir")

	# DEFAULT
	project_name="$project_dirname"

	# Is there a pyproject.toml file?
	if [[ -f "$project_dir/pyproject.toml" ]]; then
		project_name=$(poetry version | awk '{print $1}')
	# How about `package.json`?
	elif [[ -f "$project_dir/package.json" ]]; then
		project_name=$(jq -r '.name' "$project_dir/package.json")
	# How about a git remote / named repo?
	elif [[ -d "$project_dir/.git" ]]; then
		remote_url=$(git_remote_url)
		project_name=$(basename "$remote_url")
	fi

	echo "$project_name"
}

project_name_normalized() {
	project_name_raw=$(project_name "$1")
	normalize_name "$project_name_raw"
}

get_project_version() {
	local target_dir=.
	local used_cd=0
	if [[ -d $1 ]]; then
		target_dir=$1
		pushd $target_dir > /dev/null || return 1
		used_cd=1
	fi
	local found_versions=()

	if [[ -f "pyproject.toml" ]]; then
		found_version=$(poetry version | awk '{print $2}')
	elif [[ -f "package.json" ]]; then
		found_version=$(jq -r '.version' "package.json")
	fi
	if [[ -n "$found_version" ]]; then
		found_versions+=("$found_version")
	fi

	if [[ $used_cd -eq 1 ]]; then
		popd > /dev/null || return 1
	fi

	# Echo out array, joined with `\n`
	echo "${found_versions[@]}"
}

set_project_version() {
	:
	# npm version --no-git-tag-version $version_string ("v1.0.0" turns into "1.0.0")
	# poetry version $version_string  ("v1.0.0" turns into "v1.0.0", so you want to omit `v` prefix unless you actually want it to be in the string)
}

bump_project_version() {
	local target_dirs=()
	local new_version=-1
	while [[ ! $# -eq 0 ]]
	do
		if [[ -d "$1" ]]; then
			target_dirs+=("$1")
		else
			# If we are on the last variable, check if it matches semver
			if [[ $# -eq 1 ]] && [[ $1 =~ ^[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
				new_version=$1
			else
				echo "Last argument was neither a directory or version string"
				return 1
			fi
		fi
	done
	if [[ ${#target_dirs[@]} -eq 0 ]]; then
		target_dirs+=(".")
	fi
	if [[ $new_version -eq -1 ]]; then
		# Try to extract current version
		local current_version=-1
		echo "⚠️ Current version not specified. Trying to auto-extract..."
		local last_dir_with_version=""
		for target_dir in "${target_dirs[@]}"; do
			local extracted_version=$(get_project_version $target_dir)
			if [[ $? -eq 0 ]]; then
				# If we have already extracted a version, and this other directory doesn't match, we have a problem
				if ! [[ $current_version -ne -1 ]] && [[ $extracted_version != "$current_version" ]]; then
					echo "❌ Version $current_version was already found in $last_dir_with_version, but got conflicting version of $extracted_version in $target_dir"
					return 1
				elif [[ $current_version -eq -1 ]]; then
					current_version=$extracted_version
				fi
			fi
		done
		if [[ $current_version -eq -1 ]]; then
			echo "❌ Could not auto-extract current version"
		else
			echo "Detected / extracted version of $current_version. Is this correct? [Yy]es / [Nn]o?"
			read -r INPUT
			if [[ $INPUT =~ ^[Nn]$ ]]; then
				return 1
			fi
		fi

		# Determine new version from current version
		# ...
		# WIP / TODO
	fi
}

# @see https://www.nerdfonts.com/cheat-sheet for what is available
nerd_font() {
	case "$1" in
		cod_terminal_tmux) echo "\Uebc8" && return ;;
		*) echo "No mapping saved for $1" && return 1 ;;
	esac
}

exit_code_to_pass_fail_icon() {
	local exit_code=$?
	local exit_code_arg=$1
	if [[ -n "$exit_code_arg" ]]; then
		exit_code=$exit_code_arg
	fi
	[[ $exit_code -eq 0 ]] && echo "✅" || echo  "❌"
}

is_in_wezterm() {
	if [[ -z "$WEZTERM_UNIX_SOCKET" ]]; then
		return 1
	fi
	return 0
}

# Sets a user variable inside the WezTerm variable space
# NOTE: This is _NOT_ setting a shell environment variable; rather,
# this sets it within the WezTerm managed variable list, which can
# be programmatically accessed (and also emits events when changed).
# @SEE https://wezfurlong.org/wezterm/recipes/passing-data.html#user-vars
wezterm_set_var() {
	if ! (which base64 > /dev/null); then
		echo "Must have base64 in path to encode variable value"
		return 1
	fi
	local var_name=$1
	local var_val_encoded=$(echo -n "$2" | base64)
	local var_setter_str=$(printf "\033]1337;SetUserVar=%s=%s\007" "$var_name" "$var_val_encoded")
	tmux_passthrough_escape "$var_setter_str"
}

wezterm_get_var() {
	if ! (is_in_wezterm); then
		return 1
	fi
	echo "@TODO"
}

set_title() {
	local title=$1
	if ($OH_MY_ZSH_ACTIVE) && [[ $DISABLE_AUTO_TITLE != true ]]; then
		echo "You have Oh-My-ZSH active, and DISABLE_AUTO_TITLE is NOT set to true"
		echo "  ^ Setting titles via ANSI sequences will have no effect, because ZSH will just override"
		return 1
	fi
	tmux_passthrough_escape "$(printf "\x1B]0;%s\x07" "$title")"
}

is_in_tmux() {
	if ! (which tmux > /dev/null); then
		return 1
	fi
	[[ -n "$TMUX" ]]
}

tmux_reload_config() {
	tmux source-file ~/.tmux.conf
}

tmux_inspect() {
	local session_name=$1
	if [[ -z "$session_name" ]]; then
		session_name=$(tmux_session_select)
	fi
	cat <<- EOF
	################################
	# TMUX Session =               #
	#    $session_name             #
	################################
	EOF
	local spacer=""
	echo "${spacer}Windows:"
	local all_windows_in_session=$(tmux list-windows -t "$session_name" -F "#{window_index} #{window_name}")
	spacer="  "
	for window_info in $all_windows_in_session; do
		local window_idx=$(echo "$window_info" | awk '{print $1}')
		local window_name=$(echo "$window_info" | awk '{print $2}')
		echo "${spacer}∟ $window_idx | $window_name"
		local all_panes_in_window=$(tmux list-panes -t "$session_name:$window_idx" -F "#{pane_index}")
		local pane_count=$(($(echo "$all_panes_in_window" | wc -l)))
		spacer="       "
		echo "${spacer}∟ # of Panes = $pane_count"
	done

}

tmux_get_active_session_name() {
	# Note: This is necessary because `tmux display-message -p "#S"` actually
	# does not throw outside of a tmux session - it just returns the last alive
	# session
	if ! (is_in_tmux); then
		return 1
	fi
	tmux display-message -p "#S"
}

tmux_generate_session_name() {
	tmux_session_name=$1
	if [[ -z "$tmux_session_name" ]]; then
		project_name=$(project_name_normalized "")
		tmux_session_name="$project_name"
		# Default to project name + end of branch name
		current_git_branch_name=$(git_branch_name 2>&1)
		if [[ $? -eq 0 ]]; then
			tmux_session_name="${tmux_session_name}-$(basename "$current_git_branch_name")"
		fi
	fi
	echo "$tmux_session_name"
}

tmux_session_select() {
	if [[ -n "$TMUX_SESSION" ]]; then
		echo "$TMUX_SESSION"
		return
	fi
	active_sessions=$(tmux list-sessions -F "#{session_name}" 2>/dev/null)
	selected_session=$(printf "%s\n" "${active_sessions[@]}" | fzf)
	echo "$selected_session"
}

tmux_session_select_or_current() {
	local current_tmux_session_name=$(tmux_get_active_session_name)
	if [[ $? -eq 0 ]] && [[ -n "$current_tmux_session_name" ]]; then
		echo "$current_tmux_session_name"
		return
	fi
	tmux_session_select
}

tmux_session_select_and_attach() {
	tmux_attach_with_init "$(tmux_session_select)"
}

tmux_window_select() {
	local selected_session=$(tmux_session_select)
	if [[ -z "$selected_session" ]]; then
		return
	fi
	local all_windows_in_session=$(tmux list-windows -t "$selected_session" -F "#{window_index} #{window_name}")
	local selected_window_index="0"
	# Only prompt for selection if > 1 window
	if [[ $(($(echo "$all_windows_in_session" | wc -l))) -gt 1 ]]; then
		selected_window_index=$(echo "$all_windows_in_session" | fzf | awk '{print $1}')
	fi
	echo "$selected_session:$selected_window_index"
}

tmux_new_window() {
	local selected_session=$(tmux_session_select_or_current)
	tmux new-window -t "$selected_session"
}

tmux_pane_select() {
	selected_window=$(tmux_window_select)
	all_panes_in_window=$(tmux list-panes -t "$selected_window" -F "#{pane_index}")
	selected_pane=$(echo "$all_panes_in_window" | fzf --preview "tmux capture-pane -t $selected_window.{} -pJS -10")
	echo "$selected_window.$selected_pane"
}

tmux_pane_zoom_toggle() {
	if (is_in_tmux); then
		tmux resize-pane -Z
		return
	fi
	local selected_pane=$(tmux_pane_select)
	tmux resize-pane -Z -t "$selected_pane"
}
alias tmux_zoom="tmux_pane_zoom_toggle"

tmux_kill_pane() {
	local pane=$(tmux_pane_select)
	if [[ -z "$pane" ]]; then
		return
	fi
	tmux kill-pane -t "$pane"
}

tmux_scrollback_dump() {
	: "${NUM_LINES:="500"}"
	pane=$(tmux_pane_select)
	if [[ -z "$pane" ]]; then
		return
	fi
	tmux capture-pane -t "$pane" -pJS "-$NUM_LINES"
}

tmux_do_in_session_for_all_panes() {
	# TODO: Add override env var to allow forcing send-keys, even if
	# stdin is being clobbered / hijacked (e.g. by active logging)
	local session_name=$1
	if (is_in_tmux); then
		session_name=$(tmux_get_active_session_name)
	else
		# Don't pass $1 (session_name) along to send-keys
		shift
	fi
	tmux set-window-option -t "$session_name" synchronize-panes on
	tmux send-keys -t "$session_name" "$*" C-m || true
	tmux set-window-option -t "$session_name" synchronize-panes off
}

# @See https://github.com/tmux/tmux/wiki/FAQ#what-is-the-passthrough-escape-sequence-and-how-do-i-use-it
tmux_passthrough_escape() {
	local string_to_wrap=$1
	if (is_in_tmux); then
		if ! (tmux show-options -g allow-passthrough | grep -q "on"); then
			echo "allow-passthrough must be set for ANSI escaping passthrough to work with tmux"
			return 1
		fi
		printf "\033Ptmux;\033%s\033\\" "$string_to_wrap"
		return 0
	fi
	echo -ne "$string_to_wrap"
}

tmux_attach_with_init() {
	local tmux_session_name=$1
	set_title "$(printf "%s %s" "\Uebc8" "$tmux_session_name")"

	# Get the list of allowed pass-through vars
	# show-option returns list as:
	#  update-environment[0] VAR_A
	#  update-environment[1] VAR_B
	#  ...etc.
	local tmux_var_names=()
	while read -r line; do tmux_var_names+=("$line"); done < <(tmux show-option -g update-environment | awk '{print $2}')

	# Have to remap passthrough values
	# OUTER_TERM_PROGRAM -> TERM_PROGRAM
	for tmux_var_name in "${tmux_var_names[@]}"; do
		if [[ $tmux_var_name != OUTER_TERM* ]]; then
			continue
		fi
		local local_var_name=$(echo "$tmux_var_name" | sed -rn 's/^OUTER_TERM(.*)/TERM\1/p')
		local local_var_val=$(get_var_value "$local_var_name")
		set_var_value "$tmux_var_name" "$local_var_val"
		export "${tmux_var_name?}"
		echo "Set $tmux_var_name to $local_var_name val of $local_var_val"
	done

	# For Rio, use different color schemes to avoid conflicts with shader renderers
	if [[ "$TERM_PROGRAM" == "rio" ]]; then
		tmux set-option -t "$session_name" window-style 'fg=colour240,bg=default'
		tmux set-option -t "$session_name" window-active-style 'fg=colour255,bg=default'
	else
		# Reset back to defaults
		tmux set-option -t "$session_name" window-style "$(tmux_get_global_option_value "window-style")"
		tmux set-option -t "$session_name" window-active-style "$(tmux_get_global_option_value "window-active-style")"
	fi

	tmux attach-session -t "$tmux_session_name"
}

tmux_get_global_option_value() {
	local dummy_session_name=""
	# In order to get tmux config values, the server has to be up and running
	if ! (tmux has-session); then
		dummy_session_name="dummy_session$(date +%s)"
		tmux new-session -s "$dummy_session_name" -d
	fi

	# This is basically equivalent to `show-option`, thanks to `-g`
	# `-v` is to return value only, otherwise tmux returns `{VAR_NAME} {VALUE}`
	tmux show-options -gv "$1"

	if [[ -n "$dummy_session_name" ]]; then
		tmux kill-session -t "$dummy_session_name"
	fi
}

tmux_auto_open() {
	local tmux_session_name=$(tmux_generate_session_name "$1")
	echo "Session name = $tmux_session_name"

	# Check if we are already in the session
	if [[ $(tmux_get_active_session_name) == "$tmux_session_name" ]]; then
		echo "Already in session"
		return
	fi

	# Search for active session first, and attach if exists
	if (tmux has-session -t "$tmux_session_name" 2>/dev/null); then
		echo "Attaching to existing session"
		tmux_attach_with_init "$tmux_session_name"
		return
	fi

	# Offer pick list, of already open sessions + new session (at top)
	# TODO

	PANE_NUM=1
	select pane_config in "1 Pane" "2 Pane (H-Split)" "3 Pane (V, HH)"; do
		case $pane_config in
			"1 Pane") break ;;
			"2 Pane (H-Split)") PANE_NUM=2 && break ;;
			"3 Pane (V, HH)") PANE_NUM=3 && break ;;
		esac
	done
	echo "Creating new session ($tmux_session_name)"
	tmux new-session -s "$tmux_session_name" -d

	tmux set-environment -t "$tmux_session_name" JTZ_SESSION_NAME "$tmux_session_name"

	if [[ $PANE_NUM -gt 1 ]]; then
		tmux split-window -h -t "$tmux_session_name:0"
		# For 3-pane, v-split the first pane
		if [[ $PANE_NUM -eq 3 ]]; then
			tmux select-pane -t "$tmux_session_name":0.0
			tmux split-window -v -t "$tmux_session_name"
		fi
	fi

	# Loop through all panes and exec `activate`
	for pane_id in $(tmux list-panes -F "#{pane_id}" -t "$tmux_session_name"); do
		tmux send-keys -t "${tmux_session_name}:0.${pane_id}" activate C-m 2>&1
	done

	tmux select-pane -t "$tmux_session_name":0.0
	tmux_attach_with_init "$tmux_session_name"
}

# This function scans for active tmux sessions where at least one pane
# has a working directory scoped to the current one - which is useful if you
# forgot what you named the session, but remember where you were working in.
# If there are more than one matching sessions, it will let you select
# which one to attach to with `fzf`
tmux_auto_attach() {
	# Get the current working directory
	current_dir=$(pwd)

	# Get a list of all active tmux sessions
	active_sessions=()
	while IFS='' read -r line; do active_sessions+=("$line"); done < <(tmux list-sessions -F "#{session_name}" 2>/dev/null)

	# Loop through all sessions, and check if any of the panes have a
	# working directory that matches the current one
	matching_sessions=()
	for session in "${active_sessions[@]}"; do
		# Get list of pane paths
		pane_paths=()
		while IFS='' read -r line; do pane_paths+=("$line"); done  < <(tmux list-panes -t "$session" -F "#{pane_current_path}" 2>/dev/null)
		for pane_path in "${pane_paths[@]}"; do
			if [[ "$pane_path" == "$current_dir" ]]; then
				matching_sessions+=("$session")
				break
			fi
		done
	done

	declare -p matching_sessions

	# If there is only one matching session, attach to it
	if [[ ${#matching_sessions[@]} -eq 1 ]]; then
		matching_session_name=${matching_sessions[0+$ARRAY_INDEX_START]}
		echo "Found only 1 matching session ($matching_session_name). Auto-attaching now..."
		sleep 2
		tmux_attach_with_init "$matching_session_name"
		return
	fi

	# If there are multiple matching sessions, let the user select which one to attach to
	if [[ ${#matching_sessions[@]} -gt 1 ]]; then
		echo "More than one matching tmux session was found. Which would you like to attach to?"
		selected_session=$(printf "%s\n" "${matching_sessions[@]}" | fzf)
		if [[ -n "$selected_session" ]]; then
			tmux_attach_with_init "$selected_session"
			return
		fi
	fi

	# If no matching sessions, just open a new one
	echo "Could not find matching session"
	tmux_auto_open ""
}

tmux_auto_close() {
	tmux_session_name=$(tmux_generate_session_name "$1")
	if (tmux has-session -t "$tmux_session_name" 2>/dev/null); then
		echo "Killing session ('$tmux_session_name')"
		tmux kill-session -t "$tmux_session_name"
	else
		echo "No session to kill (could not find '$tmux_session_name')"
	fi
}

# Revert the last commit, but don't undo the changes
git_revert_last() {
	git reset HEAD~1
}

git_sha_short() {
	git rev-parse --short HEAD
}

git_sha_full() {
	git rev-parse HEAD
}

git_sha_both() {
	echo "$(git_sha_full)\t$(git_sha_short)"
}

git_has_lfs_files() {
	git lfs ls-files | grep -q .
}

alias git_default_origin="git remote"

# Returns the (best-guess) name of the trunk branch, but
# WITHOUT the remote prefix (e.g. `main`, not `origin/main`)
git_trunk_branch() {
	git remote show "$(git_default_origin)" | grep "HEAD branch" | cut -d ":" -f 2 | sed -e 's/^[[:space:]]*//'
}

# Returns the (best-guess) name of the trunk branch, but
# WITH the remote prefix (e.g. `origin/main`, not `main`)
git_trunk_branch_remote() {
	echo "$(git_default_origin)/$(git_trunk_branch)"
}

git_root_dir() {
	git rev-parse --show-toplevel
}

git_repo_name() {
	remote_url=$(git_remote_url)
	basename "$remote_url"
}

git_repo_name_normalized() {
	normalize_name "$(git_repo_name)"
}

git_cd_root_dir() {
	cd "$(git_root_dir)" || exit
}

git_trunk_ahead_files() {
	TRUNK_BRANCH=$(git_trunk_branch)
	git fetch
	git --no-pager diff --name-only origin/"$TRUNK_BRANCH"...HEAD
}

# This should essentially be the file list of the diff for your `push`
git_local_ahead_of_remote_files() {
	CURRENT_BRANCH=$(git_branch_name)
	git fetch
	git --no-pager diff --name-only origin/"$CURRENT_BRANCH"...HEAD
}

git_update_local_trunk() {
	TRUNK_BRANCH=$(git_trunk_branch)
	CURRENT_BRANCH=$(git_branch_name)
	if [[ "$TRUNK_BRANCH" == "$CURRENT_BRANCH" ]]; then
		git pull
		return
	fi
	git fetch
	git fetch . origin/"$TRUNK_BRANCH":"$TRUNK_BRANCH"
}

git_behind_ahead_plain() {
	git fetch
	local TRUNK_BRANCH=$(git_trunk_branch)
	git rev-list --left-right --count origin/"$TRUNK_BRANCH"...HEAD
}

git_behind_ahead() {
	# Get the trunk / main branch in the repo (e.g. `main`)
	local TRUNK_BRANCH=$(git_trunk_branch)
	git fetch
	echo "Behind | Ahead"
	echo "      $(git_behind_ahead_plain)"
}



git_stat_live() {
	if [[ $* == *--summary ]]; then
		watch -n 2 -c "git diff --staged --stat  ':(exclude)package-lock.json' | tail -n 1"
	fi
	watch -n 2 -c "git diff --staged --stat  ':(exclude)package-lock.json'"
}

git_diff_live() {
	watch -n 2 -c "git diff --staged ':(exclude)package-lock.json'"
}

git_select_commit() {
	MAX_PAST_COMMITS_TO_LIST=40
	commits=$(git log --pretty=format:"%H %s" -n $MAX_PAST_COMMITS_TO_LIST)

	# Use fzf to interactively select a commit
	commit=$(echo "$commits" | fzf --height 70% --reverse --ansi)

	# Extract the commit hash from the selected line
	commit_hash=$(echo "$commit" | awk '{print $1}')

	echo "$commit_hash"
}

# Given a stash string like `stash@{0}: On main: do x and y`,
# extract out just the stash index
git_extract_stash_index() {
	stash_string="$1"
	echo "$stash_string" | grep -o -E "\{[0-9]+\}" | tr -d "{}"
}

git_stash_select() {
	stash_list=$(git stash list)
	# shellcheck disable=SC2016
	selected_stash=$(echo "$stash_list" | fzf \
		--height 70% \
		--reverse \
		--ansi \
		--preview "source ~/.zshrc && git stash show -p "'"$(git_extract_stash_index {})"'""
	)
	echo "$selected_stash"
}
alias git_select_stash="git_stash_select"
alias git_stash_list="git_stash_select"
alias git_stash_preview="git_stash_select"

git_copy_commit_sha() {
	commit_hash=$(git_select_commit)
	echo "$commit_hash" | copy_to_clipboard
}

git_copy_commit_msg() {
	commit_hash=$(git_select_commit)
	commit_msg=$(git log --pretty=format:"%B" -n 1 "$commit_hash")
	echo "$commit_msg" | copy_to_clipboard
}

# Use this to interactively select a past commit to target for `git commit --fixup=`
git_fixup() {
	commit_hash=$(git_select_commit)
	git commit --fixup="$commit_hash"
}


# TODO: This works, but really should be re-written in JS or Python
# (too many ZSH and bash workarounds, hard to read)
git_find_fixup_base() {
	MAX_PAST_COMMITS_TO_SCAN_PER_FIXUP=40
	LOG_DIVIDER="$UNIT_SEPARATOR_CHAR"
	seeking_commit_msgs=()
	commit_scan_counter=0
	# Iterate over all git log entries
	git log --pretty=format:"%H${LOG_DIVIDER}%s" | while read line
	do
		# Check if we already at limit and need to bail out
		commit_scan_counter=$((commit_scan_counter+1))
		if [[ $commit_scan_counter -gt $MAX_PAST_COMMITS_TO_SCAN_PER_FIXUP ]]; then
			echo "Could not find the ultimate fixup base, and limit of $MAX_PAST_COMMITS_TO_SCAN_PER_FIXUP scan commits reached"
			echo "Still seeking / could not find within limit:"
			printf "\t%s\n" "$(declare -p seeking_commit_msgs)"
			return 1
		fi

		# Extract out commit hash and message from git log line
		commit_hash=$(echo "$line" | awk -F"$LOG_DIVIDER" '{ print $1 }')
		commit_msg=$(echo "$line" | awk -F"$LOG_DIVIDER" '{ print $2 }')

		# Is this a `fixup! {original message}` commit?
		if [[ "$commit_msg" == "fixup! "* ]]; then
			# Add message, without `fixup! ` prefix, to search list
			target_commit_msg=${commit_msg#"fixup! "}
			seeking_commit_msgs+=("$target_commit_msg")

			# Reset the scan counter, so we can search x num past this new point
			commit_scan_counter=0
		elif [[ ${#seeking_commit_msgs[@]} -gt 0 ]]; then
			# Remove all fixups that fix this commit
			holes_count=0
			for ((i=0; i<${#seeking_commit_msgs[@]}; i++)); do
				if [[ ${seeking_commit_msgs[$i+$ARRAY_INDEX_START]} == "$commit_msg" ]]; then
					unset -v 'seeking_commit_msgs[$i+$ARRAY_INDEX_START]'
					holes_count=$((holes_count+1))
				fi
			done

			# Are we done yet?
			if [[ $holes_count -eq ${#seeking_commit_msgs[@]} ]]; then
				echo "${commit_hash}~1"
				return 0
			fi

			# Remove holes / sparse -> dense
			# Not double-quoting this is the easiest way to do this without
			# accidentally leaving empty strings
			# shellcheck disable=SC2128
			# shellcheck disable=SC2206
			seeking_commit_msgs=($seeking_commit_msgs)
		fi
	done
}


# Returns the git SHA base of HEAD and default trunk
git_find_merge_base() {
	git merge-base HEAD "$(git_trunk_branch_remote)"
}



git_find_github_pr() {
	SHA=$1
	gh pr list --search "$SHA"
}

# Useful internal util for accepting either `$1` as PR base,
# if supplied, else guessing that user wanted the default remote + trunk
_git_pr_base() {
	local TARGET_REF="$1"
	if [[ -z $TARGET_REF ]]; then
		TARGET_REF="$(git_trunk_branch_remote)"
	fi
	echo "$TARGET_REF"
}

git_diff_pr() {
	git diff "$(_git_pr_base "$1")...HEAD"
}

# TODO: I don't think this is quite right...
git_log_pr() {
	git log --cherry-pick --right-only "$(_git_pr_base "$1")...HEAD"
}

# TODO: Blergh
git_squash_diff_log() {
	:
}

# Use this with `--fixup` commits, to auto-target the last commit before fixup
# with interactive rebase
# Options:
#	(flag) `--editor`: Don't skip the editor (_DO_ stop on editor)
git_auto_rebase() {
	local skip_editor=$([[ $* == *--editor ]] && echo "false" || echo "true")
	local new_target_base=$(git_find_fixup_base)

	if [[ $? -ne 0 ]]; then
		echo "$new_target_base"
		echo "Could not auto-find new base. Cancelling auto-rebase"
		return 1
	fi

	while true; do
		echo "Found target base:"
		printf "\t%s\n" "$new_target_base"
		printf "\t%s\n Target Base = " "$(git show --no-patch --oneline "$new_target_base" | cat)"
		printf "Continue? [Yy]es / ENTER, [Nn]o, [Cc]ancel\n"
		read -r answer
		case $answer in
			[Yy]*) break ;;
			"") break ;;
			[Nn]*) return 0 ;;
			[Cc]*) return 0 ;;
		esac
	done

	local git_version=$(git --version | grep -E -o "\d+\.\d+.\d+$")

	if [[ "$skip_editor" != "true" ]]; then
		git rebase --autosquash --interactive "$new_target_base"
		return
	fi

	# New in git 2.44 - auto-squash support in non-interactive mode
	if [[ $(parse_version_string "$git_version") -ge $(parse_version_string "2.44") ]]; then
		git rebase --autosquash "$new_target_base"
	else
		# Use `GIT_SEQUENCE_EDITOR=true` to skip editor
		GIT_SEQUENCE_EDITOR=true git rebase --autosquash --interactive "$new_target_base"
	fi

}


git_branch_name() {
	git rev-parse --abbrev-ref HEAD
}

# WARNING: This errors if no corresponding tag can be found
git_tag_name() {
	git describe --tags --abbrev=0
}

# NOTE: This returns the remote branch name, prefixed with the name of the remote itself
# E.g.
#	`origin/my-branch`
git_remote_branch() {
	# https://stackoverflow.com/a/9753364/11447682
	git for-each-ref --format='%(upstream:short)' "$(git symbolic-ref -q HEAD)"
}

git_remote_url() {
	git remote get-url origin
}

git_branch_backup() {
	# Default to current branch
	local branch_to_backup=$(git rev-parse --abbrev-ref HEAD)
	# Check if a different branch, other than the current, was specified to backup
	if [[ -n "$1" ]]; then
		if (git branch | grep --silent "$1"); then
			branch_to_backup="$1"
		else
			echo "Branch $1 does not exist"
			return 1
		fi
	fi
	backup_branch_name="backup/$branch_to_backup--$(date '+%Y-%m-%d--%I-%M-%p')"
	git branch "$branch_to_backup" "$backup_branch_name"
	echo "✅ Backed up branch $branch_to_backup to $backup_branch_name"
}
alias git_backup_branch="git_branch_backup"

git_checkout_dirty() {
	target_branch_name=$1
	operation="git checkout $target_branch_name"
	git_do_while_dirty "$operation"
}
if [[ $SHELL_TYPE == "ZSH" ]]; then
	:
	# TODO: This is close, but not working perfectly
	# compdef _git git_checkout_dirty=git-checkout
fi

git_sparse_checkout() {
	local OUT_DIR=""
	local REMOTE=""
	local BRANCH=""
	local SUB_PATHS=()

	while [[ ! $# -eq 0 ]]
	do
		case "$1" in
			-o|--out-dir)
				OUT_DIR=$2
				shift
				;;
			-r|--remote)
				REMOTE=$2
				shift
				;;
			-b|--branch)
				BRANCH=$2
				shift
				;;
			*)
				SUB_PATHS+=("$1")
				shift
				;;
		esac
		shift
	done

	local ERR=0
	if [[ -z "$REMOTE" ]]; then
		echo "You must specify the remote URL / source (-r / --remote)"
		ERR=1
	fi
	if [[ -z "$OUT_DIR" ]]; then
		echo "You must specify the destination directory (-o / --out-dir)"
		ERR=1
	fi
	[[ $ERR -eq 1 ]] && return 1

	local GIT_ARGS=(clone --filter=blob:none --no-checkout --depth 1)
	if [[ -n "$BRANCH" ]]; then
		GIT_ARGS+=(--branch "$BRANCH")
	fi
	GIT_ARGS+=(--sparse)

	# Clone into out_dir and cd to it
	git "${GIT_ARGS[@]}" "$REMOTE" "$OUT_DIR"
	pushd "$OUT_DIR" || exit

	# Selectively add the sub paths
	for sub_path in "${SUB_PATHS[@]}"; do
		git sparse-checkout add "$sub_path"
	done
	git checkout
	popd || exit
}

# TODO: would be nice if this could separately stash dropped changes (even if just in a patch file)
git_do_while_dirty() {
	git_operation="$*"
	IFS=

	# If no operation was provided, default to very last command
	if [[ -z "$git_operation" ]]; then
		git_operation=$(fc -ln -1)
		echo "No command passed. Did you want to retry your last command?"
		printf "\t%s\n" "$git_operation"
		while true; do
			printf "Retry? [Yy]es / ENTER, [Nn]o, [Cc]ancel\n"
			read -r answer
			case $answer in
				[Yy]*) break ;;
				"") break ;;
				[Nn]*) return 0 ;;
				[Cc]*) return 0 ;;
			esac
		done
	fi


	# If user forgot to include `git`, add it for them. E.g., passing `pull` instead of `git pull`
	if [[ $git_operation != git* ]]; then
		git_operation="git $git_operation"
	fi

	echo "Operation to try = '$git_operation'"

	# Error out when command is NOT run from root of git repo, as this can cause issues with things
	# like `git checkout ${PATHSPEC}`, as the paths git's stdout uses are relative to repo root,
	# even if you running command from subdirectory
	git_root=$(git rev-parse --show-toplevel)
	if [[ "$git_root" != "$PWD" ]]; then
		echo "ERROR: You are not running this command from the root of a git repository"
		echo "This can cause issues with things like \`git checkout\`, as the paths git's stdout"
		echo "uses are relative to repo root, even if you running command from subdirectory"
		echo "Current directory: $PWD"
		echo "Git root: $git_root"
		return 1
	fi

	git_operation_results=$($SHELL -c "$git_operation" 2>&1)

	# If operation was clean, nothing to do
	error_string_test=$(echo "$git_operation_results" | grep -E "error: Your local changes to the following files would be overwritten by")

	# TODO: Add check for `error: The following untracked working tree files would be overwritten by merge:`

	echo "$error_string_test"
	if [[ "$error_string_test" == "" ]]; then
		echo "✅🚀 Operation was clean"
		return 0
	fi

	# Get list of conflicting file paths
	dirty_files=$(echo "$git_operation_results" | grep -E -o "^[[:blank:]]+.*" | sed -e 's/^[[:space:]]*//')
	cat << EOF
========= DIRTY FILES =========
$dirty_files
===============================
EOF

	# Use stash to temporarily stash changes
	# Newer versions of git can support stashing just staged changes
	use_staged_stash=false
	git_version=$(git --version | grep -E -o "\d+\.\d+.\d+")
	if [[ $(parse_version_string "$git_version") -ge $(parse_version_string "2.35") ]]; then
		echo "Found git version >= 2.3"
		echo "💡 Your git version supports staged stashes."
		use_staged_stash=true
	else
		while true; do
			printf "⚠️ Your git version does NOT support staged stashes. Continue? [Yy]es / ENTER, [Nn]o, [Cc]ancel\n"
			read -r answer
			case $answer in
				[Yy]*) break ;;
				"") break ;;
				[Nn]*) return 0 ;;
				[Cc]*) return 0 ;;
			esac
		done
	fi

	ITEMS_PRESERVED=0
	# Go through list of conflicting files and ask what the user wants to do
	preserve="unsure"
	# different fd (`<&9`) is to avoid conflict with inner `read`
	# https://stackoverflow.com/q/6911520/11447682
	while IFS= read -r dirty_file <&9; do
		if [[ $preserve == "unsure" ]]; then
			while true; do
				# Ask user what to do about this (and rest) of files
				printf "❔ Keep changes to %s?\n" "$dirty_file"
				printf "[Aa]ll files, [Yy]es / ENTER, [Nn]o, / [Dd]rop+rest, [Pp]review, [Cc]ancel\n"
				read -r answer
				case $answer in
					[Aa]*) preserve="all" && break ;;
					[Yy]*) preserve="yes" && break ;;
					"") break ;;
					[Nn]*) preserve="no" && break ;;
					[Dd]*) preserve="none" && break ;;
					[Pp]*) git diff "$dirty_file" ;;
					[Cc]*) return 0 ;;
				esac
			done
		fi

		if [[ $preserve == "none" ]]; then
			git checkout "$dirty_file"
		elif [[ $preserve == "all" ]]; then
			git add "$dirty_file"
			ITEMS_PRESERVED=$((ITEMS_PRESERVED+1))
		else
			if [[ $preserve == "yes" ]]; then
				git add "$dirty_file"
				ITEMS_PRESERVED=$((ITEMS_PRESERVED+1))
			else
				git checkout "$dirty_file"
				# There is an edge-case where this can fail; if the file that is conflicting
				# is a previously / currently untracked file, but the upstream is now tracking
				# it / has added it, then `git checkout file` will not work, because it isn't
				# in git to begin with, but at the same time, you can't git pull if it now
				# exists in the upstream.
				# In this scenario, [...] TODO
			fi
			# Reset for next go-around
			preserve="unsure"
		fi
	done 9<<< "$dirty_files"

	if [[ $ITEMS_PRESERVED -gt 0 ]]; then
		if [[ $use_staged_stash == "true" ]]; then
			git stash --staged
			# TODO
			# git stash --staged -m "TODO gen message"
		else
			git stash
		fi
	fi

	# Actually do the thing
	$SHELL -c "$git_operation"

	if [[ $ITEMS_PRESERVED -gt 0 ]]; then
		git stash pop
	fi
}

# You can use this to delete branch names nested under a slash (or other patterns)
#	Example: `git_branch_delete_pattern feature-a/tmp/*`
git_branch_delete_pattern() {
	git_branch_pattern=$1
	matching_branches=$(git branch --list "$git_branch_pattern")
	echo "This will delete the following branches"
	echo "$matching_branches"
	hard_delete=0
	while true; do
		printf "Are you sure? [Yy]es / ENTER, [Hh]ard delete, [Cc]ancel / [Nn]o\n"
		read -r answer
		case $answer in
			[Yy]*) break ;;
			[Hh]*) hard_delete=1 && break ;;
			"") break ;;
			[Cc]*) return 0 ;;
			[Nn]*) return 0 ;;
		esac
	done
	if [[ $hard_delete == 1 ]]; then
		echo "$matching_branches" | xargs git branch -D
		return 0
	fi
	echo "$matching_branches" | xargs git branch -d
}

git_stats() {
	git fetch
	local CURRENT_BRANCH=$(git_branch_name)
	local REMOTE_BRANCH=$(git_remote_branch)
	local TRUNK_BRANCH=$(git_trunk_branch)
	local trunk_diff_stats=$(git diff --staged --stat "origin/$TRUNK_BRANCH" | tail -n 1)

	local remote_diff_stats=""
	if [[ -n "$REMOTE_BRANCH" ]]; then
		remote_diff_stats=$(git diff --stat "$REMOTE_BRANCH" | tail -n 1)
	else
		REMOTE_BRANCH="(UNSET)"
		remote_diff_stats="NA"
	fi

	cat <<- EOF
		+=====================================================================================
		|                                      |
		|   .oooooo.     ooooo  ooooooooooooo  |  Branch = $CURRENT_BRANCH
		|  d8P'   Y8b     888   8    888    8  |  Trunk Branch = $TRUNK_BRANCH
		|  888            888        888       |    Trunk Diff Stats = $trunk_diff_stats
		|  888            888        888       |  Remote Branch = ${REMOTE_BRANCH}
		|  888     ooooo  888        888       |    Remote Diff Stats = ${remote_diff_stats}
		|  .88.    .88'   888        888       |    Behind / Ahead =
		|  .Y8bood8P.    o888o      o888o      |      Behind | Ahead
		|                                      |         $(git_behind_ahead_plain)
		|                                      |
		+=====================================================================================
	EOF
}

# Display most touched and/or most recently touched
git_heatmap() {
	echo "TODO"
}

# Get information about the state of things while stopped during a rebase
git_rebase_info() {
	# TODO
	:
}

git_tree_view() {
	ALL=1
	while true; do
		printf "What to show? [Aa]ll / ENTER, Current [Bb]ranch\n"
		read -r answer
		case $answer in
			[Aa]*) break ;;
			"") break ;;
			[Bb]*) ALL=0 && break ;;
			[Cc]*) return 0 ;;
		esac
	done
	if [[ $ALL == 1 ]]; then
		git log --graph --oneline --decorate --all
	else
		git log --graph --oneline --decorate
	fi
}


# Program to pack an entire repo, WITH TRACKING, into a single compressed tarball.
# Supports git LFS!
# To use, unpack and then git clone the unpacked dir
git_pack_to_tarball_with_tracking() {
	local ARCHIVE_PATH="$1"
	local TRUNK_BRANCH=$(git_trunk_branch)

	# Error out when command is NOT run from root of git repo, as this tends to complicate things
	local git_root=$(git rev-parse --show-toplevel)
	if [[ "$git_root" != "$PWD" ]]; then
		echo "ERROR: You are not running this command from the root of a git repository"
		echo "Current directory: $PWD"
		echo "Git root: $git_root"
		return 1
	fi

	# If ARCHIVE_PATH was not specified, default to repo / project name, plus hash, plus ext
	if [[ -z "$ARCHIVE_PATH" ]]; then
		ARCHIVE_PATH="$(project_name_normalized)___$(git_sha_full).tar.gz"
		echo "Defaulting output filename to $ARCHIVE_PATH"
	fi
	local ARCHIVE_NAME=$(basename "$ARCHIVE_PATH")

	local TMP_DIR=$(mktemp -d)
	echo "🔗 Temp dir for bundling = $TMP_DIR"

	echo "At a minimum, there are $(git ls-files | wc -l) files to clone and pack"
	local HAS_LFS_FILES=0

	if (git_has_lfs_files); then
		echo "📎 Git LFS files detected"
		HAS_LFS_FILES=1
	fi

	# For backing up source code PLUS actual git history (`.git`) our options are actually pretty limited,
	# because
	# - `git archive` only archives files based on `.gitignore`; does not include `.git` objects
	# - `git bundle` does include git objects, but does not work well with git LFS (which we use for large files)
	# So, instead use "bare" repo folders to clone
	local BARE_REPO_DIR_NAME=$(git_repo_name_normalized)
	local BARE_REPO_DIR_PATH="$TMP_DIR/$BARE_REPO_DIR_NAME"
	mkdir -p "$BARE_REPO_DIR_PATH"
	local GIT_BARE_REMOTE_PATH="file://$TMP_DIR/$BARE_REPO_DIR_NAME"
	pushd "$BARE_REPO_DIR_PATH" || exit
	echo "🏗️ Initializing temp bare repository"
	git init --bare
	popd || exit

	git remote add git-bare-clone "$GIT_BARE_REMOTE_PATH"

	if [[ $HAS_LFS_FILES -eq 1 ]]; then
		echo "🔁 Making sure LFS is up-to-date"
		git lfs fetch --all
	fi

	echo "💾 Cloning to temp bare repo..."
	git push git-bare-clone "$TRUNK_BRANCH"

	if [[ $HAS_LFS_FILES -eq 1 ]]; then
		echo "  ↳ 💾 Pushing LFS objects to temp bare clone"
		git lfs push --all git-bare-clone
	fi

	local UNPACKED_SIZE=$(du -hs "$TMP_DIR/$BARE_REPO_DIR_NAME" | awk '{print $1}')

	# Perform auto-sync of remote ref, so we don't run into this:
	# `warning: remote HEAD refers to nonexistent ref, unable to checkout`
	# https://stackoverflow.com/a/15631690/11447682
	pushd "$BARE_REPO_DIR_PATH" || exit
	local BARE_HEAD_REF=$(git symbolic-ref HEAD)
	if ! [[ -f "$BARE_HEAD_REF" ]]; then
		cat <<- EOF
		=== 🚨 WARNING 🚨 ===
		Could not find a HEAD ref of $BARE_HEAD_REF in the bare repo.
		    Auto-patching to match $TRUNK_BRANCH.
		=====================
		EOF
		git symbolic-ref HEAD refs/heads/"$TRUNK_BRANCH"
	fi
	popd || exit

	# Detach
	git remote remove git-bare-clone
	# Pack
	echo "🔎 Unpacked dirname will be $BARE_REPO_DIR_NAME"
	echo "📦 Packing into tarball..."
	echo "📦 ..."
	echo "📦 ......"
	echo "📦 ........."
	tar --cd "$TMP_DIR" -czf "$TMP_DIR/git-repository.tar.gz" "$BARE_REPO_DIR_NAME"

	# Move file, cleanup
	echo "💾 Copying tarball to final location"
	mv "$TMP_DIR/git-repository.tar.gz" "$ARCHIVE_PATH"
	local PACKED_SIZE=$(du -hs "$ARCHIVE_PATH" | awk '{print $1}')
	rm -rf "$TMP_DIR"

	local META_INFO_MD=$(cat <<- EOF
	- (Primary) Remote: $(git_remote_url)
	- Trunk Branch:     $TRUNK_BRANCH
	- Has LS Files      $([[ $HAS_LFS_FILES -eq 1 ]] && echo "TRUE" || echo "FALSE")
	- Packed Size:      $PACKED_SIZE
	- Unpacked Size:    $UNPACKED_SIZE
	EOF
	)

	local CLONE_INSTRUCTIONS_MD=$(cat <<- EOF
	# $BARE_REPO_DIR_NAME

	## Instructions for Unpacking and Cloning

	***Shell One-Liner***

	\`\`\`bash
	REPO_TEMP_DIR="\$(mktemp -d)"; tar -xvzf $ARCHIVE_NAME -C "\$REPO_TEMP_DIR"; git clone "file://\$REPO_TEMP_DIR/$BARE_REPO_DIR_NAME" ./where_to_restore_repo_to; rm -rf \$REPO_TEMP_DIR
	\`\`\`

	***Manual Unpacking***

	1. Unpack archive with utility of choice
	2. Run \`git clone \${unpacked_path} \${where_to_restore_repo_to}\`

	## Meta Info

	$META_INFO_MD

	EOF
	)

	local CLONE_INSTRUCTIONS_FIE_PATH="$(dirname "$ARCHIVE_PATH")/${ARCHIVE_NAME}__README.md"
	echo "$CLONE_INSTRUCTIONS_MD" > "$CLONE_INSTRUCTIONS_FIE_PATH"

	echo "✅ Done! Tarball exported and temp dir deleted."
	echo "  ↳ Final Path = $ARCHIVE_PATH"
	echo "     ↳ README      = $CLONE_INSTRUCTIONS_FIE_PATH"
	echo "     ↳ Packed Size = $PACKED_SIZE"
	echo "  ↳ Unpacked name = $BARE_REPO_DIR_NAME"
	echo "     ↳ Unpacked Size = $UNPACKED_SIZE"
}

docker_pick_container_full() {
	local _PRESELECT_ALL="${PRESELECT_ALL:=$(check_args_for_value "--all" "$@" && echo 1 || echo 0)}"
	unset PRESELECT_ALL
	local multi=$([[ -n "$multi" ]] && echo "true" || echo "false")
	# TODO support picking non-active containers
	# TODO add fzf preview (show more details?)
	local container_list=$(docker ps --format "table {{.ID}}\t{{.Image}}\t{{.Names}}")
	local fzf_args=("--header-lines=1" "--reverse")
	if [[ "$multi" == "true" ]] || [[ $_PRESELECT_ALL -eq 1 ]]; then
		fzf_args+=("--multi")
	fi
	if [[ $_PRESELECT_ALL -eq 1 ]]; then
		fzf_args+=("--bind")
		fzf_args+=("load:select-all+clear-query")
	fi
	local container=$(echo "$container_list" | fzf "${fzf_args[@]}")
	if [[ -z "$container" ]]; then
		return 1
	fi
	echo "$container" # ID | Image |  Name
}

docker_pick_container() {
	local container=$(docker_pick_container_full)
	if [[ -z "$container" ]]; then
		return 1
	fi
	local container_id=$(echo "$container" | awk '{print $1}')
	echo "$container_id"
}

docker_pick_image() {
	all_images=$(docker image ls --format "table {{.Repository}}:{{.Tag}}\t{{.ID}}")
	selected_image=$(echo "$all_images" | fzf --height 40% --reverse --header-lines=1)
	if [[ -z "$selected_image" ]]; then
		return 1
	fi
	image_id=$(echo "$selected_image" | awk '{print $2}')
	echo "$image_id"
}
alias docker_image_select="docker_pick_image"

docker_stop() {
	if (check_args_for_value "--all" "$@"); then local PRESELECT_ALL=1; fi
	local containers_str=$(multi=1 PRESELECT_ALL=$PRESELECT_ALL docker_pick_container_full)
	if [[ -z "$containers_str" ]]; then
		return 1
	fi
	while IFS='' read -r line; do containers+=("$line"); done < <(echo "$containers_str")
	for container_line in "${containers[@]}"; do
		local container_id=$(echo "$container_line" | awk '{print $1}')
		local container_name=$(echo "$container_line" | awk '{print $3}')
		echo "Stopping $container_name ($container_id)"
		docker stop "$container_id"
	done
}
alias docker_stop_all="docker_stop --all"

docker_restart() {
	local HARD_RESTART=$([[ $* == *--hard* ]] && echo "true" || echo "false")
	local EXTRA_ARGS=()
	if [[ $* == *--detach* ]]; then
		EXTRA_ARGS+=("-d")
	fi
	local container=$(docker_pick_container_full)
	if [[ -z "$container" ]]; then
		return 1
	fi
	local container_id=$(echo "$container" | awk '{print $1}')
	local container_name=$(echo "$container" | awk '{print $3}')
	echo "Restarting $container_name ($container_id)"

	if [[ "$HARD_RESTART" == "true" ]]; then
		docker stop "$container_id"
		docker start --force-recreate "${EXTRA_ARGS[@]}" "$container_id"
	else
		docker restart "$container_id"
	fi
}

docker_copy_to_container() {
	local host_source="$1"
	local container_destination="${2:="/tmp/"}"
	if [[ -z "$host_source" ]]; then
		echo "No source file specified"
		return 1
	fi
	if [[ ! -e "$host_source" ]]; then
		echo "Source file does not exist"
		return 1
	fi
	[[ -z "$CONTAINER_REF" ]] && local CONTAINER_REF="$(docker_pick_container)"
	if [[ -z "$CONTAINER_REF" ]]; then
		return 1
	fi
	echo "Copying $host_source to $CONTAINER_REF:$container_destination"
	docker cp "$host_source" "$CONTAINER_REF:$container_destination"
}
alias docker_copy="docker_copy_to_container"

# Note: For debugging usage, the new `docker debug` command looks promising,
# but requires a paid plan to use
docker_exec_it() {
	local CONTAINER_REF=$CONTAINER_REF
	if [[ -z "$CONTAINER_REF" ]]; then
		CONTAINER_REF=$(docker_pick_container)
	fi
	if [[ -z "$CONTAINER_REF" ]]; then
		return 1
	fi
	local TARGET_BIN=$1
	if [[ -z "$TARGET_BIN" ]]; then
		TARGET_BIN="bash"
	fi
	if [[ "$TARGET_BIN" == "bash" ]]; then
		# Try first, to see if we should fall back to sh
		docker exec "$CONTAINER_REF" bash --help > /dev/null
		if [[ $? -ne 0 ]]; then
			echo "Falling back to sh, bash not found"
			TARGET_BIN="sh"
		fi
	fi
	docker exec -it "$CONTAINER_REF" "$TARGET_BIN"
}

docker_get_working_dir() {
	CONTAINER_REF=$1
	docker inspect --format='{{json .Config.Labels}}' "$CONTAINER_REF" | jq '.["com.docker.compose.project.working_dir"]'
}

# Pick a small(ish) docker image; useful for various ephemeral purposes
docker_pick_minimal_image_name() {
	select image in "busybox (smallest, no bash)" "alpine (small, no bash)" "debian (w/bash)" "ubuntu (w/bash)" "nektos_act_ubuntu_22_04_slim" "jtz_sandbox (Ubuntu, bash, file, git, utils, etc.)" "arch_linux" "fedora"; do
		case $image in
			# https://hub.docker.com/_/busybox
			busybox*) echo "busybox" && break ;;
			# https://hub.docker.com/_/alpine
			alpine*) echo "alpine" && break ;;
			# https://hub.docker.com/_/debian
			debian*) echo "debian" && break ;;
			# https://hub.docker.com/_/ubuntu
			ubuntu*) echo "ubuntu" && break ;;
			# https://github.com/catthehacker/docker_images
			nektos_act_ubuntu_22_04_slim*) echo "ghcr.io/catthehacker/ubuntu:act-latest" && break ;;
			# ./adockerfiles/ubuntu_sandbox
			jtz_sandbox*) echo "jtz-reg/jtz/ubuntu_sandbox" && break ;;
			# https://hub.docker.com/_/archlinux/
			arch_linux*) echo "archlinux" && break ;;
			# https://hub.docker.com/_/fedora/
			fedora*) echo "fedora" && break ;;
			*) echo "Invalid selection" ;;
		esac
	done
}

docker_sandbox() {
	local shared_dir="$1"
	local used_temp_dir=0
	if ! [[ -d "$shared_dir" ]]; then
		used_temp_dir=1
		shared_dir=$(mktemp -d)
	fi
	docker_inspect_volume "$shared_dir"
	if [[ $used_temp_dir -eq 1 ]]; then
		echo "Deleting temp dir $shared_dir"
		rm -r "$shared_dir"
	fi
}


# Uses a temporary (small) docker container to mount a volume for inspection
docker_inspect_volume() {
	local VOLUME_NAME=$1
	local VOLUME_IS_DIR=0
	if [[ -d "$VOLUME_NAME" ]]; then
		VOLUME_IS_DIR=1
	fi
	if [[ $VOLUME_IS_DIR -eq 0 ]] && ! (docker volume ls | grep "$VOLUME_NAME$" > /dev/null); then
		echo "Volume not found"
		return 1
	fi
	local IMAGE_NAME=$(docker_pick_minimal_image_name)
	local IMAGE_SHELL=$(echo "$IMAGE_NAME" | grep -q -E "busybox|alpine" && echo "sh" || echo "bash")
	cat <<- EOF
		Temp Image = $IMAGE_NAME
		Shell = $IMAGE_SHELL
		Volume = $VOLUME_NAME
		Container Mount = /tmp/volume

		Have fun inspecting!
	EOF
	docker run --rm -it -v "$VOLUME_NAME":/tmp/volume "$IMAGE_NAME" "$IMAGE_SHELL" -c "cd /tmp/volume; exec $IMAGE_SHELL"
}

docker_list_binds() {
	CONTAINER_REF=$(docker_pick_container)
	docker inspect --format='{{json .HostConfig.Binds}}' "$CONTAINER_REF" | jq
}

docker_is_image_available_locally() {
	local IMAGE_REF="$1"
	docker image inspect "$IMAGE_REF" > /dev/null
}

# For docker container names, only "[a-zA-Z0-9][a-zA-Z0-9_.-]" are allowed.
docker_normalize_name_container() {
	local CONTAINER_NAME=$1
	# Replace `:` with `-`
	CONTAINER_NAME="$(echo "$CONTAINER_NAME" | sed -e 's/:/-/g')"
	# For everything else, just remove char entirely
	CONTAINER_NAME="$(echo "$CONTAINER_NAME" | sed -e 's/[^a-zA-Z0-9_.-]//g')"
	echo "$CONTAINER_NAME"
}

docker_image_exec() {
	local image_id=$1
	if [[ -n "$image_id" ]] && ! (echo "$image_id" | grep -q -E "^-"); then
		shift
	else
		image_id=$(docker_pick_image)
	fi
	if [[ -z "$image_id" ]]; then
		return 1
	fi
	local CONTAINER_NAME=$(docker_normalize_name_container "$image_id-$(date_ms)")
	local DOCKER_SHELL="$DOCKER_SHELL"
	if [[ -z $DOCKER_SHELL ]]; then
		DOCKER_SHELL="bash"
	fi
	docker run --name "$CONTAINER_NAME" --rm -it "$@" "$image_id" "/bin/$DOCKER_SHELL"
}
alias docker_exec_image="docker_image_exec"
alias docker_run_image_interactive="docker_exec_image"

# Throwaway container for PostgreSQL
docker_temp_pg() {
	local IMAGE_NAME="postgres:latest"
	local HOST_PORT="5432"
	# Check for already bound
	if (find_pid_by_port "$HOST_PORT"); then
		echo "Port $HOST_PORT is already bound; using randomized port"
		docker_image_exec "$IMAGE_NAME" -p 5432 "$@"
		return 0
	fi
	docker_image_exec "$IMAGE_NAME" -p "$HOST_PORT:5432" "$@"
}

# Execs pg_dump inside a given Docker container, and then copies the backup out
# of the container before deleting
# TODO: Would be cool to rework this to handle a bunch of different DB formats
pg_dump_container() {
	local db_user
	local db_pass
	local db_name
	local container_ref

	while [[ ! $# -eq 0 ]]
	do
		case "$1" in
			-c|--container)
				INSTANCE_ID=$2
				shift
				;;
			-u|--username)
				db_user=$2
				shift
				;;
			-p|--password)
				db_pass=$2
				shift
				;;
			-d|--database)
				db_name=$2
				shift
				;;
			*)
				echo "Invalid option ${1}"
				;;
		esac
		shift
	done

	if [[ -z $container_ref ]]; then
		container_ref=$(docker_pick_container)
		if [[ -z $container_ref ]]; then
			return 1
		fi
	fi

	DUMP_DB_DIR="/tmp/pg_dump_temp"
	DUMP_DB_PATH="${DUMP_DB_DIR}/${db_name}__dump.sql"
	PG_DUMP_SCRIPT=$(cat <<- EOF
	mkdir -p "$DUMP_DB_DIR"
	PGPASSWORD="$db_pass" pg_dump -U $db_user $db_name > "$DUMP_DB_PATH"
	if ! [[ -s $DUMP_DB_PATH  ]]; then
		exit 1
	fi
	EOF
	)
	echo "🚀 Running backup script"
	if ! docker exec "$container_ref" /bin/bash -c "$PG_DUMP_SCRIPT"; then
		echo "🚨 Backup failed"
		return 1
	fi
	echo "💾 Copying backup out of container"
	docker cp "$container_ref:$DUMP_DB_PATH" .
	echo "🗑️ Cleaning up"
	docker exec "$container_ref" /bin/bash -c "rm -f $DUMP_DB_PATH"
}

docker_inspect_image() {
	image_id=$(docker_pick_image)
	docker inspect "$image_id"
}
alias docker_inspect_image_interactive="docker_inspect_image | jless"

docker_inspect_image_init() {
	local image_json=$(docker_inspect_image)
	echo "$image_json" | jq '.[0].Config | {Cmd, Entrypoint}'
}

docker_inspect_container() {
	CONTAINER_REF=$(docker_pick_container)
	docker inspect "$CONTAINER_REF"
}
alias docker_inspect_container_interactive="docker_inspect_container | jless"

docker_inspect_container_init() {
	local CONTAINER_REF=$(docker_pick_container)
	docker inspect "$CONTAINER_REF" | jq '.[0].Config | {Cmd, Entrypoint}'
}

docker_inspect_networks() {
	local combined_network_json=""
	# NOTE: We can't simply use `docker network ls --format json`, because
	# this doesn't output as much info as `docker network inspect`
	local combined_network_json=""
	for docker_network_id in $(docker network ls | sed -r '1d;' | awk '{print $1}'); do
		# Note: `sed` usage is to remove first and last lines, since Docker
		# wraps output in array (`[]`) for some reason
		local network_json=$(docker network inspect "$docker_network_id" | sed -r '1d;$d')
		if [[ $combined_network_json != "" ]]; then
			combined_network_json="${combined_network_json},"
		fi
		combined_network_json="${combined_network_json}${network_json}"
	done
	render_json_as_table "[${combined_network_json}]"
}

docker_log_follow() {
	CONTAINER_REF=$(docker_pick_container)
	docker logs -f "$CONTAINER_REF"
}

run_raw_cmd_in_dotfiles_venv() {
	local RAW_CMD_TO_RUN=$1
	if ! [[ -d "$DOTFILES_DIR" ]]; then
		return 1
	fi
	(
		cd "$DOTFILES_DIR" || exit
		activate || exit
		$SHELL -c "$RAW_CMD_TO_RUN"
	)
}

run_raw_python_in_dotfiles_venv() {
	local RAW_CODE_TO_RUN=$1
	if ! [[ -d "$DOTFILES_DIR" ]]; then
		return 1
	fi
	(
		cd "$DOTFILES_DIR" || exit
		activate || exit
		python3 -c "$RAW_CODE_TO_RUN"
	)
}

ensure_pkg_in_dotfiles_venv() {
	pkg_name="$1"
	echo "Checking if $pkg_name is installed..." 1>&2
	if ! (run_raw_cmd_in_dotfiles_venv "pip show $pkg_name" > /dev/null); then
		echo "$pkg_name is not installed. Would you like to install it in the dotfiles venv? [Yy]es / [Nn]o" 1>&2
		read -r answer
		case $answer in
			[Yy]*)
				run_raw_cmd_in_dotfiles_venv "pip install $pkg_name"
				return 0
				;;
			*)
				return 1
				;;
		esac
	fi

	return 0
}


# In a sub-shell, run a command in different directory, and then switch back
exec_in() {
	if ! [[ -d $1 ]]; then
		echo "Invalid directory ($1)"
		return 1
	fi
	if [[ $# -le 1 ]]; then
		echo "Not enough arguments"
		return 1
	fi
	if ! (
		pushd "$1" > /dev/null || exit
		shift
		$SHELL -c "$*"
		popd > /dev/null || exit
	); then
		return 1
	fi
}

# Find the true global package dir / bin for a brew installed package,
# where `brew --prefix PKG` only returns something like `/usr/local/opt/PKG`
# e.g. `brew_find_global_pkd_dir fzf` -> `/usr/local/Cellar/fzf/0.45.0`
brew_find_global_pkd_dir() {
	PACKAGE_NAME=$1
	readlink -f "$(brew --prefix "$PACKAGE_NAME")"
}

npm_find_npx_global_pkg_dir() {
	PACKAGE_NAME=$1
	find "$HOME/.npm/_npx" -type d -name "$PACKAGE_NAME"
}

# NOTE: This is for packages installed with `-g`, not those installed via npx
# For npx, use `npm_find_npx_global_pkg_dir`, for which each package gets an isolated
# subdir, not a shared node_modules
npm_find_global_node_modules() {
	asdf_exec_with_global_version npm root -g
}

npm_find_global_pkg_dir() {
	PACKAGE_NAME=$1
	GLOBAL_NODE_MODULES=$(npm_find_global_node_modules)
	# Make sure to scan for symlinks as well, to handle `npm link` and friends
	found_dir=$(find -L "$GLOBAL_NODE_MODULES" -type d -depth 1 -name "$PACKAGE_NAME")
	if [[ -z "$found_dir" ]]; then
		echo "ERROR: Could not find $PACKAGE_NAME in global node_modules"
		return 1
	fi
	echo "$found_dir" | head -n 1
}

# Generate an ESM import statement, out of your global node_modules
# Pretty hacky: not many good reasons to use this, other than for fiddling around
# @see run_...in_global_node fns for a slightly better approach (but still hacky / just for fiddling)
scaffold_global_node_import() {
	PACKAGE_NAME=$1
	PACKAGE_DIR=$(npm_find_global_pkg_dir "$PACKAGE_NAME")
	copy_to_clipboard <<- EOF
	import {} from '$PACKAGE_DIR'
	EOF
}

run_file_in_global_node() {
	GLOBAL_NODE_MODULES=$(npm_find_global_node_modules)
	# TODO clean this up with piping?
	FILE_TO_EXEC="$1"
	FILENAME=$(basename "$FILE_TO_EXEC")
	# no-clobber
	cp -n "$FILE_TO_EXEC" "$GLOBAL_NODE_MODULES/"
	# WARNING: This might seem super hacky - why not just use `NODE_PATH=$GLOBAL_NODE_MODULES`?
	# Well, that *would* work, except for that they decided to ignore `NODE_PATH` when
	# moving to ESM `import` 🙃
	# https://nodejs.org/api/esm.html#esm_no_node_path
	(
		cd "$GLOBAL_NODE_MODULES" || exit
		node "$FILENAME"
	)
	rm "$GLOBAL_NODE_MODULES/$FILENAME"
}

run_raw_js_in_global_node() {
	RAW_CODE_TO_RUN=$1
	GLOBAL_NODE_MODULES=$(npm_find_global_node_modules)
	(
		cd "$GLOBAL_NODE_MODULES" || exit
		node --eval "$RAW_CODE_TO_RUN"
	)
}

repl_in_global_node() {
	GLOBAL_NODE_MODULES=$(npm_find_global_node_modules)
	pushd "$GLOBAL_NODE_MODULES" || exit
	node --experimental-repl-await
	popd || exit
}

# Execute a command with the global version of an asdf plugin, regardless of which dir
# you are in.
# @example `asdf_exec_with_global_version node --version`
asdf_exec_with_global_version() {
	# This is kind of hacky, but it works and asdf doesn't provide a "get global version" API
	# https://github.com/asdf-vm/asdf/issues/1340
	(cd /; asdf exec "$@")
	# Note: Above should pass through exit code, so no need to check and re-throw
}

# E.g. `asdf_get_true_path golang``
asdf_get_true_path() {
	asdf where "$1"
}

lint_versions() {
	if ! [[ -f ".tool-versions" ]]; then
		return 1
	fi
	#TODO
}

local_web_server_for_dir() {
	local serve_dir="$PWD"
	if [[ -d $1 ]]; then
		serve_dir=$1
		shift
	fi
	if [[ "$serve_dir" == "." ]]; then
		echo "Do not use '.' as serving directory; it will serve full drive"
		return 1
	fi
	asdf_exec_with_global_version npx local-web-server --directory "$serve_dir" "$@"
}

local_web_server_for_file() {
	local serve_file="$1"
	if ! [[ -f $serve_file ]]; then
		echo "Missing file to serve"
		return 1
	fi
	shift
	asdf_exec_with_global_version npx local-web-server --spa "$serve_file" "$@"
}

# Note to self: you can use `--package` to avoid ambiguity around package name vs bin / entrypoint
npx_exec_global() {
	asdf_exec_with_global_version npx --no-install "$@"
}

npm_ls_global() {
	asdf_exec_with_global_version npm ls -g --depth=0 "$1"
}

find_proc_by_port() {
	local PORT=$1
	lsof -i :"$PORT"
}

find_procs_by_string() {
	local SEARCH_STRING=$1
	if [[ $SLIM -eq 1 ]]; then
		# Form of pgrep -l is `${PID}{SPACE}{CMD}`
		echo $'PID\tCMD'
		# Change space between PID and CMD to tab, but leave the rest alone
		# (CMD can have spaces in it, so we don't want to split on *every* space)
		pgrep -l -f "$SEARCH_STRING" | sed -rn 's/^([0-9]+) (.*)$/\1\t\2/p'
		# Note: If you want to use `awk` with above, use `-F'\t'` to set separator
		return
	fi
	# r = sort by CPU
	# m = sort by memory
	# x = include processes without a controlling terminal (this is most)
	local ps_output=$(ps -x -m -o ruser,pid,ppid,pgid,etime,cpu,%cpu,%mem,command)
	# Headings
	echo "$ps_output" | head -n 1
	# Filtered content
	echo "$ps_output" | tail -n +2 | grep "$SEARCH_STRING" | grep --invert "grep"
}

pick_procs_by_string() {
	local proc_list=$(find_procs_by_string "$1")
	local header_row=$(echo $proc_list | head -n 1)

	# Detect proc list format
	local proc_list_format="ps".
	local pid_column=2
	if [[ $header_row == $'PID\tCMD' ]]; then
		pid_column=1
		proc_list_format="pgrep"
	fi

	# Use FZF to select (drop `user` column)
	# TODO: Add always present preview bar, which shows full un-truncated command entry
	local selected_lines=$(echo "$proc_list" | fzf --header-lines=1 --reverse --multi --with-nth=2.. --sync --bind 'start:select-all')
	if [[ -z "$selected_lines" ]]; then
		return 1
	fi
	echo "$selected_lines" | awk "$(printf '{print $%s}' $pid_column)"
}

find_pid_by_port() {
	local PORT=$1
	lsof -t -i :"$PORT"
}

get_proc_info_by_pid() {
	local PID=$1
	ps -p "$PID" -o pid,ppid,pgid,command
}

get_proc_info_by_port() {
	local PORT=$1
	local PID=$(find_pid_by_port "$PORT")

	if [[ -z "$PID" ]]; then
		echo "No process found on port $PORT"
		return 1
	fi

	get_proc_info_by_pid "$PID"
}

kill_procs_by_pid_interactive() {
	local SELECTED_SIG=$(fzf --reverse <<< "$SIGNALS_PICK_LIST" | awk '{print $1}')
	if [[ -z "$SELECTED_SIG" ]] || [[ "$SELECTED_SIG" == "---" ]]; then
		return 1
	fi
	for PID in "$@"; do
		kill -"$SELECTED_SIG" "$PID"
	done
}

kill_procs_by_port_interactive() {
	local pids=$(find_pid_by_port)
	# TODO display proc pick list, multi-select, before passing to kill
	kill_procs_by_pid_interactive "$pids"
}

kill_procs_by_string_interactive() {
	local MATCHING_PIDS=$(pick_procs_by_string "$@")
	kill_procs_by_pid_interactive "$MATCHING_PIDS"
}

restart_vscode() {
	local CODE_PIDS=$(pick_procs_by_string "Visual Studio Code.app/Contents/MacOS/Electron")
	kill_procs_by_pid_interactive "$CODE_PIDS"
	sleep 10
	code
}

kill_procs_locking_file() {
	local file_path=$1
	if [[ -z "$file_path" ]]; then
		echo "No file_path specified"
		return 1
	fi
	local fuser_output=$(fuser "$file_path")
	# /file/path/string 1234
	# or, if no PID is locking
	# /file/path/string
	# TODO
}

# This is a workaround to tell the task runner that a given task is up-to-date,
# without actually running the task to generate the new fingerprint / checksum.
# Ideally, there would be a way to do this directly via the task cli (e.g. `task --mark-up-to-date`)
# See `scripts/task_mark_up_to_date.mjs` for full details`
task_mark_up_to_date() {
	local TASKFILE_PATH
	TASKFILE_PATH="${TASKFILE_PATH:="$PWD/Taskfile.yml"}"
	local TASK_NAME=$1
	if [[ ! -f "$TASKFILE_PATH" ]]; then
		echo "ERROR: Could not find $TASKFILE_PATH"
		return 1
	fi
	if [[ -z "$TASK_NAME" ]]; then
		echo "ERROR: Please define TASK_NAME"
		return 1
	fi
	TASK_NAME=$TASK_NAME TASKFILE_PATH=$TASKFILE_PATH run_file_in_global_node "$HOME/dotfiles/scripts/task_mark_up_to_date.mjs"
}

# This might seem like a lot of code just to wrap ffmpeg's `scale`, but this:
# - Handles rounding auto-heights to be divisible by 2 (which ffmpeg does not)
# - Picks a `_resized` output filename based on the input
# - Prompts for target width if not provided, from selection
ffmpeg_resize() {
	INPUT_FILE=$1
	TARGET_WIDTH=$2
	INPUT_DIR=$(dirname "$INPUT_FILE")
	INPUT_FILE_EXT=$(basename "$INPUT_FILE" | sed -E 's/^.+(\.[^.]+)$/\1/')
	INPUT_FILE_NO_EXT=$(basename "$INPUT_FILE" | sed -E 's/\.[^.]+$//')
	: "${OUTPUT_FILE:="$INPUT_FILE_NO_EXT"_resized"$INPUT_FILE_EXT"}"

	# If target width, not provided, use choices
	if [[ -z "$TARGET_WIDTH" ]]; then
		printf "What should the target width be?\n\t[Aa])1920\n\t[Bb])1280\n\t[Cc])720\n\t[Dd])480\n"
		read -r answer
		case $answer in
			A|a) TARGET_WIDTH=1920 ;;
			B|b) TARGET_WIDTH=1280 ;;
			C|c) TARGET_WIDTH=720 ;;
			D|d) TARGET_WIDTH=480 ;;
			*) echo "Invalid selection" && return 1 ;;
		esac
	fi

	# Get width and height of input file
	INPUT_DIMENSIONS=$(ffprobe -v error -select_streams v -show_entries stream=width,height -of csv=p=0:s=x "$INPUT_FILE")
	print "INPUT_DIMENSIONS = $INPUT_DIMENSIONS"
	if ! TARGET_HEIGHT=$(INPUT_DIMENSIONS=$INPUT_DIMENSIONS TARGET_WIDTH=$TARGET_WIDTH node <<- "EOF"
	const regPatt = /(?<width>\d+)x(?<height>\d+)/i;
	const INPUT_DIMENSIONS = /** @type {`${string}x${string}`} */ (process.env.INPUT_DIMENSIONS);
	const TARGET_WIDTH = parseInt(process.env.TARGET_WIDTH);

	if (!regPatt.test(INPUT_DIMENSIONS)) {
		throw new Error(`Invalid input dimensions (${INPUT_DIMENSIONS})`);
	}

	if (Number.isNaN(TARGET_WIDTH)) {
		throw new Error(`Invalid target width (${TARGET_WIDTH})`);
	}

	const {
		groups: { width: _width, height: _height },
	} = regPatt.exec(INPUT_DIMENSIONS);
	const width = parseInt(_width);
	const height = parseInt(_height);

	let targetHeight = (TARGET_WIDTH * height) / width;

	// Handle rounding auto-heights to be divisible by 2
	if (targetHeight % 2 !== 0) {
		const roundedTargetHeight = Math.round(targetHeight / 2) * 2;
		console.warn(`Rounding auto-height to be divisible by 2: ${targetHeight} -> ${roundedTargetHeight}`);
		targetHeight = roundedTargetHeight;
	}

	console.log(targetHeight);
	EOF
	); then
		echo "ERROR: Could not parse input dimensions"
		return 1
	fi


	echo "Resizing $INPUT_FILE to $TARGET_WIDTH pixels wide (out = $INPUT_DIR/$OUTPUT_FILE)"
	ffmpeg -loglevel warning -stats -i "$INPUT_FILE" -vf scale="$TARGET_WIDTH:$TARGET_HEIGHT" "$INPUT_DIR/$OUTPUT_FILE"
	echo "Rendered to $INPUT_DIR/$OUTPUT_FILE"
	echo "✅ Done"
}

px_from_rem() {
	REM=$1
	echo "$((16 * REM))"
}

rem_from_px() {
	PX=$1
	echo "$((PX / 16))"
}

curl_post_json_file() {
	URL=$1
	JSON_FILE_PATH=$2
	if ! [[ -f $JSON_FILE_PATH ]]; then
		echo "ERROR: Could not find JSON file at $JSON_FILE_PATH"
		return 1
	fi
	shift 2
	curl -X POST -H "Content-Type: application/json" -d @"$JSON_FILE_PATH" "$@" "$URL"
}

aws_list_profiles() {
	aws configure list-profiles
}

aws_ec2_instance_get_public_dns_addr() {
	aws ec2 describe-instances --instance-ids "$1" --query 'Reservations[*].Instances[*].[PublicDnsName]' --output text
}

aws_pick_default_ec2_username() {
	# TODO present options of ec2-user, ubuntu, etc.
	# use fzf
	:
}

aws_lint_instance_id() {
	local INSTANCE_ID=$1
	if ! [[ $INSTANCE_ID =~ ^i-[a-z0-9]+$ ]]; then
		echo "Invalid instance ID format. Should be I-123abc455 (found $INSTANCE_ID)"
		return 1
	fi
	return 0
}

# Connect to an AWS EC2 Instance, via instance-connect
# Remember: You can use`AWS_PROFILE=${name}` to set the AWS credential profile
# to use for all the AWS commands
aws_ec2_instance_connect_send_pub_key() {
	local PUBLIC_KEY
	local INSTANCE_ID
	local EC2_USERNAME
	while [[ ! $# -eq 0 ]]
	do
		case "$1" in
			-i|--instance-id)
				INSTANCE_ID=$2
				shift
				;;
			-u|--user|--username)
				EC2_USERNAME=$2
				shift
				;;
			-pub|--public-key)
				PUBLIC_KEY=$2
				shift
				;;
			*)
				echo "Invalid option ${1}"
				;;
		esac
		shift
	done

	if ! (which aws > /dev/null); then
		echo "ERROR: AWS CLI not found"
		return 1
	fi

	if [[ -z "$INSTANCE_ID" ]]; then
		echo "You must pass instance ID with '--instance-id' or '-i'"
		return 1
	fi
	aws_lint_instance_id "$INSTANCE_ID" || return 1

	if [[ -z "$EC2_USERNAME" ]]; then
		echo "You did not specify a username with '--user' / '--username'"
		echo "Please pick a username, or re-run command with specific username to use"
		if ! EC2_USERNAME=$(aws_pick_default_ec2_username); then
			return 1
		fi
	fi

	if ! [[ -f $PUBLIC_KEY ]]; then
		echo "ERROR: Could not find public and/or private key"
		return 1
	fi

	# Send public key
	aws ec2-instance-connect \
		send-ssh-public-key \
			--no-paginate \
			--instance-id "$INSTANCE_ID" \
			--instance-os-user "$EC2_USERNAME" \
			--ssh-public-key "file://${PUBLIC_KEY}" | cat > /dev/null

	if [[ $? -ne 0 ]]; then
		echo "ERROR: Could not send public key"
		return 1
	fi
}

# WARNING: Because this function is intended to be used with command substitution
# you need to ***VERY*** careful not to send to stdout within the function,
# except for the very last echo of the generated private key.
# Either use stderr, or another fd other than stdout
aws_ec2_instance_connect_send_pub_key_temp() {
	local INSTANCE_ID=""
	local EC2_USERNAME=""
	local SSH_CONFIG_ALIAS=""
	# 60 seconds is the limit after which the key is removed on the server
	local DELETE_LOCAL_KEY_DELAY_SEC=60
	local MODIFY_SSH_CONFIG=1

	while [[ ! $# -eq 0 ]]
	do
		case "$1" in
			-i|--instance-id)
				INSTANCE_ID=$2
				shift
				;;
			-u|--user|--username)
				EC2_USERNAME=$2
				shift
				;;
			-d|--delay|--delete-delay)
				DELETE_LOCAL_KEY_DELAY_SEC=$2
				shift
				;;
			-a|--alias)
				SSH_CONFIG_ALIAS=$2
				shift
				;;
			-n|--no-modify-config)
				MODIFY_SSH_CONFIG=0
				;;
			*)
				echo "Invalid option ${1}"
				return 1
				;;
		esac
		shift
	done

	if [[ -z "$INSTANCE_ID" ]]; then
		echo "Error: You must pass instance ID with '--instance-id' or '-i'"
		return 1
	fi
	aws_lint_instance_id "$INSTANCE_ID" || return 1

	if [[ -z "$SSH_CONFIG_ALIAS" ]]; then
		SSH_CONFIG_ALIAS="$INSTANCE_ID"
	fi

	if [[ -z "$EC2_USERNAME" ]]; then
		echo "Warning: You didn't specify EC2 username. Defaulting to 'ubuntu'" 1>&2
		EC2_USERNAME="ubuntu"
	fi

	echo "🔐 Generating temporary key pair" 1>&2
	local tmp_dir=$(mktemp -d)
	ssh-keygen -t rsa -b 4096 -C "TEMPORARY key for EC2 Instance Connect" -N "" -f "$tmp_dir/tmp_key" 1>&2
	PRIVATE_KEY="$tmp_dir/tmp_key"
	PUBLIC_KEY="$tmp_dir/tmp_key.pub"

	echo "⬆️ Attempting sending of public key" 1>&2
	if ! (aws_ec2_instance_connect_send_pub_key --instance-id "$INSTANCE_ID" --username "$EC2_USERNAME" --public-key "$PUBLIC_KEY"); then
		return 1
	fi

	local DNS_ADDR="?"

	local SSH_CONFIG_UPDATED_ICON="❌"
	if [[ $MODIFY_SSH_CONFIG -eq 1 ]]; then
		DNS_ADDR=$(aws_ec2_instance_get_public_dns_addr "$INSTANCE_ID")
		if [[ -z "$DNS_ADDR" ]]; then
			echo "Cannot update SSH config without knowing hostname" 1>&2
			return 1
		fi
		echo "Adding entry (alias = $SSH_CONFIG_ALIAS) to ~/.ssh/config" 1>&2
		if ! (manssh add "$SSH_CONFIG_ALIAS" "${EC2_USERNAME}@${DNS_ADDR}" -i "$PRIVATE_KEY" 1>&2); then
			echo "Error: Failure updating SSH config via manssh"
			return 1
		fi

		SSH_CONFIG_UPDATED_ICON="✅"
	fi

	# Return private key path, and then delete after very short delay
	# We are assuming that caller is going to use private key very shortly after
	# generating
	cat 1>&2 << EOF
========
Private key-pair is ready for use.
    Host: $DNS_ADDR
    SSH Config Updated?: $SSH_CONFIG_UPDATED_ICON
    Dir: $(dirname $PRIVATE_KEY)
        Private key: $PRIVATE_KEY
        Public key: $PRIVATE_KEY.pub
    Auto-delete after: $DELETE_LOCAL_KEY_DELAY_SEC seconds.
========
EOF
	echo "$PRIVATE_KEY"
	{
		sleep "$DELETE_LOCAL_KEY_DELAY_SEC"
		echo $'\n========\n🗑️ Deleting temporary key pair' 1>&2
		rm -r "$tmp_dir"
		echo $'✅ Successfully deleted temporary key pair\n========\n' 1>&2

		if [[ $MODIFY_SSH_CONFIG -eq 1 ]]; then
			printf $'\n========\n🗑️ Removing entry (alias = %s) from ~/.ssh/config' "$SSH_CONFIG_ALIAS" 1>&2
			manssh delete "$SSH_CONFIG_ALIAS" 1>&2
			echo $'\n✅ Successfully removed entry from SSH config\n========\n' 1>&2
		fi
	} > /dev/null &
}

aws_ec2_instance_connect_generate_temp_ssh_command() {
	local INSTANCE_ID=""
	local EC2_USERNAME="ec2-user"
	local PORT_BINDINGS=()
	local OPEN_VS_CODE=0
	local EXEC_COMMAND=0

	while [[ ! $# -eq 0 ]]
	do
		case "$1" in
			-i|--instance-id)
				INSTANCE_ID=$2
				shift
				;;
			-u|--user|--username)
				EC2_USERNAME=$2
				shift
				;;
			-p|--port)
				PORT_BINDINGS+=("$2")
				shift
				;;
			-c|--code)
				OPEN_VS_CODE=1
				;;
			-e|--exec)
				EXEC_COMMAND=1
				;;
			*)
				echo "Invalid option ${1}"
				;;
		esac
		shift
	done

	if [[ -z "$INSTANCE_ID" ]]; then
		echo "You must pass instance ID with '--instance-id' or '-i'"
		return 1
	fi
	aws_lint_instance_id "$INSTANCE_ID" || return 1

	local DELETE_DELAY=10
	if [[ $OPEN_VS_CODE -eq 1 ]]; then
		DELETE_DELAY=60
	fi
	local PRIVATE_KEY=$(aws_ec2_instance_connect_send_pub_key_temp --user "$EC2_USERNAME" --instance-id "$INSTANCE_ID" --delete-delay "$DELETE_DELAY")

	if [[ $? -ne 0 ]] || [[ $PRIVATE_KEY == "Error"* ]]; then
		echo "Failed to generate private key: $PRIVATE_KEY"
		return 1
	fi

	local SSH_ARGS=(-o ServerAliveInterval=20 -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -i "$PRIVATE_KEY")
	if [[ ${#PORT_BINDINGS[@]} -gt 0 ]]; then
		for PORT_BINDING in "${PORT_BINDINGS[@]}"; do
			# If port binding is of form \d+, use same port locally
			if (echo "$PORT_BINDING" | grep -E --silent '^\d+$'); then
				SSH_ARGS+=(-L "\*:${PORT_BINDING}:localhost:${PORT_BINDING}")
			elif (echo "$PORT_BINDING" | grep -E --silent '^\d+:\d+$'); then
				local REMOTE_PORT=$(echo "$PORT_BINDING" | cut -d':' -f1)
				local LOCAL_PORT=$(echo "$PORT_BINDING" | cut -d':' -f1)
				SSH_ARGS+=(-L "\*:${REMOTE_PORT}:localhost:${LOCAL_PORT}")
			else
				echo "Could not understand how to bind port input of $PORT_BINDING"
				return 1
			fi
		done
	fi

	local DNS_ADDR=$(aws_ec2_instance_get_public_dns_addr "$INSTANCE_ID")
	SSH_ARGS+=("${EC2_USERNAME}@${DNS_ADDR}")

	echo "ssh ${SSH_ARGS[*]}"

	if [[ $OPEN_VS_CODE -eq 1 ]]; then
		echo "Launching vscode"
		code --folder-uri "vscode-remote://ssh-remote+$INSTANCE_ID/"
	fi

	if [[ $EXEC_COMMAND -eq 1 ]]; then
		ssh "${SSH_ARGS[@]}"
	fi
}

aws_ec2_instance_connect_ssh() {
	local INSTANCE_ID=""
	local SSH_CONFIG_ALIAS=""
	local EC2_USERNAME="ec2-user"
	local USE_TEMP_KEY_PAIR=0
	local USE_DEFAULT_KEY_PAIR=0
	local PORT_BINDINGS=()
	local PRIVATE_KEY=""
	local PUBLIC_KEY=""
	while [[ ! $# -eq 0 ]]
	do
		case "$1" in
			-i|--instance-id)
				INSTANCE_ID=$2
				shift
				;;
			-u|--user|--username)
				EC2_USERNAME=$2
				shift
				;;
			-p|--port)
				PORT_BINDINGS+=("$2")
				shift
				;;
			-pk|--private-key)
				PRIVATE_KEY=$2
				shift
				;;
			-pub|--public-key)
				PUBLIC_KEY=$2
				shift
				;;
			-dkp|--default-key-pair)
				USE_DEFAULT_KEY_PAIR=1
				shift
				;;
			-a|--alias)
				SSH_CONFIG_ALIAS=$2
				shift
				;;
			*)
				echo "Invalid option ${1}"
				;;
		esac
		shift
	done

	if [[ -z "$INSTANCE_ID" ]]; then
		echo "You must pass instance ID with '--instance-id' or '-i'"
		return 1
	fi
	aws_lint_instance_id "$INSTANCE_ID" || return 1

	local tmp_dir
	if ! [[ -f $PUBLIC_KEY ]] || ! [[ -f $PRIVATE_KEY ]]; then
		if [[ $USE_DEFAULT_KEY_PAIR -eq 1 ]]; then
			PRIVATE_KEY="$HOME/.ssh/id_rsa"
			PUBLIC_KEY="$HOME/.ssh/id_rsa.pub"
		else
			echo "🔐 Generating temporary key pair"
			USE_TEMP_KEY_PAIR=1
			tmp_dir=$(mktemp -d)
			ssh-keygen -t rsa -b 4096 -C "TEMPORARY key for EC2 Instance Connect" -N "" -f "$tmp_dir/tmp_key"
			PRIVATE_KEY="$tmp_dir/tmp_key"
			PUBLIC_KEY="$tmp_dir/tmp_key.pub"
		fi
	fi

	if ! [[ -f $PUBLIC_KEY ]] || ! [[ -f $PRIVATE_KEY ]]; then
		echo "Couldn't find public key and/or private key"
		return 1
	fi

	# Push public key before establishing SSH
	if ! (aws_ec2_instance_connect_send_pub_key --instance-id "$INSTANCE_ID" --username "$EC2_USERNAME" --public-key "$PUBLIC_KEY"); then
		return 1
	fi

	local SSH_ARGS=(-o ServerAliveInterval=20 -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -i "$PRIVATE_KEY")
	if [[ ${#PORT_BINDINGS[@]} -gt 0 ]]; then
		for PORT_BINDING in "${PORT_BINDINGS[@]}"; do
			# If port binding is of form \d+, use same port locally
			if (echo "$PORT_BINDING" | grep -E --silent '^\d+$'); then
				SSH_ARGS+=(-L "\*:${PORT_BINDING}:localhost:${PORT_BINDING}")
			elif (echo "$PORT_BINDING" | grep -E --silent '^\d+:\d+$'); then
				local REMOTE_PORT=$(echo "$PORT_BINDING" | cut -d':' -f1)
				local LOCAL_PORT=$(echo "$PORT_BINDING" | cut -d':' -f1)
				SSH_ARGS+=(-L "\*:${REMOTE_PORT}:localhost:${LOCAL_PORT}")
			else
				echo "Could not understand how to bind port input of $PORT_BINDING"
				return 1
			fi
		done
	fi

	# Establish SSH connection
	local DNS_ADDR=$(aws_ec2_instance_get_public_dns_addr "$INSTANCE_ID")
	SSH_ARGS+=("${EC2_USERNAME}@${DNS_ADDR}")
	declare -p SSH_ARGS
	ssh "${SSH_ARGS[@]}"

	# Cleanup
	if [[ $USE_TEMP_KEY_PAIR -eq 1 ]] && [[ -d "$tmp_dir" ]]; then
		echo "🗑️ Deleting temporary key pair"
		rm -r "$tmp_dir"
	fi
}

tensorjs_keras_converter() {
	local raw_model_path=$1
	if ! [[ -f "$raw_model_path" ]]; then
		echo "Could not find model at $raw_model_path"
		return 1
	fi
	local raw_model_name=$(basename $raw_model_path)
	out_dir_name=tfjs_generated
	out_dir="./${out_dir_name}"
	mkdir "$out_dir" || true
	local converter_args=(
		"tensorflowjs_converter"
		"--input_format=keras"
		"/tmp/${raw_model_name}"
		"/tmp/${out_dir_name}"
	)
	docker run --rm -t \
		-v "${raw_model_path}:/tmp/${raw_model_name}" \
		-v "${out_dir}:/tmp/${out_dir_name}" \
		"jtz-reg/jtz/tensorflowjs" \
		"${converter_args[@]}"
}

get_cert_fingerprint() {
	local CERT_FILE=$1
	if ! [[ -f "$CERT_FILE" ]]; then
		echo "Could not find $CERT_FILE"
		return 1
	fi
	openssl x509 -pubkey -noout -in "$CERT_FILE" | openssl pkey -pubin -outform der | openssl dgst -sha256 -binary | openssl enc -base64
}

# Open a browser, pre-configured to temporarily trust a local SSL cert file
trust_cert_fingerprint() {
	local PUBLIC_CERT_FILE=$1
	if ! [[ -f $PUBLIC_CERT_FILE ]]; then
		echo "$PUBLIC_CERT_FILE does not exist"
		return 1
	fi
	if ! local PUBLIC_CERT_FINGERPRINT=$(get_cert_fingerprint "$PUBLIC_CERT_FILE"); then
		echo "Could not generate cert fingerprint"
		return 1
	fi

	if (check_args_for_value "--chrome" "$@"); then
		chrome --ignore-certificate-errors-spki-list="$PUBLIC_CERT_FINGERPRINT" --user-data-dir=/tmp
		return 0
	fi

	echo "TODO: Add Firefox support. This might not even be possible - need to comb through https://wiki.mozilla.org/Firefox/CommandLineOptions"
	return 1
}

compose_ssl_cert_query() {
	local CERT_FILE_OR_DOMAIN_URL=$1
	local CERT_FILE=$1
	shift
	if ! [[ -f "$CERT_FILE_OR_DOMAIN_URL" ]]; then
		local CERT_FILE=$(mktemp)
		# Remap 'https://example.com' -> 'example.com:443'
		openssl s_client -connect "$CERT_FILE_OR_DOMAIN_URL" </dev/null 2>/dev/null > "$CERT_FILE"
	fi
	openssl x509 -pubkey -in "$CERT_FILE" "$@"
}

SSH_PUBLIC_KEY_START_PATTERN="^ssh-[a-zA-Z]{2,}[a-zA-Z0-9-]*"

get_cert_type() {
	local cert_file_or_url="$1"
	if [[ $1 =~ ^https://.* ]]; then
		echo "URL"
		return
	elif [[ -f "$cert_file_or_url" ]]; then
		if (file "$cert_file_or_url" | grep --silent "SSH"); then
			if (grep --silent -E "^-----BEGIN OPENSSH PRIVATE KEY-----" "$cert_file_or_url"); then
				echo "SSH:PRIVATE"
				return
			elif (grep --silent -E "$SSH_PUBLIC_KEY_START_PATTERN" "$cert_file_or_url"); then
				echo "SSH:PUBLIC"
				return
			fi
			# Unknown format
			return 1
		elif (file "$cert_file_or_url" | grep --silent "PEM"); then
			echo "SSL:PUBLIC"
			return
		# This makes some assumptions
		elif (file "$cert_file_or_url" | grep --silent "ASCII text") && (grep --silent -E "^-----BEGIN PRIVATE KEY-----" "$cert_file_or_url"); then
			echo "SSL:PRIVATE"
			return
		fi
	fi

	# Unknown format
	return 1
}

get_cert_info() {
	local cert_file_or_url="$1"
	echo "🧠 Determining type of $cert_file_or_url ..."
	local cert_type=$(get_cert_type "$cert_file_or_url")


	if ! [[ $? -eq 0 ]]; then
		echo "Could not determine the type of certificate. Is $cert_file_or_url a valid input"
	fi

	echo "ℹ️ Type mapped as $cert_type"
	echo "🔨 Extracting information for $cert_type"

	# SSL
	if [[ $cert_type == "SSL:PUBLIC" ]] || [[ $cert_type == "SSL:PRIVATE" ]]; then
		echo "🔨 Extracting SSL cert info"
		compose_ssl_cert_query "$cert_file_or_url" -text -pubkey
		return
	fi

	# SSH
	if [[ $cert_type == "SSH:PUBLIC" ]] || [[ $cert_type == "SSH:PRIVATE" ]]; then
		ssh-keygen -lf "$cert_file_or_url"
		return
	fi

	# Unknown type / unmapped type
	echo "Could not determine how to extract info from $cert_type, $cert_file_or_url"
	return 1
}

is_cert_not_expired() {
	compose_ssl_cert_query "$1" -noout -checkend 0
}

get_registered_custom_uri_hyperlink_schemes() {
	if [[ $IS_MAC -ne 1 ]]; then
		# TODO: Linux support
		return 1
	fi

	# https://apple.stackexchange.com/a/397188/428959
	/System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/LaunchServices.framework/Versions/A/Support/lsregister  -dump URLSchemeBinding
}

get_local_ip() {
	for interface in en0 en1
	do
		local local_ip_addr=$(ipconfig getifaddr "$interface")
		if [[ $? -eq 0 ]]; then
			echo "$local_ip_addr"
			return 0
		fi
	done
	return 1
}

dev_ticket() {
	cat <<- "EOF" | copy_to_clipboard
	# Intro / Abstract

	SHORT_INTRO

	# Implementation Guidance / Resources / Tips

	- Item_A

	# Acceptance Criteria

	- [ ] Item_A
	EOF
}

top_snapshot() {
	if [[ $IS_MAC -eq 1 ]]; then
		top -l 1 | head -n 11
	else
		top -bn1 | head -n 11
	fi
}

splash_screen() {
	local INFO_TEXT=""
	if [[ $IS_MAC -eq 1 ]]; then
		INFO_TEXT="$(uname -snrom)"
	else
		INFO_TEXT="$(uname -snriom)"
	fi
	if (which lsb_release > /dev/null); then
		INFO_TEXT+=$'\n'
		INFO_TEXT+="$(lsb_release -a 2>/dev/null)"
	fi
	INFO_TEXT+=$'\n\n'
	INFO_TEXT+="$(top_snapshot)"

	render_text_overlay "$JT_LOGO" "$INFO_TEXT" "-1" 1
}

# TODO: Idea for cool util - parse doc strings / comments
# above fn names, and use them as part of quick pick list.
# I.e., so you could do so something like:
# - `dot_fn_pick docker*` - pick from docker commands
# - `dot_fn_pick fn_a fn_b` - pick from specific pick list
dot_fn_pick() {
	:
}

dot_fn_help() {
	:
}

# This is currently pretty macoS specific
# Also, runs code that triggers OS permission checks, so will fail if denied
whats_up() {
	WINDOW_TITLE=$(cat << "EOF" | xargs -0 osascript -e
global frontApp, frontAppName, windowTitle

set windowTitle to ""
tell application "System Events"
	set frontApp to first application process whose frontmost is true
	set frontAppName to name of frontApp
	tell process frontAppName
		tell (1st window whose value of attribute "AXMain" is true)
			set windowTitle to value of attribute "AXTitle"
		end tell
	end tell
end tell

return {frontAppName, windowTitle}
EOF
)
	STATUS_STRING=$(cat << EOF
Active Window = $WINDOW_TITLE
EOF
)

	if (npx --package jtz-time-tracker-utils jttu --version > /dev/null); then
		STATUS_STRING=$(cat << EOF
$STATUS_STRING
==== Time Tracker ====
$(npx --package jtz-time-tracker-utils jttu harvest status)
======================
EOF
)
	fi
	echo "$STATUS_STRING"
}

if [[ "$SHELL_TYPE" == "ZSH" ]]; then
	# This has a lot of zsh-isms in it
	# shellcheck disable=SC1091
	source "$DOTFILES_DIR/utils/large_llm_query.sh"
fi
