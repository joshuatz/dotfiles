#!/usr/bin/env bash

get_shell_type() {
	if [[ -n "$ZSH_VERSION" ]] || echo $SHELL | grep --silent -E "\/zsh$"; then
		echo "ZSH"
		return
	elif [[ -n "$BASH_VERSION" ]] || echo $SHELL | grep --silent -E "\/bash$"; then
		echo "BASH"
	fi
}
SHELL_TYPE=$(get_shell_type)

ARRAY_INDEX_START=0
if [[ "$SHELL_TYPE" == "ZSH" ]]; then
	# cmon y'all, can't we just agree on things for once?
	ARRAY_INDEX_START=1
fi

IS_MAC=0
if [[ "$OSTYPE" == "darwin"* ]]; then
	IS_MAC=1
fi

# Not perfect across all OSes, but a "good enough" approach for most
get_computer_name() {
	if (which scutil > /dev/null); then
		scutil --get ComputerName
		return 0
	fi
	uname -n | sed -e 's/\.local$//'
}

pretty_path() {
	echo "$PATH" | tr ':' '\n'
}

# You can use this to parse version strings and then use the resulting number for comparison
# Example:
#     if [[ $(parse_version_string $(git --version | grep -E -o "\d+\.\d+.\d+$")) -ge $(parse_version_string "2.39.0") ]]
# https://stackoverflow.com/a/37939589/11447682
function parse_version_string { echo "$@" | awk -F. '{ printf("%d%03d%03d%03d\n", $1,$2,$3,$4); }'; }

reload() {
	if [[ $SHELL_TYPE == "ZSH" ]]; then
		# Note: Don't use source ~/.zshrc
		# See: https://github.com/ohmyzsh/ohmyzsh/wiki/FAQ#how-do-i-reload-the-zshrc-file
		exec zsh
	elif [[ $SHELL_TYPE == "BASH" ]]; then
		source ~/.bash_profile
	else
		echo "Not sure how to reload this shell"
	fi
}

ding() {
	# Hello? Is anyone home? It's me, your terminal.
	echo -e "\a"
}

get_clipboard_contents() {
	if (which pbpaste > /dev/null); then
		pbpaste
	elif (which xclip > /dev/null); then
		xclip -selection clipboard -o
	elif (which wl-paste > /dev/null); then
		wl-paste
	else
		echo "ERROR: Could not find a clipboard utility"
	fi
}

get_clipboard_html() {
	if [[ $IS_MAC -ne 1 ]]; then
		# TODO
		return 1
	fi

	# https://stackoverflow.com/a/24132171/11447682
	# The Perl part of this is to convert the hex string to a readable string
	osascript -e 'the clipboard as Â«class HTMLÂ»' | perl -ne 'print chr foreach unpack("C*",pack("H*",substr($_,11,-3)))'
}

copy_to_clipboard() {
	if (which pbcopy > /dev/null); then
		pbcopy
	elif (which xclip > /dev/null); then
		xclip -selection clipboard
	elif (which wl-copy > /dev/null); then
		wl-copy
	else
		echo "ERROR: Could not find a clipboard utility"
	fi
}

# This only overwrites clipboard content if the selection is NOT empty
# It always return 0, so that it can be conveniently used with places
# that expect a copy command to always work
copy_to_clipboard_if_not_empty() {
	text="$1"
	# make sure to remove both space AND trailing line breaks
	if [[ -z "$(${text//})" ]]; then
		ding
		return 0
	fi
	echo "$text" | copy_to_clipboard
}

copy_html_to_clipboard() {
	html="$1"
	plaintext="$2"
	# Fallback to HTML as plaintext if not set
	if [[ -z "$plaintext" ]]; then
		plaintext="$html"
	fi
	if [[ $IS_MAC -eq 1 ]]; then
		# If HTML is not prefixed with meta charset tag, add it
		if [[ -z "$NO_WRAP" ]] && (! echo "$html" | grep -q -E "^<meta charset"); then
			html="<meta charset=\"utf-8\">${html}"
		fi

		# https://stackoverflow.com/a/11089226/11447682
		# https://aaron.cc/copying-the-current-safari-tab-as-a-to-the-clipboard-as-a-clickable-link/
		html_hex=$(echo -n "$html" | hexdump -ve '1/1 "%.2x"')
		if [[ -n "$NO_PLAIN" ]]; then
			osascript <<- EOF
				set the clipboard to Â«data HTML${html_hex}Â»
			EOF
			return
		fi
		# TODO: The `string:"${plaintext}"` part of this is problematic if the string contains special chars (and maybe even
		# if it just contains any `"`?)
		# E.g.: 6216:6226: syntax error: Expected â€œ,â€ or â€œ}â€ but found identifier. (-2741)
		osascript <<- EOF
			set the clipboard to {Â«class HTMLÂ»:Â«data HTML${html_hex}Â», string:"${plaintext}"}
		EOF
	else
		echo "$html" | xclip -selection clipboard -t text/html
	fi
}

copy_tab_to_clipboard() {
	printf "\t" | copy_to_clipboard
}

copy_last_command_to_clipboard() {
	last_command=$(fc -ln -1)
	echo "$last_command" | copy_to_clipboard
}

markdown_to_html_clipboard() {
	md="$1"
	# If no arg, grab from clipboard
	if [[ -z "$md" ]]; then
		md=$(get_clipboard_contents)
	fi
	html=""
	if (which pandoc > /dev/null); then
		html=$(echo "$md" | pandoc -f gfm -t html)
	else
		html=$(npx marked --gfm -s "$md")
	fi
	copy_html_to_clipboard "$html" "$md"
	echo "âœ… HTML copied to clipboard"
}

convert_clipboard_to_plaintext() {
	# Takes the clipboard contents and converts it to plaintext, in-place
	text=$(get_clipboard_contents)
	echo "$text" | copy_to_clipboard
}

convert_clipboard_html_to_md() {
	html=$(get_clipboard_html)
	echo "$html" | pandoc -f html -t markdown | copy_to_clipboard
}

firefox() {
	if [[ "IS_MAC" -eq 1 ]]; then
		/Applications/Firefox.app/Contents/MacOS/firefox "$@"
		return 0
	fi
	return 1
}

# Opens firefox, with each URL passed at the end, as a new tab
# Currently, with tree style tabs, the first URL becomes the root tab
# and any subsequent new tabs are loaded as children
# (TODO: Make this more flexible)
firefox_with_tabs() {
	args=(
		"-new-window"
		"$1"
	)
	shift
	for arg in "$@"; do
		args+=("-new-tab" "$arg")
	done
	firefox "${args[@]}"
}

date_iso() {
	# 2020-11-28T12:11:28Z
	date -u +"%Y-%m-%dT%H:%M:%SZ"
}

date_ms() {
	if which gdate > /dev/null; then
		gdate +%s%3N
	else
		date +%s000
		# echo "WARNING: gdate not found; faking millseconds from seconds"
	fi
}

# Like `touch` + `mkdir -p`: creates intermediate directories if they don't exist yet
make-file() {
	file_path=$1
	if [[ -e $file_path ]]; then
		echo "File already exists"
	else
		mkdir -p "$(dirname "$file_path")"
		touch "$file_path"
	fi
}

get_cpu_throttle_info() {
	if [[ $* == *--watch* ]]; then
		pmset -g thermlog
		return
	fi
	pmset -g therm
}

make_venv() {
	VENV_PATH=./.venv
	echo "Where should the virtual environment be created? (press enter to default to .venv)"
	read -r INPUT
	if [[ $INPUT != "" ]]; then
		VENV_PATH=$INPUT
	fi
	if [[ -d $VENV_PATH ]]; then
		echo "${VENV_PATH} already exists"
	else
		echo "Preparing virtual environment in ${VENV_PATH}"
		python3 -m venv $VENV_PATH
		source $VENV_PATH/bin/activate
	fi
}

check_venv() {
	which python | grep "$PWD"
}

# Generates the poetry named environment string
# Although this _can_ be used to check that the correct virtual environment is
# activated, it is generally much easier to just use a regular venv and point
# poetry to it (because then you can just do something like `which python | grep $PWD`)
# For implementation reference see
#   https://github.com/python-poetry/poetry/blob/7c86992909257caa4f51a50c001f5894bfe5065e/src/poetry/utils/env.py#L635
#   https://github.com/python-poetry/poetry/blob/7c86992909257caa4f51a50c001f5894bfe5065e/src/poetry/utils/env.py#L1212-L1220
generate_poetry_env_name_str() {
	PROJECT_NAME=$(basename "$PWD")
	if [[ -f pyproject.toml ]]; then
		PROJECT_NAME=$(poetry version | sed -E -n 's/(.+) [.0-9]+$/\1/p')
	fi
	PROJECT_NAME=$PROJECT_NAME python << "EOF"
import base64
import os
import re
import hashlib

# shim - re-implement poetry encode method
def encode(string: str):
	if isinstance(string, bytes):
		return string
	return string.encode("utf-8")

def generate_env_name(package_name: str, cwd: str) -> str:
	package_name = package_name.lower()
	sanitized_name = re.sub(r'[ $`!*@"\\\r\n\t]', "_", package_name)[:42]
	normalized_cwd = os.path.normcase(os.path.realpath(cwd))
	h_bytes = hashlib.sha256(encode(normalized_cwd)).digest()
	h_str = base64.urlsafe_b64encode(h_bytes).decode()[:8]
	return f"{sanitized_name}-{h_str}"

cwd = os.getcwd()
print(generate_env_name(os.environ["PROJECT_NAME"], cwd))
# Should print something like `project-name-ABCD1a-Z`
EOF
}

# Search for, and activate, a local python virtual environment
# @TODO - if python env is *already* activated, check if path matches, and if not
# 	deactivate and then activate
# @TODO - handle Poetry
activate() {
	fail=1
	possible_envs=(./venv ./.venv ./env ./.env)
	for env_dir in "${possible_envs[@]}"; do
		if [[ -e "$env_dir/bin/activate" ]]; then
			source "$env_dir/bin/activate"
			fail=0
			break
		fi
	done
	return $fail
}

pip_upgrade() {
	python3 -m pip install --upgrade pip
}

# Like clear, but extra space to pad the start
wipe() {
	for run in {1..10}; do
		echo $'\n'
	done
	clear
}

render_image() {
	IMAGE_PATH=$1

	# ImageMagick
	if (which display > /dev/null); then
		# Sometimes can be installed, but misconfigured. Can use a simple` --version`
		# check to verify
		if (display --version > /dev/null 2>&1); then
			display "$IMAGE_PATH"
			return
		else
			echo "WARNING: ImageMagick installed, but not configured correctly"
		fi
	fi

	if (which chafa > /dev/null); then
		chafa "$IMAGE_PATH"
		return
	fi

	echo "ERROR: Could not find a suitable image viewer"
	return 1
}

# Note: This is ZSH specific; todo - make agnostic?
reload_func() {
	unfunction "_$1" && compinit
}

normalize_name() {
	input_name="$1"
	# SPACE -> `-`
	# (anything else, non alpha-numeric) -> REMOVED
	echo "$input_name" | tr ' ' '-' | tr -cd '[:alnum:]-'
}

project_name() {
	project_dir=$1
	if [[ -z "$project_dir" ]]; then
		project_dir="$PWD"
	fi
	project_dirname=$(basename "$project_dir")

	# DEFAULT
	project_name="$project_dirname"

	# Is there a pyproject.toml file?
	if [[ -f "$project_dir/pyproject.toml" ]]; then
		project_name=$(poetry version | awk '{print $1}')
	# How about `package.json`?
	elif [[ -f "$project_dir/package.json" ]]; then
		project_name=$(jq -r '.name' "$project_dir/package.json")
	# How about a git remote / named repo?
	elif [[ -d "$project_dir/.git" ]]; then
		remote_url=$(git_remote_url)
		project_name=$(basename "$remote_url")
	fi

	echo "$project_name"
}

project_name_normalized() {
	project_name_raw=$(project_name "$1")
	normalize_name "$project_name_raw"
}

tmux_generate_session_name() {
	tmux_session_name=$1
	if [[ -z "$tmux_session_name" ]]; then
		project_name=$(project_name_normalized "")
		tmux_session_name="$project_name"
		# Default to project name + end of branch name
		current_git_branch_name=$(git_branch_name 2>&1)
		if [[ $? -eq 0 ]]; then
			tmux_session_name="${tmux_session_name}-$(basename "$current_git_branch_name")"
		fi
	fi
	echo "$tmux_session_name"
}

tmux_session_select() {
	if [[ -n "$TMUX_SESSION" ]]; then
		echo "$TMUX_SESSION"
		return
	fi
	active_sessions=$(tmux list-sessions -F "#{session_name}" 2>/dev/null)
	selected_session=$(printf "%s\n" "${active_sessions[@]}" | fzf)
	echo "$selected_session"
}

tmux_session_select_and_attach() {
	tmux attach-session -t "$(tmux_session_select)"
}

tmux_window_select() {
	selected_session=$(tmux_session_select)
	if [[ -z "$selected_session" ]]; then
		return
	fi
	all_windows_in_session=$(tmux list-windows -t "$selected_session" -F "#{window_index} #{window_name}")
	selected_window_index="0"
	# Only prompt for selection if > 1 window
	if [[ $(($(echo "$all_windows_in_session" | wc -l))) -gt 1 ]]; then
		selected_window_index=$(echo "$all_windows_in_session" | fzf | awk '{print $1}')
	fi
	echo "$selected_session:$selected_window_index"
}

tmux_pane_select() {
	selected_window=$(tmux_window_select)
	all_panes_in_window=$(tmux list-panes -t "$selected_window" -F "#{pane_index}")
	selected_pane=$(echo "$all_panes_in_window" | fzf --preview "tmux capture-pane -t $selected_window.{} -pJS -10")
	echo "$selected_window.$selected_pane"
}

tmux_scrollback_dump() {
	: "${NUM_LINES:="500"}"
	pane=$(tmux_pane_select)
	if [[ -z "$pane" ]]; then
		return
	fi
	tmux capture-pane -t "$pane" -pJS "-$NUM_LINES"
}

tmux_auto_open() {
	tmux_session_name=$(tmux_generate_session_name "$1")
	echo "Session name = $tmux_session_name"

	# Search for active session first, and attach if exists
	if (tmux has-session -t "$tmux_session_name" 2>/dev/null); then
		echo "Attaching to existing session"
		tmux attach-session -t "$tmux_session_name"
		return
	fi

	PANE_NUM=1
	select pane_config in "1 Pane" "2 Pane (H-Split)" "3 Pane (V, HH)"; do
		case $pane_config in
			"1 Pane") break ;;
			"2 Pane (H-Split)") PANE_NUM=2 && break ;;
			"3 Pane (V, HH)") PANE_NUM=3 && break ;;
		esac
	done
	echo "Creating new session ($tmux_session_name)"
	tmux new-session -s "$tmux_session_name" -d

	if [[ $PANE_NUM -gt 1 ]]; then
		tmux split-window -h -t "$tmux_session_name:0"
		# For 3-pane, v-split the first pane
		if [[ $PANE_NUM -eq 3 ]]; then
			tmux select-pane -t "$tmux_session_name":0.0
			tmux split-window -v -t "$tmux_session_name"
		fi
	fi

	# Loop through all panes and exec `activate`
	for pane_id in $(tmux list-panes -F "#{pane_id}" -t "$tmux_session_name"); do
		tmux send-keys -t "${tmux_session_name}:0.${pane_id}" activate C-m 2>&1
	done

	tmux select-pane -t "$tmux_session_name":0.0
	tmux attach-session -t "$tmux_session_name"
}

# This function scans for active tmux sessions where at least one pane
# has a working directory scoped to the current one - which is useful if you
# forgot what you named the session, but remember where you were working in.
# If there are more than one matching sessions, it will let you select
# which one to attach to with `fzf`
tmux_auto_attach() {
	# Get the current working directory
	current_dir=$(pwd)

	# Get a list of all active tmux sessions
	active_sessions=()
	while IFS='' read -r line; do active_sessions+=("$line"); done < <(tmux list-sessions -F "#{session_name}" 2>/dev/null)

	# Loop through all sessions, and check if any of the panes have a
	# working directory that matches the current one
	matching_sessions=()
	for session in "${active_sessions[@]}"; do
		# Get list of pane paths
		pane_paths=()
		while IFS='' read -r line; do pane_paths+=("$line"); done  < <(tmux list-panes -t "$session" -F "#{pane_current_path}" 2>/dev/null)
		for pane_path in "${pane_paths[@]}"; do
			if [[ "$pane_path" == "$current_dir" ]]; then
				matching_sessions+=("$session")
				break
			fi
		done
	done

	declare -p matching_sessions

	# If there is only one matching session, attach to it
	if [[ ${#matching_sessions[@]} -eq 1 ]]; then
		matching_session_name=${matching_sessions[0+$ARRAY_INDEX_START]}
		echo "Found only 1 matching session ($matching_session_name). Auto-attaching now..."
		sleep 2
		tmux attach-session -t "$matching_session_name"
		return
	fi

	# If there are multiple matching sessions, let the user select which one to attach to
	if [[ ${#matching_sessions[@]} -gt 1 ]]; then
		echo "More than one matching tmux session was found. Which would you like to attach to?"
		selected_session=$(printf "%s\n" "${matching_sessions[@]}" | fzf)
		if [[ -n "$selected_session" ]]; then
			tmux attach-session -t "$selected_session"
			return
		fi
	fi

	# If no matching sessions, just open a new one
	echo "Could not find matching session"
	tmux_auto_open ""
}

tmux_auto_close() {
	tmux_session_name=$(tmux_generate_session_name "$1")
	if (tmux has-session -t "$tmux_session_name" 2>/dev/null); then
		echo "Killing session ('$tmux_session_name')"
		tmux kill-session -t "$tmux_session_name"
	else
		echo "No session to kill (could not find '$tmux_session_name')"
	fi
}

# Revert the last commit, but don't undo the changes
git_revert_last() {
	git reset HEAD~1
}

git_sha() {
	short=$(git rev-parse --short HEAD)
	long=$(git rev-parse HEAD)
	echo "${short}\t${long}"
}

git_trunk_branch() {
	git remote show origin | grep "HEAD branch" | cut -d ":" -f 2 | sed -e 's/^[[:space:]]*//'
}

git_root_dir() {
	git rev-parse --show-toplevel
}

git_cd_root_dir() {
	cd "$(git_root_dir)" || exit
}

git_trunk_ahead_files() {
	TRUNK_BRANCH=$(git_trunk_branch)
	git fetch
	git --no-pager diff --name-only origin/"$TRUNK_BRANCH"...HEAD
}

# This should essentially be the file list of the diff for your `push`
git_local_ahead_of_remote_files() {
	CURRENT_BRANCH=$(git_branch_name)
	git fetch
	git --no-pager diff --name-only origin/"$CURRENT_BRANCH"...HEAD
}

git_update_local_trunk() {
	TRUNK_BRANCH=$(git_trunk_branch)
	CURRENT_BRANCH=$(git_branch_name)
	if [[ "$TRUNK_BRANCH" == "$CURRENT_BRANCH" ]]; then
		git pull
		return
	fi
	git fetch . origin/"$TRUNK_BRANCH":"$TRUNK_BRANCH"
}

git_behind_ahead() {
	# Get the trunk / main branch in the repo (e.g. `main`)
	TRUNK_BRANCH=$(git_trunk_branch)
	git fetch
	echo "Behind | Ahead"
	echo "      $(git rev-list --left-right --count origin/"$TRUNK_BRANCH"...HEAD)"
}

git_stat_live() {
	if [[ $* == *--summary ]]; then
		watch -n 2 -c "git diff --staged --stat  ':(exclude)package-lock.json' | tail -n 1"
	fi
	watch -n 2 -c "git diff --staged --stat  ':(exclude)package-lock.json'"
}

git_diff_live() {
	watch -n 2 -c "git diff --staged ':(exclude)package-lock.json'"
}

git_select_commit() {
	MAX_PAST_COMMITS_TO_LIST=40
	commits=$(git log --pretty=format:"%H %s" -n $MAX_PAST_COMMITS_TO_LIST)

	# Use fzf to interactively select a commit
	commit=$(echo "$commits" | fzf --height 70% --reverse --ansi)

	# Extract the commit hash from the selected line
	commit_hash=$(echo "$commit" | awk '{print $1}')

	echo "$commit_hash"
}

# Given a stash string like `stash@{0}: On main: do x and y`,
# extract out just the stash index
git_extract_stash_index() {
	stash_string="$1"
	echo "$stash_string" | grep -o -E "\{[0-9]+\}" | tr -d "{}"
}

git_stash_select() {
	stash_list=$(git stash list)
	# shellcheck disable=SC2016
	selected_stash=$(echo "$stash_list" | fzf \
		--height 70% \
		--reverse \
		--ansi \
		--preview "source ~/.zshrc && git stash show -p "'"$(git_extract_stash_index {})"'""
	)
	echo "$selected_stash"
}
alias git_select_stash="git_stash_select"

git_copy_commit_sha() {
	commit_hash=$(git_select_commit)
	echo "$commit_hash" | copy_to_clipboard
}

git_copy_commit_msg() {
	commit_hash=$(git_select_commit)
	commit_msg=$(git log --pretty=format:"%B" -n 1 "$commit_hash")
	echo "$commit_msg" | copy_to_clipboard
}

# Use this to interactively select a past commit to target for `git commit --fixup=`
git_fixup() {
	commit_hash=$(git_select_commit)
	git commit --fixup="$commit_hash"
}


# TODO: This works, but really should be re-written in JS or Python
# (too many ZSH and bash workarounds, hard to read)
git_find_fixup_base() {
	MAX_PAST_COMMITS_TO_SCAN_PER_FIXUP=40
	LOG_DIVIDER=$(echo $'\x1F')
	seeking_commit_msgs=()
	commit_scan_counter=0
	# Iterate over all git log entries
	git log --pretty=format:"%H${LOG_DIVIDER}%s" | while read line
	do
		# Check if we already at limit and need to bail out
		commit_scan_counter=$((commit_scan_counter+1))
		if [[ $commit_scan_counter -gt $MAX_PAST_COMMITS_TO_SCAN_PER_FIXUP ]]; then
			echo "Could not find the ultimate fixup base, and limit of $MAX_PAST_COMMITS_TO_SCAN_PER_FIXUP scan commits reached"
			echo "Still seeking / could not find within limit:"
			printf "\t%s\n" "$(declare -p seeking_commit_msgs)"
			return 1
		fi

		# Extract out commit hash and message from git log line
		commit_hash=$(echo "$line" | awk -F"$LOG_DIVIDER" '{ print $1 }')
		commit_msg=$(echo "$line" | awk -F"$LOG_DIVIDER" '{ print $2 }')

		# Is this a `fixup! {original message}` commit?
		if [[ "$commit_msg" == "fixup! "* ]]; then
			# Add message, without `fixup! ` prefix, to search list
			target_commit_msg=${commit_msg#"fixup! "}
			seeking_commit_msgs+=("$target_commit_msg")

			# Reset the scan counter, so we can search x num past this new point
			commit_scan_counter=0
		elif [[ ${#seeking_commit_msgs[@]} -gt 0 ]]; then
			# Remove all fixups that fix this commit
			holes_count=0
			for ((i=0; i<${#seeking_commit_msgs[@]}; i++)); do
				if [[ ${seeking_commit_msgs[$i+$ARRAY_INDEX_START]} == "$commit_msg" ]]; then
					unset -v 'seeking_commit_msgs[$i+$ARRAY_INDEX_START]'
					holes_count=$((holes_count+1))
				fi
			done

			# Are we done yet?
			if [[ $holes_count -eq ${#seeking_commit_msgs[@]} ]]; then
				echo "${commit_hash}~1"
				return 0
			fi

			# Remove holes / sparse -> dense
			# Not double-quoting this is the easiest way to do this without
			# accidentally leaving empty strings
			# shellcheck disable=SC2128
			# shellcheck disable=SC2206
			seeking_commit_msgs=($seeking_commit_msgs)
		fi
	done
}

git_find_github_pr() {
	SHA=$1
	gh pr list --search "$SHA"
}

# Use this with `--fixup` commits, to auto-target the last commit before fixup
# with interactive rebase
# Options:
#	(flag) `--skip-editor`: Don't open interactive editor
git_auto_rebase() {
	skip_editor=$([[ $* == *--skip-editor ]] && echo "true" || echo "false")
	new_target_base=$(git_find_fixup_base)

	if [[ $? -ne 0 ]]; then
		echo "$new_target_base"
		echo "Could not auto-find new base. Cancelling auto-rebase"
		return 1
	fi

	while true; do
		echo "Found target base:"
		printf "\t%s\n" "$new_target_base"
		printf "\t%s\n Target Base = " "$(git show --no-patch --oneline "$new_target_base" | cat)"
		printf "Continue? [Yy]es / ENTER, [Nn]o, [Cc]ancel\n"
		read -r answer
		case $answer in
			[Yy]*) break ;;
			"") break ;;
			[Nn]*) return 0 ;;
			[Cc]*) return 0 ;;
		esac
	done

	git_version=$(git --version | grep -E -o "\d+\.\d+.\d+$")

	if [[ "$skip_editor" != "true" ]]; then
		git rebase --autosquash --interactive "$new_target_base"
		return
	fi

	# New in git 2.44 - auto-squash support in non-interactive mode
	if [[ $(parse_version_string "$git_version") -ge $(parse_version_string "2.44") ]]; then
		git rebase --autosquash "$new_target_base"
	else
		# Use `GIT_SEQUENCE_EDITOR=true` to skip editor
		GIT_SEQUENCE_EDITOR=true git rebase --autosquash --interactive "$new_target_base"
	fi

}


git_branch_name() {
	git rev-parse --abbrev-ref HEAD
}

# WARNING: This errors if no corresponding tag can be found
git_tag_name() {
	git describe --tags --abbrev=0
}

# NOTE: This returns the remote branch name, prefixed with the name of the remote itself
# E.g.
#	`origin/my-branch`
git_remote_branch() {
	# https://stackoverflow.com/a/9753364/11447682
	git for-each-ref --format='%(upstream:short)' "$(git symbolic-ref -q HEAD)"
}

git_remote_url() {
	git remote get-url origin
}

git_branch_backup() {
	current_branch_name=$(git rev-parse --abbrev-ref HEAD)
	backup_branch_name="backup/$current_branch_name--$(date '+%Y-%m-%d--%I-%M-%p')"
	git branch "$backup_branch_name"
	echo "âœ… Backed up branch to $backup_branch_name"
}
alias git_backup_branch="git_branch_backup"

git_checkout_dirty() {
	target_branch_name=$1
	operation="git checkout $target_branch_name"
	git_do_while_dirty "$operation"
}
if [[ $SHELL_TYPE == "ZSH" ]]; then
	:
	# TODO: This is close, but not working perfectly
	# compdef _git git_checkout_dirty=git-checkout
fi

git_do_while_dirty() {
	git_operation="$*"
	IFS=

	# If no operation was provided, default to very last command
	if [[ -z "$git_operation" ]]; then
		git_operation=$(fc -ln -1)
		echo "No command passed. Did you want to retry your last command?"
		printf "\t%s\n" "$git_operation"
		while true; do
			printf "Retry? [Yy]es / ENTER, [Nn]o, [Cc]ancel\n"
			read -r answer
			case $answer in
				[Yy]*) break ;;
				"") break ;;
				[Nn]*) return 0 ;;
				[Cc]*) return 0 ;;
			esac
		done
	fi


	# If user forgot to include `git`, add it for them. E.g., passing `pull` instead of `git pull`
	if [[ $git_operation != git* ]]; then
		git_operation="git $git_operation"
	fi

	echo "Operation to try = '$git_operation'"

	# Error out when command is NOT run from root of git repo, as this can cause issues with things
	# like `git checkout ${PATHSPEC}`, as the paths git's stdout uses are relative to repo root,
	# even if you running command from subdirectory
	git_root=$(git rev-parse --show-toplevel)
	if [[ "$git_root" != "$PWD" ]]; then
		echo "ERROR: You are not running this command from the root of a git repository"
		echo "This can cause issues with things like \`git checkout\`, as the paths git's stdout"
		echo "uses are relative to repo root, even if you running command from subdirectory"
		echo "Current directory: $PWD"
		echo "Git root: $git_root"
		return 1
	fi

	git_operation_results=$($SHELL -c "$git_operation" 2>&1)

	# If operation was clean, nothing to do
	error_string_test=$(echo "$git_operation_results" | grep -E "error: Your local changes to the following files would be overwritten by")

	# TODO: Add check for `error: The following untracked working tree files would be overwritten by merge:`

	echo "$error_string_test"
	if [[ "$error_string_test" == "" ]]; then
		echo "Operation was clean"
		return 0
	fi

	# Get list of conflicting file paths
	dirty_files=$(echo "$git_operation_results" | grep -E -o "^[[:blank:]]+.*" | sed -e 's/^[[:space:]]*//')
	cat << EOF
========= DIRTY FILES =========
$dirty_files
===============================
EOF

	# Use stash to temporarily stash changes
	# Newer versions of git can support stashing just staged changes
	use_staged_stash=false
	git_version=$(git --version | grep -E -o "\d+\.\d+.\d+$")
	if [[ $(parse_version_string "$git_version") -ge $(parse_version_string "2.35") ]]; then
		echo "Found git version >= 2.3"
		echo "Your git version supports staged stashes."
		use_staged_stash=true
	else
		while true; do
			printf "Your git version does NOT support staged stashes. Continue? [Yy]es / ENTER, [Nn]o, [Cc]ancel\n"
			read -r answer
			case $answer in
				[Yy]*) break ;;
				"") break ;;
				[Nn]*) return 0 ;;
				[Cc]*) return 0 ;;
			esac
		done
	fi

	ITEMS_PRESERVED=0
	# Go through list of conflicting files and ask what the user wants to do
	preserve="unsure"
	# different fd (`<&9`) is to avoid conflict with inner `read`
	# https://stackoverflow.com/q/6911520/11447682
	while IFS= read -r dirty_file <&9; do
		if [[ $preserve == "unsure" ]]; then
			while true; do
				# Ask user what to do about this (and rest) of files
				printf "Keep changes to %s?\n" "$dirty_file"
				printf "[Aa]ll files, [Yy]es / ENTER, [Nn]o, / [Dd]rop+rest, [Pp]review, [Cc]ancel\n"
				read -r answer
				case $answer in
					[Aa]*) preserve="all" && break ;;
					[Yy]*) preserve="yes" && break ;;
					"") break ;;
					[Nn]*) preserve="no" && break ;;
					[Dd]*) preserve="none" && break ;;
					[Pp]*) git diff "$dirty_file" ;;
					[Cc]*) return 0 ;;
				esac
			done
		fi

		if [[ $preserve == "none" ]]; then
			git checkout "$dirty_file"
		elif [[ $preserve == "all" ]]; then
			git add "$dirty_file"
			ITEMS_PRESERVED=$((ITEMS_PRESERVED+1))
		else
			if [[ $preserve == "yes" ]]; then
				git add "$dirty_file"
				ITEMS_PRESERVED=$((ITEMS_PRESERVED+1))
			else
				git checkout "$dirty_file"
			fi
			# Reset for next go-around
			preserve="unsure"
		fi
	done 9<<< "$dirty_files"

	if [[ $ITEMS_PRESERVED -gt 0 ]]; then
		if [[ $use_staged_stash == "true" ]]; then
			git stash --staged
		else
			git stash
		fi
	fi

	# Actually do the thing
	$SHELL -c "$git_operation"

	if [[ $ITEMS_PRESERVED -gt 0 ]]; then
		git stash pop
	fi
}

# You can use this to delete branch names nested under a slash (or other patterns)
#	Example: `git_branch_delete_pattern feature-a/tmp/*`
git_branch_delete_pattern() {
	git_branch_pattern=$1
	matching_branches=$(git branch --list "$git_branch_pattern")
	echo "This will delete the following branches"
	echo "$matching_branches"
	hard_delete=0
	while true; do
		printf "Are you sure? [Yy]es / ENTER, [Hh]ard delete, [Cc]ancel / [Nn]o\n"
		read -r answer
		case $answer in
			[Yy]*) break ;;
			[Hh]*) hard_delete=1 && break ;;
			"") break ;;
			[Cc]*) return 0 ;;
			[Nn]*) return 0 ;;
		esac
	done
	if [[ $hard_delete == 1 ]]; then
		echo "$matching_branches" | xargs git branch -D
		return 0
	fi
	echo "$matching_branches" | xargs git branch -d
}

git_stats() {
	git fetch
	CURRENT_BRANCH=$(git_branch_name)
	REMOTE_BRANCH=$(git_remote_branch)
	TRUNK_BRANCH=$(git_trunk_branch)
	trunk_diff_stats=$(git diff --staged --stat "origin/$TRUNK_BRANCH" | tail -n 1)
	behind_ahead=$(git_behind_ahead)

	remote_diff_str=""
	if [[ -n "$REMOTE_BRANCH" ]]; then
		remote_diff_stats=$(git diff --stat "$REMOTE_BRANCH" | tail -n 1)
		remote_diff_str=$(cat <<- EOF

			  Remote Diff Stats = $remote_diff_stats
		EOF
		)
	else
		REMOTE_BRANCH="(UNSET)"
	fi



	cat <<- EOF
		Branch = $CURRENT_BRANCH
		Trunk Branch = $TRUNK_BRANCH
		  Trunk Diff Stats = $trunk_diff_stats
		Remote Branch = ${REMOTE_BRANCH}${remote_diff_str}
		Behind / Ahead = $behind_ahead
	EOF
}

# Get information about the state of things while stopped during a rebase
git_rebase_info() {
	# TODO
	:
}

git_tree_view() {
	ALL=1
	while true; do
		printf "What to show? [Aa]ll / ENTER, Current [Bb]ranch\n"
		read -r answer
		case $answer in
			[Aa]*) break ;;
			"") break ;;
			[Bb]*) ALL=0 && break ;;
			[Cc]*) return 0 ;;
		esac
	done
	if [[ $ALL == 1 ]]; then
		git log --graph --oneline --decorate --all
	else
		git log --graph --oneline --decorate
	fi
}

docs() {
	if [[ -d "$DOCS_DIR" ]]; then
		(
			cd "$DOCS_DIR" || return
			"$EDITOR" .
		)
	else
		open  "https://docs.joshuatz.com/"
	fi
}

docker_pick_container() {
	# TODO support picking non-active containers
	container_list=$(docker ps --format "table {{.ID}}\t{{.Image}}\t{{.Names}}")
	container=$(echo "$container_list" | fzf --height 40% --reverse --header-lines=1)
	container_id=$(echo "$container" | awk '{print $1}')
	echo "$container_id"
}

docker_exec_it() {
	CONTAINER_REF=$(docker_pick_container)
	docker exec -it "$CONTAINER_REF" bash
	# TODO retry with `sh` if bash not found
}

docker_get_working_dir() {
	CONTAINER_REF=$1
	docker inspect --format='{{json .Config.Labels}}' "$CONTAINER_REF" | jq '.["com.docker.compose.project.working_dir"]'
}

# Pick a small(ish) docker image; useful for various ephemeral purposes
docker_pick_minimal_image_name() {
	select image in "busybox (smallest, no bash)" "alpine (small, no bash)" "debian (w/bash)" "ubuntu (w/bash)"; do
		case $image in
			# https://hub.docker.com/_/busybox
			busybox*) echo "busybox" && break ;;
			# https://hub.docker.com/_/alpine
			alpine*) echo "alpine" && break ;;
			# https://hub.docker.com/_/debian
			debian*) echo "debian" && break ;;
			# https://hub.docker.com/_/ubuntu
			ubuntu*) echo "ubuntu" && break ;;
			*) echo "Invalid selection" ;;
		esac
	done
}

# Uses a temporary (small) docker container to mount a volume for inspection
docker_inspect_volume() {
	VOLUME_NAME=$1
	if ! (docker volume ls | grep "$VOLUME_NAME$" > /dev/null); then
		echo "Volume not found"
		return 1
	fi
	IMAGE_NAME=$(docker_pick_minimal_image_name)
	IMAGE_SHELL=$(echo "$IMAGE_NAME" | grep -q -E "busybox|alpine" && echo "sh" || echo "bash")
	cat <<- EOF
		Temp Image = $IMAGE_NAME
		Shell = $IMAGE_SHELL
		Volume = $VOLUME_NAME
		Container Mount = /tmp/volume

		Have fun inspecting!
	EOF
	docker run --rm -it -v "$VOLUME_NAME":/tmp/volume "$IMAGE_NAME" "$IMAGE_SHELL" -c "cd /tmp/volume; exec $IMAGE_SHELL"
}

docker_list_binds() {
	CONTAINER_REF=$(docker_pick_container)
	docker inspect --format='{{json .HostConfig.Binds}}' "$CONTAINER_REF" | jq
}

docker_pick_image() {
	all_images=$(docker image ls --format "table {{.Repository}}:{{.Tag}}\t{{.ID}}")
	selected_image=$(echo "$all_images" | fzf --height 40% --reverse --header-lines=1)
	image_id=$(echo "$selected_image" | awk '{print $2}')
	echo "$image_id"
}

docker_image_exec() {
	: "${DOCKER_SHELL:="bash"}"
	image_id=$(docker_pick_image)
	docker run --rm -it "$image_id" "/bin/$DOCKER_SHELL"
}
alias docker_exec_image="docker_image_exec"
alias docker_run_image_interactive="docker_exec_image"

docker_inspect_image() {
	image_id=$(docker_pick_image)
	docker inspect "$image_id"
}

docker_log_follow() {
	CONTAINER_REF=$(docker_pick_container)
	docker logs -f "$CONTAINER_REF"
}

# Find the true global package dir / bin for a brew installed package
# e.g. `brew_find_global_pkd_dir fzf` -> `/usr/local/Cellar/fzf/0.45.0`
brew_find_global_pkd_dir() {
	PACKAGE_NAME=$1
	readlink -f "$(brew --prefix "$PACKAGE_NAME")"
}

npm_find_npx_global_pkg_dir() {
	PACKAGE_NAME=$1
	find "$HOME/.npm/_npx" -type d -name "$PACKAGE_NAME"
}

# NOTE: This is for packages installed with `-g`, not those installed via npx
# For npx, use `npm_find_npx_global_pkg_dir`, for which each package gets an isolated
# subdir, not a shared node_modules
npm_find_global_node_modules() {
	asdf_exec_with_global_version npm root -g
}

npm_find_global_pkg_dir() {
	PACKAGE_NAME=$1
	GLOBAL_NODE_MODULES=$(npm_find_global_node_modules)
	# Make sure to scan for symlinks as well, to handle `npm link` and friends
	found_dir=$(find -L "$GLOBAL_NODE_MODULES" -type d -depth 1 -name "$PACKAGE_NAME")
	if [[ -z "$found_dir" ]]; then
		echo "ERROR: Could not find $PACKAGE_NAME in global node_modules"
		return 1
	fi
	echo "$found_dir" | head -n 1
}

# Generate an ESM import statement, out of your global node_modules
# Pretty hacky: not many good reasons to use this, other than for fiddling around
# @see run_...in_global_node fns for a slightly better approach (but still hacky / just for fiddling)
scaffold_global_node_import() {
	PACKAGE_NAME=$1
	PACKAGE_DIR=$(npm_find_global_pkg_dir "$PACKAGE_NAME")
	copy_to_clipboard <<- EOF
	import {} from '$PACKAGE_DIR'
	EOF
}

run_file_in_global_node() {
	GLOBAL_NODE_MODULES=$(npm_find_global_node_modules)
	# TODO clean this up with piping?
	FILE_TO_EXEC="$1"
	FILENAME=$(basename "$FILE_TO_EXEC")
	# no-clobber
	cp -n "$FILE_TO_EXEC" "$GLOBAL_NODE_MODULES/"
	# WARNING: This might seem super hacky - why not just use `NODE_PATH=$GLOBAL_NODE_MODULES`?
	# Well, that *would* work, except for that they decided to ignore `NODE_PATH` when
	# moving to ESM `import` ðŸ™ƒ
	# https://nodejs.org/api/esm.html#esm_no_node_path
	(
		cd "$GLOBAL_NODE_MODULES" || exit
		node "$FILENAME"
	)
	rm "$GLOBAL_NODE_MODULES/$FILENAME"
}

run_raw_js_in_global_node() {
	RAW_CODE_TO_RUN=$1
	GLOBAL_NODE_MODULES=$(npm_find_global_node_modules)
	(
		cd "$GLOBAL_NODE_MODULES" || exit
		node --eval "$RAW_CODE_TO_RUN"
	)
}

repl_in_global_node() {
	GLOBAL_NODE_MODULES=$(npm_find_global_node_modules)
	pushd "$GLOBAL_NODE_MODULES" || exit
	node --experimental-repl-await
	popd || exit
}

# Execute a command with the global version of an asdf plugin, regardless of which dir
# you are in.
# @example `asdf_exec_with_global_version node --version`
asdf_exec_with_global_version() {
	# This is kind of hacky, but it works and asdf doesn't provide a "get global version" API
	# https://github.com/asdf-vm/asdf/issues/1340
	(cd /; asdf exec "$@")
	# Note: Above should pass through exit code, so no need to check and re-throw
}

# Note to self: you can use `--package` to avoid ambiguity around package name vs bin / entrypoint
npx_exec_global() {
	asdf_exec_with_global_version npx --no-install "$@"
}

npm_ls_global() {
	asdf_exec_with_global_version npm ls -g --depth=0 "$1"
}

find_proc_by_port() {
	PORT=$1
	lsof -i :"$PORT"
}

find_pid_by_port() {
	PORT=$1
	lsof -t -i :"$PORT"
}

get_proc_info_by_pid() {
	PID=$1
	ps -p "$PID" -o pid,ppid,pgid,command
}

get_proc_info_by_port() {
	PORT=$1
	PID=$(find_pid_by_port "$PORT")

	if [[ -z "$PID" ]]; then
		echo "No process found on port $PORT"
		return 1
	fi

	get_proc_info_by_pid "$PID"
}

# This is a workaround to tell the task runner that a given task is up-to-date,
# without actually running the task to generate the new fingerprint / checksum.
# Ideally, there would be a way to do this directly via the task cli (e.g. `task --mark-up-to-date`)
# See `scripts/task_mark_up_to_date.mjs` for full details`
task_mark_up_to_date() {
	: "${TASKFILE_PATH:="$PWD/Taskfile.yml"}"
	TASK_NAME=$1
	if [[ ! -f "$TASKFILE_PATH" ]]; then
		echo "ERROR: Could not find $TASKFILE_PATH"
		return 1
	fi
	if [[ -z "$TASK_NAME" ]]; then
		echo "ERROR: Please define TASK_NAME"
		return 1
	fi
	TASK_NAME=$TASK_NAME TASKFILE_PATH=$TASKFILE_PATH run_file_in_global_node "$HOME/scripts/task_mark_up_to_date.mjs"
	unset TASKFILE_PATH
}

# This might seem like a lot of code just to wrap ffmpeg's `scale`, but this:
# - Handles rounding auto-heights to be divisible by 2 (which ffmpeg does not)
# - Picks a `_resized` output filename based on the input
# - Prompts for target width if not provided, from selection
ffmpeg_resize() {
	INPUT_FILE=$1
	TARGET_WIDTH=$2
	INPUT_DIR=$(dirname "$INPUT_FILE")
	INPUT_FILE_EXT=$(basename "$INPUT_FILE" | sed -E 's/^.+(\.[^.]+)$/\1/')
	INPUT_FILE_NO_EXT=$(basename "$INPUT_FILE" | sed -E 's/\.[^.]+$//')
	: "${OUTPUT_FILE:="$INPUT_FILE_NO_EXT"_resized"$INPUT_FILE_EXT"}"

	# If target width, not provided, use choices
	if [[ -z "$TARGET_WIDTH" ]]; then
		printf "What should the target width be?\n\t[Aa])1920\n\t[Bb])1280\n\t[Cc])720\n\t[Dd])480\n"
		read -r answer
		case $answer in
			A|a) TARGET_WIDTH=1920 ;;
			B|b) TARGET_WIDTH=1280 ;;
			C|c) TARGET_WIDTH=720 ;;
			D|d) TARGET_WIDTH=480 ;;
			*) echo "Invalid selection" && return 1 ;;
		esac
	fi

	# Get width and height of input file
	INPUT_DIMENSIONS=$(ffprobe -v error -select_streams v -show_entries stream=width,height -of csv=p=0:s=x "$INPUT_FILE")
	print "INPUT_DIMENSIONS = $INPUT_DIMENSIONS"
	if ! TARGET_HEIGHT=$(INPUT_DIMENSIONS=$INPUT_DIMENSIONS TARGET_WIDTH=$TARGET_WIDTH node <<- "EOF"
	const regPatt = /(?<width>\d+)x(?<height>\d+)/i;
	const INPUT_DIMENSIONS = /** @type {`${string}x${string}`} */ (process.env.INPUT_DIMENSIONS);
	const TARGET_WIDTH = parseInt(process.env.TARGET_WIDTH);

	if (!regPatt.test(INPUT_DIMENSIONS)) {
		throw new Error(`Invalid input dimensions (${INPUT_DIMENSIONS})`);
	}

	if (Number.isNaN(TARGET_WIDTH)) {
		throw new Error(`Invalid target width (${TARGET_WIDTH})`);
	}

	const {
		groups: { width: _width, height: _height },
	} = regPatt.exec(INPUT_DIMENSIONS);
	const width = parseInt(_width);
	const height = parseInt(_height);

	let targetHeight = (TARGET_WIDTH * height) / width;

	// Handle rounding auto-heights to be divisible by 2
	if (targetHeight % 2 !== 0) {
		const roundedTargetHeight = Math.round(targetHeight / 2) * 2;
		console.warn(`Rounding auto-height to be divisible by 2: ${targetHeight} -> ${roundedTargetHeight}`);
		targetHeight = roundedTargetHeight;
	}

	console.log(targetHeight);
	EOF
	); then
		echo "ERROR: Could not parse input dimensions"
		return 1
	fi


	echo "Resizing $INPUT_FILE to $TARGET_WIDTH pixels wide (out = $INPUT_DIR/$OUTPUT_FILE)"
	ffmpeg -loglevel warning -stats -i "$INPUT_FILE" -vf scale="$TARGET_WIDTH:$TARGET_HEIGHT" "$INPUT_DIR/$OUTPUT_FILE"
	echo "Rendered to $INPUT_DIR/$OUTPUT_FILE"
	echo "âœ… Done"
}

px_from_rem() {
	REM=$1
	echo "$((16 * REM))"
}

rem_from_px() {
	PX=$1
	echo "$((PX / 16))"
}

# Connect to an AWS EC2 Instance, via instance-connect
# Remember: You can use`AWS_PROFILE=${name}` to set the AWS credential profile
# to use for all the AWS commands
aws_ec2_instance_connect() {
	PORT_BINDINGS=()
	EC2_USERNAME="ec2-user"
	PRIVATE_KEY="$HOME/.ssh/id_rsa"
	PUBLIC_KEY="$HOME/.ssh/id_rsa.pub"
	while [[ ! $# -eq 0 ]]
	do
		case "$1" in
			-i|--instance-id)
				INSTANCE_ID=$2
				shift
				;;
			-u|--username)
				EC2_USERNAME=$2
				shift
				;;
			-p|--port)
				PORT_BINDINGS+=("$2")
				shift
				;;
			-pk|--private-key)
				PRIVATE_KEY=$2
				shift
				;;
			-pub|--public-key)
				PUBLIC_KEY=$2
				shift
				;;
			*)
				echo "Invalid option ${1}"
				;;
		esac
		shift
	done

	if ! (which aws > /dev/null); then
		echo "ERROR: AWS CLI not found"
		return 1
	fi

	# Check format
	if ! [[ $INSTANCE_ID =~ ^i-[a-z0-9]+$ ]]; then
		echo "Invalid instance ID format. Should be I-123abc455"
		return 1
	fi

	if ! [[ -f $PUBLIC_KEY ]] || ! [[ -f $PRIVATE_KEY ]]; then
		echo "ERROR: Could not find public and/or private key"
		return 1
	fi

	# Send public key
	aws ec2-instance-connect \
		send-ssh-public-key \
			--no-paginate \
			--instance-id "$INSTANCE_ID" \
			--instance-os-user "$EC2_USERNAME" \
			--ssh-public-key "file://${PUBLIC_KEY}" | cat > /dev/null

	if [[ $? -ne 0 ]]; then
		echo "ERROR: Could not send public key"
		return 1
	fi

	SSH_ARGS=(-o ServerAliveInterval=20 -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -i "$PRIVATE_KEY")
	if [[ ${#PORT_BINDINGS[@]} -gt 0 ]]; then
		for PORT_BINDING in "${PORT_BINDINGS[@]}"; do
			SSH_ARGS+=(-L "\*:$PORT_BINDING:localhost:$PORT_BINDING")
		done
	fi

	# Establish SSH connection
	DNS_ADDR=$(aws ec2 describe-instances --instance-ids "$INSTANCE_ID" --query 'Reservations[*].Instances[*].[PublicDnsName]' --output text)
	SSH_ARGS+=("${EC2_USERNAME}@${DNS_ADDR}")
	declare -p SSH_ARGS
	ssh "${SSH_ARGS[@]}"
}

large_llm_query() {
	export LC_ALL="C"
	unset IFS
	TEMP_DIR_PATH=$(mktemp -d)
	echo "Using temporary directory $TEMP_DIR_PATH"
	BANNED_FILE_PATTERNS=(
		".env"
		"scratch.py"
	)
	# In addition to text/* (e.g. text/plain, text/x-shellscript)
	EXTRA_ACCEPTED_MIME_TYPES=(
		"application/json"
		"application/ld+json"
	)
	TEMP_PROMPT_FILE="$TEMP_DIR_PATH/.prompt.txt"
	touch "$TEMP_PROMPT_FILE"
	DEBUG=0

	if [[ -z "$GOOGLE_GEMINI_API_KEY" ]]; then
		GOOGLE_GEMINI_API_KEY=$(op item get 'Google_Gemini_API_Key' --vault Private --fields 'credential')
	fi
	if [[ -z "$GOOGLE_GEMINI_API_KEY" ]]; then
		echo "ERROR: Could not find Google_Gemini_API_Key"
		return 1
	fi

	# Hardcode for now
	MODEL="gemini"

	FILENAMES_PASSED_VIA_ARG=()
	RIPGREP_ARGS=()
	GLOB=""
	QUESTION=""
	LLM_PROMPT=""
	while [[ ! $# -eq 0 ]]; do
		case "$1" in
			-rg|--ripgrep-args)
				# Turn string into args arr
				declare -a RIPGREP_ARGS=($(echo $2 | awk '{for(i=1;i<=NF;i++) print $i}'))
				declare -p RIPGREP_ARGS
				shift
				;;
			-g|--glob)
				GLOB=$2
				shift
				;;
			-q|--question)
				QUESTION=$2
				shift
				;;
			-p|--prompt)
				LLM_PROMPT=$2
				shift
				;;
			-m|--model)
				MODEL=$2
				shift
				;;
			-d|--debug)
				DEBUG=1
				;;
			*)
				if [[ -f "$1" ]]; then
					FILENAMES_PASSED_VIA_ARG+=("$1")
				else
					echo "Invalid option ${1}"
				fi
				;;
		esac
		shift
	done

	if [[ $MODEL != "gemini" ]]; then
		echo "Not yet implemented support for $MODEL"
		return 1
	fi

	if [[ ${#FILENAMES_PASSED_VIA_ARG[@]} -eq 0  ]] && [[ -z "$GLOB" ]] && [[ ${#RIPGREP_ARGS[@]} -eq 0 ]]; then
		echo "What different search terms should be used to search?"
		echo "Press enter to add another, type EOF to end query"
		AT_LEAST_ONE_SEARCH_DONE=0
		RIPGREP_ARGS+=("-l" "-i")
		while true; do
			read -r SEARCH_TERM
			if [[ -z "$SEARCH_TERM" ]] || [[ "$SEARCH_TERM" == "EOF" ]]; then
				break
			fi
			AT_LEAST_ONE_SEARCH_DONE=1
			RIPGREP_ARGS+=("-e" "$SEARCH_TERM")
		done
		if [[ $AT_LEAST_ONE_SEARCH_DONE -eq 0 ]]; then
			echo "ERROR: Must provide at least one search term"
			return 1
		fi
	fi

	if [[ ${#FILENAMES_PASSED_VIA_ARG[@]} -eq 0  ]] && [[ -z "$GLOB" ]] && [[ ${#RIPGREP_ARGS[@]} -eq 0 ]]; then
		echo "ERROR: Must provide ripgrep arguments (-rg / --ripgrep-args), glob (-g / --glob), or filenames."
		return 1
	fi

	# If neither `--prompt` nor `--question` was not passed, ask user / read from stdin
	if [[ -z "$LLM_PROMPT" ]] && [[ -z "$QUESTION" ]]; then
		echo "Enter question:"
		read -r QUESTION
		if [[ -z "$QUESTION" ]]; then
			echo "ERROR: Must provide a question (or prompt, with --prompt)"
			return 1
		fi
	fi

	# Make sure `--file` is included in args
	# If not, PREpend it as first arg
	# if [[ ! " ${RIPGREP_ARGS[*]} " =~ " --files " ]]; then
	# 	RIPGREP_ARGS=("--files" "${RIPGREP_ARGS[@]}")
	# fi

	# Prepare base prompt / prefix
	if [[ -z "$LLM_PROMPT" ]]; then
		cat > "$TEMP_PROMPT_FILE" <<- EOF
		You are an expert programmer, and someone has asked you to answer the following

		Question: $QUESTION

		You need to answer - preferably ONLY with references to the below reference material. Try to be as accurate as possible; cite files used to form your answer, and even line numbers if possible.

		Each file below is separated like so:

		---
		File: FILE_NAME
		FILE_CONTENTS
		---

		Here is the reference material / files:

		---
		EOF
	else
		echo "$LLM_PROMPT" > "$TEMP_PROMPT_FILE"
	fi

	dump_file_to_prompt() {
		FILE_PATH=$1
		if ! [[ -f $FILE_PATH ]]; then
			return 0
		fi
		# Check for binary / non-plain-text (against `ACCEPTED_FILE_MATCHES`)
		FILE_MIME_TYPE=$(file -b --mime-type $FILE_PATH)
		if [[ " ${BANNED_FILE_PATTERNS[*]} " =~ " ${FILE_PATH} " ]]; then
			echo "WARNING: Skipping $FILE_PATH; banned file pattern found"
			return 0
		fi
		if ! [[ $FILE_MIME_TYPE == "text/"*  ]] && ! [[ " ${EXTRA_ACCEPTED_MIME_TYPES[*]} " =~ " ${FILE_MIME_TYPE} " ]]; then
			echo "WARNING: Skipping $FILE_PATH; non-parseable mime-type found ($FILE_MIME_TYPE)"
			return 0
		fi
		echo "Dumping file to prompt: $FILE_PATH"
		FILE_CONTENTS_WITH_LINE_NUMBERS=$(cat -n "$FILE_PATH")
		# Remove leading indent
		# shellcheck disable=SC2001
		FILE_CONTENTS_WITH_LINE_NUMBERS=$(echo "$FILE_CONTENTS_WITH_LINE_NUMBERS" | sed 's/^[[:space:]]*//')
		cat >> "$TEMP_PROMPT_FILE" <<- EOF
		File: $FILE_PATH
		$FILE_CONTENTS_WITH_LINE_NUMBERS
		---
		EOF
	}

	# Iterate  over files
	for FILE_PATH in "${FILENAMES_PASSED_VIA_ARG[@]}"; do
		dump_file_to_prompt "$FILE_PATH"
	done
	if [[ -n $GLOB ]]; then
		if [[ $SHELL_TYPE != "ZSH" ]]; then
			echo "TODO verify glob behavior in other shells"
			return 1
		fi

		# Note: `~` for glob expansion is a zsh-ism
		# shellcheck disable=SC2296
		# shellcheck disable=SC2206
		FILE_LIST=(${~GLOB})

		for FILE_PATH in "${FILE_LIST[@]}"; do
			dump_file_to_prompt "$FILE_PATH"
		done
	else
		declare -p RIPGREP_ARGS
		for FILE_PATH in $(rg "${RIPGREP_ARGS[@]}"); do
			# TODO support partial file extraction, so to save on some tokens
			# e.g., include X number of lines around search term(s)
			dump_file_to_prompt "$FILE_PATH"
		done
	fi

	cat <<- EOF
	Prompt Stats:
		Line Count = $(wc -l < "$TEMP_PROMPT_FILE")
		Word Count = $(wc -w < "$TEMP_PROMPT_FILE")
	EOF

	# Warning: Technically, this could be done in pure bash, but there are a lot of oddities around
	# escaping, line breaks, and space expansion across shells, that makes this really error-prone
	# Leaving this partial attempt commented out for now
	# ESCAPED_PROMPT_STRING=$(cat $TEMP_PROMPT_FILE | jq -Rsa .)
	## Keep line breaks as literal line breaks / escaped
	# ESCAPED_PROMPT_STRING_FINAL=$(LC_ALL=en_US.UTF-8 echo "$ESCAPED_PROMPT_STRING" | sed 's/$/\\\\n/' | tr -d '\n')

	# Also worth noting that we are actually double-escaping here, due to the nature
	# of the heredoc and having to escape the shell first

	POST_BODY=$(TEMP_PROMPT_FILE=$TEMP_PROMPT_FILE node <<- EOF
	let TEMP_PROMPT_FILE_CONTENTS = require('fs').readFileSync(process.env.TEMP_PROMPT_FILE, 'utf8');
	// Remove any CR (e.g., from a CRLF file dumped to prompt)
	TEMP_PROMPT_FILE_CONTENTS = TEMP_PROMPT_FILE_CONTENTS.replace(/\r/g, '');
	// Double escape tabs
	TEMP_PROMPT_FILE_CONTENTS = TEMP_PROMPT_FILE_CONTENTS.replace(/\t/g, '\\\\t');
	// Double backslashes
	TEMP_PROMPT_FILE_CONTENTS = TEMP_PROMPT_FILE_CONTENTS.replace(/\\\\/g, '\\\\\\\\');
	// Double escape newlines to avoid shell expansion
	TEMP_PROMPT_FILE_CONTENTS = TEMP_PROMPT_FILE_CONTENTS.replace(/\n/g, '\\\\n');
	console.log(JSON.stringify({
		contents: [{
			parts: [{
				text: TEMP_PROMPT_FILE_CONTENTS
			}]
		}]
	}));
	EOF
	)

	echo "$POST_BODY" > "$TEMP_DIR_PATH/.prompt_req.json"

	while true; do
		printf "Are you sure you want to send off the prompt? [Yy]es / ENTER, [Cc]ancel / [Nn]o\n"
		read -r answer
		case $answer in
			[Yy]*) break ;;
			"") break ;;
			[Cc]*) return 0 ;;
			[Nn]*) return 0 ;;
		esac
	done

	# Actually make request
	# Make sure to use `-d @file` to avoid "argument list too long"
	response=$(curl "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?key=$GOOGLE_GEMINI_API_KEY" \
		-H 'Content-Type: application/json' \
		-X POST \
		-d @"$TEMP_DIR_PATH/.prompt_req.json"
	)
	echo "$response" > "$TEMP_DIR_PATH/.prompt_res.json"

	# Combine all `candidates.contents.parts[].text`
	# Double-escape line breaks again
	response=$response node <<- EOF
	let combined = '';
	const response = JSON.parse(process.env.response);
	response.candidates.forEach(can => {
		if (can.finishReason !== 'STOP') {
			console.warn('Unusual finish reason:', can.finishReason);
			return;
		}
		can.content.parts.forEach(p => {
			combined += p.text;
		})
	});
	if (combined) {
		console.log('===== Server Response =====');
		console.log(combined);
		console.log('=============================')
	}
	EOF

	# If response errored out and/or parsing failed dump response
	if [[ $? -ne 0 ]]; then
		echo "Error parsing response"
		echo "$response"
		return 1
	fi

	echo "Done!"
	if [[ $DEBUG -eq 1 ]]; then
		echo "You can inspect the full prompt and response in $TEMP_DIR_PATH"
	else
		rm -r "$TEMP_DIR_PATH"
		echo "Deleted temporary prompt files"
	fi

}

# This is currently pretty macoS specific
# Also, runs code that triggers OS permission checks, so will fail if denied
whats_up() {
	WINDOW_TITLE=$(cat << "EOF" | xargs -0 osascript -e
global frontApp, frontAppName, windowTitle

set windowTitle to ""
tell application "System Events"
	set frontApp to first application process whose frontmost is true
	set frontAppName to name of frontApp
	tell process frontAppName
		tell (1st window whose value of attribute "AXMain" is true)
			set windowTitle to value of attribute "AXTitle"
		end tell
	end tell
end tell

return {frontAppName, windowTitle}
EOF
)
	STATUS_STRING=$(cat << EOF
Active Window = $WINDOW_TITLE
EOF
)

	if (npx --package jtz-time-tracker-utils jttu --version > /dev/null); then
		STATUS_STRING=$(cat << EOF
$STATUS_STRING
==== Time Tracker ====
$(npx --package jtz-time-tracker-utils jttu harvest status)
======================
EOF
)
	fi
	echo "$STATUS_STRING"
}
