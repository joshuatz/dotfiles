#!/usr/bin/env bash

get_shell_type() {
	if [[ -n "$ZSH_VERSION" ]] || echo $SHELL | grep --silent -E "\/zsh$"; then
		echo "ZSH"
		return
	elif [[ -n "$BASH_VERSION" ]] || echo $SHELL | grep --silent -E "\/bash$"; then
		echo "BASH"
	fi
}
SHELL_TYPE=$(get_shell_type)
IS_MAC=0
if [[ "$OSTYPE" == "darwin"* ]]; then
	IS_MAC=1
fi

# Not perfect across all OSes, but a "good enough" approach for most
get_computer_name() {
	if (which scutil > /dev/null); then
		scutil --get ComputerName
		return 0
	fi
	uname -n | sed -e 's/\.local$//'
}

pretty_path() {
	echo "$PATH" | tr ':' '\n'
}

# You can use this to parse version strings and then use the resulting number for comparison
# Example:
#     if [[ $(parse_version_string $(git --version | grep -E -o "\d+\.\d+.\d+$")) -ge $(parse_version_string "2.39.0") ]]
# https://stackoverflow.com/a/37939589/11447682
function parse_version_string { echo "$@" | awk -F. '{ printf("%d%03d%03d%03d\n", $1,$2,$3,$4); }'; }

reload() {
	if [[ $SHELL_TYPE == "ZSH" ]]; then
		# Note: Don't use source ~/.zshrc
		# See: https://github.com/ohmyzsh/ohmyzsh/wiki/FAQ#how-do-i-reload-the-zshrc-file
		exec zsh
	elif [[ $SHELL_TYPE == "BASH" ]]; then
		source ~/.bash_profile
	else
		echo "Not sure how to reload this shell"
	fi
}

get_clipboard_contents() {
	if (which pbpaste > /dev/null); then
		pbpaste
	elif (which xclip > /dev/null); then
		xclip -selection clipboard -o
	elif (which wl-paste > /dev/null); then
		wl-paste
	else
		echo "ERROR: Could not find a clipboard utility"
	fi
}

copy_to_clipboard() {
	if (which pbcopy > /dev/null); then
		pbcopy
	elif (which xclip > /dev/null); then
		xclip -selection clipboard
	elif (which wl-copy > /dev/null); then
		wl-copy
	else
		echo "ERROR: Could not find a clipboard utility"
	fi
}

convert_clipboard_to_plaintext() {
	# Takes the clipboard contents and converts it to plaintext, in-place
	text=$(get_clipboard_contents)
	echo "$text" | copy_to_clipboard
}

copy_html_to_clipboard() {
	html="$1"
	plaintext="$2"
	# Fallback to HTML as plaintext if not set
	if [[ -z "$plaintext" ]]; then
		plaintext="$html"
	fi
	if [[ $IS_MAC -eq 1 ]]; then
		# If HTML is not prefixed with meta charset tag, add it
		if [[ -z "$NO_WRAP" ]] && (! echo "$html" | grep -q -E "^<meta charset"); then
			html="<meta charset=\"utf-8\">${html}"
		fi

		# https://stackoverflow.com/a/11089226/11447682
		# https://aaron.cc/copying-the-current-safari-tab-as-a-to-the-clipboard-as-a-clickable-link/
		html_hex=$(echo -n "$html" | hexdump -ve '1/1 "%.2x"')
		if [[ -n "$NO_PLAIN" ]]; then
			osascript <<- EOF
				set the clipboard to «data HTML${html_hex}»
			EOF
			return
		fi
		osascript <<- EOF
			set the clipboard to {«class HTML»:«data HTML${html_hex}», string:"${plaintext}"}
		EOF
	else
		echo "$html" | xclip -selection clipboard -t text/html
	fi
}

markdown_to_html_clipboard() {
	md="$1"
	# If no arg, grab from clipboard
	if [[ -z "$md" ]]; then
		md=$(get_clipboard_contents)
	fi
	html=""
	if (which pandoc > /dev/null); then
		html=$(echo "$md" | pandoc -f markdown -t html)
	else
		html=$(npx marked --gfm -s "$md")
	fi
	copy_html_to_clipboard "$html" "$md"
	echo "✅ HTML copied to clipboard"
}

date_iso() {
	# 2020-11-28T12:11:28Z
	date -u +"%Y-%m-%dT%H:%M:%SZ"
}

date_ms() {
	if which gdate > /dev/null; then
		gdate +%s%3N
	else
		date +%s000
		# echo "WARNING: gdate not found; faking millseconds from seconds"
	fi
}

# Like `touch` + `mkdir -p`: creates intermediate directories if they don't exist yet
make-file() {
	file_path=$1
	if [[ -e $file_path ]]; then
		echo "File already exists"
	else
		mkdir -p "$(dirname "$file_path")"
		touch "$file_path"
	fi
}

get_cpu_throttle_info() {
	if [[ $* == *--watch* ]]; then
		pmset -g thermlog
		return
	fi
	pmset -g therm
}

make_venv() {
	VENV_PATH=./.venv
	echo "Where should the virtual environment be created? (press enter to default to .venv)"
	read -r INPUT
	if [[ $INPUT != "" ]]; then
		VENV_PATH=$INPUT
	fi
	if [[ -d $VENV_PATH ]]; then
		echo "${VENV_PATH} already exists"
	else
		echo "Preparing virtual environment in ${VENV_PATH}"
		python3 -m venv $VENV_PATH
		source $VENV_PATH/bin/activate
	fi
}

check_venv() {
	which python | grep "$PWD"
}

# Generates the poetry named environment string
# Although this _can_ be used to check that the correct virtual environment is
# activated, it is generally much easier to just use a regular venv and point
# poetry to it (because then you can just do something like `which python | grep $PWD`)
# For implementation reference see
#   https://github.com/python-poetry/poetry/blob/7c86992909257caa4f51a50c001f5894bfe5065e/src/poetry/utils/env.py#L635
#   https://github.com/python-poetry/poetry/blob/7c86992909257caa4f51a50c001f5894bfe5065e/src/poetry/utils/env.py#L1212-L1220
generate_poetry_env_name_str() {
	PROJECT_NAME=$(basename "$PWD")
	if [[ -f pyproject.toml ]]; then
		PROJECT_NAME=$(poetry version | sed -E -n 's/(.+) [.0-9]+$/\1/p')
	fi
	PROJECT_NAME=$PROJECT_NAME python << "EOF"
import base64
import os
import re
import hashlib

# shim - re-implement poetry encode method
def encode(string: str):
	if isinstance(string, bytes):
		return string
	return string.encode("utf-8")

def generate_env_name(package_name: str, cwd: str) -> str:
	package_name = package_name.lower()
	sanitized_name = re.sub(r'[ $`!*@"\\\r\n\t]', "_", package_name)[:42]
	normalized_cwd = os.path.normcase(os.path.realpath(cwd))
	h_bytes = hashlib.sha256(encode(normalized_cwd)).digest()
	h_str = base64.urlsafe_b64encode(h_bytes).decode()[:8]
	return f"{sanitized_name}-{h_str}"

cwd = os.getcwd()
print(generate_env_name(os.environ["PROJECT_NAME"], cwd))
# Should print something like `project-name-ABCD1a-Z`
EOF
}

# Search for, and activate, a local python virtual environment
# @TODO - if python env is *already* activated, check if path matches, and if not
# 	deactivate and then activate
# @TODO - handle Poetry
activate() {
	fail=1
	possible_envs=(./venv ./.venv ./env ./.env)
	for env_dir in "${possible_envs[@]}"; do
		if [[ -e "$env_dir/bin/activate" ]]; then
			source "$env_dir/bin/activate"
			fail=0
			break
		fi
	done
	return $fail
}

pip_upgrade() {
	python3 -m pip install --upgrade pip
}

# Like clear, but extra space to pad the start
wipe() {
	for run in {1..10}; do
		echo $'\n'
	done
	clear
}

render_image() {
	IMAGE_PATH=$1

	# ImageMagick
	if (which display > /dev/null); then
		# Sometimes can be installed, but misconfigured. Can use a simple` --version`
		# check to verify
		if (display --version > /dev/null 2>&1); then
			display "$IMAGE_PATH"
			return
		else
			echo "WARNING: ImageMagick installed, but not configured correctly"
		fi
	fi

	if (which chafa > /dev/null); then
		chafa "$IMAGE_PATH"
		return
	fi

	echo "ERROR: Could not find a suitable image viewer"
	return 1
}

# Note: This is ZSH specific; todo - make agnostic?
reload_func() {
	unfunction "_$1" && compinit
}

# Revert the last commit, but don't undo the changes
git_revert_last() {
	git reset HEAD~1
}

git_sha() {
	short=$(git rev-parse --short HEAD)
	long=$(git rev-parse HEAD)
	echo "${short}\t${long}"
}

git_trunk_branch() {
	git remote show origin | grep "HEAD branch" | cut -d ":" -f 2 | sed -e 's/^[[:space:]]*//'
}

git_trunk_ahead_files() {
	TRUNK_BRANCH=$(git_trunk_branch)
	git fetch
	git --no-pager diff --name-only origin/"$TRUNK_BRANCH"...HEAD
}

# This should essentially be the file list of the diff for your `push`
git_local_ahead_of_remote_files() {
	CURRENT_BRANCH=$(git_branch_name)
	git fetch
	git --no-pager diff --name-only origin/"$CURRENT_BRANCH"...HEAD
}

git_update_local_trunk() {
	TRUNK_BRANCH=$(git_trunk_branch)
	CURRENT_BRANCH=$(git_branch_name)
	if [[ "$TRUNK_BRANCH" == "$CURRENT_BRANCH" ]]; then
		git pull
		return
	fi
	git fetch . origin/"$TRUNK_BRANCH":"$TRUNK_BRANCH"
}

git_behind_ahead() {
	# Get the trunk / main branch in the repo (e.g. `main`)
	TRUNK_BRANCH=$(git_trunk_branch)
	git fetch
	echo "Behind | Ahead"
	echo "      $(git rev-list --left-right --count origin/"$TRUNK_BRANCH"...HEAD)"
}

git_select_commit() {
	MAX_PAST_COMMITS_TO_LIST=40
	commits=$(git log --pretty=format:"%H %s" -n $MAX_PAST_COMMITS_TO_LIST)

	# Use fzf to interactively select a commit
	commit=$(echo "$commits" | fzf --height 70% --reverse --ansi)

	# Extract the commit hash from the selected line
	commit_hash=$(echo "$commit" | awk '{print $1}')

	echo "$commit_hash"
}

git_copy_commit() {
	commit_hash=$(git_select_commit)
	echo "$commit_hash" | copy_to_clipboard
}

# Use this to interactively select a past commit to target for `git commit --fixup=`
git_fixup() {
	commit_hash=$(git_select_commit)
	git commit --fixup="$commit_hash"
}


# TODO: This works, but really should be re-written in JS or Python
# (too many ZSH and bash workarounds, hard to read)
git_find_fixup_base() {
	array_index_start=0
	if [[ "$SHELL_TYPE" == "ZSH" ]]; then
		# cmon y'all, can't we just agree on things for once?
		array_index_start=1
	fi
	MAX_PAST_COMMITS_TO_SCAN_PER_FIXUP=40
	LOG_DIVIDER=$(echo $'\x1F')
	seeking_commit_msgs=()
	commit_scan_counter=0
	# Iterate over all git log entries
	git log --pretty=format:"%H${LOG_DIVIDER}%s" | while read line
	do
		# Check if we already at limit and need to bail out
		commit_scan_counter=$((commit_scan_counter+1))
		if [[ $commit_scan_counter -gt $MAX_PAST_COMMITS_TO_SCAN_PER_FIXUP ]]; then
			echo "Could not find the ultimate fixup base, and limit of $MAX_PAST_COMMITS_TO_SCAN_PER_FIXUP scan commits reached"
			echo "Still seeking / could not find within limit:"
			printf "\t%s\n" "$(declare -p seeking_commit_msgs)"
			return 1
		fi

		# Extract out commit hash and message from git log line
		commit_hash=$(echo "$line" | awk -F"$LOG_DIVIDER" '{ print $1 }')
		commit_msg=$(echo "$line" | awk -F"$LOG_DIVIDER" '{ print $2 }')

		# Is this a `fixup! {original message}` commit?
		if [[ "$commit_msg" == "fixup! "* ]]; then
			# Add message, without `fixup! ` prefix, to search list
			target_commit_msg=${commit_msg#"fixup! "}
			seeking_commit_msgs+=("$target_commit_msg")

			# Reset the scan counter, so we can search x num past this new point
			commit_scan_counter=0
		elif [[ ${#seeking_commit_msgs[@]} -gt 0 ]]; then
			# Remove all fixups that fix this commit
			holes_count=0
			for ((i=0; i<${#seeking_commit_msgs[@]}; i++)); do
				if [[ ${seeking_commit_msgs[$i+$array_index_start]} == "$commit_msg" ]]; then
					unset -v 'seeking_commit_msgs[$i+$array_index_start]'
					holes_count=$((holes_count+1))
				fi
			done

			# Are we done yet?
			if [[ $holes_count -eq ${#seeking_commit_msgs[@]} ]]; then
				echo "${commit_hash}~1"
				return 0
			fi

			# Remove holes / sparse -> dense
			# Not double-quoting this is the easiest way to do this without
			# accidentally leaving empty strings
			# shellcheck disable=SC2128
			# shellcheck disable=SC2206
			seeking_commit_msgs=($seeking_commit_msgs)
		fi
	done
}

# Use this with `--fixup` commits, to auto-target the last commit before fixup
# with interactive rebase
git_auto_rebase() {
	new_target_base=$(git_find_fixup_base)

	if [[ $? -ne 0 ]]; then
		echo "$new_target_base"
		echo "Could not auto-find new base. Cancelling auto-rebase"
		return 1
	fi

	while true; do
		echo "Found target base:"
		printf "\t%s\n" "$new_target_base"
		printf "\t%s\n Target Base = " "$(git show --no-patch --oneline "$new_target_base" | cat)"
		printf "Continue? [Yy]es / ENTER, [Nn]o, [Cc]ancel\n"
		read -r answer
		case $answer in
			[Yy]*) break ;;
			"") break ;;
			[Nn]*) return 0 ;;
			[Cc]*) return 0 ;;
		esac
	done

	git rebase --autosquash --interactive "$new_target_base"
}


git_branch_name() {
	git rev-parse --abbrev-ref HEAD
}

# NOTE: This returns the remote branch name, prefixed with the name of the remote itself
# E.g.
#	`origin/my-branch`
git_remote_branch() {
	# https://stackoverflow.com/a/9753364/11447682
	git for-each-ref --format='%(upstream:short)' "$(git symbolic-ref -q HEAD)"
}

git_remote_url() {
	git remote get-url origin
}

git_branch_backup() {
	current_branch_name=$(git rev-parse --abbrev-ref HEAD)
	backup_branch_name="backup/$current_branch_name--$(date '+%Y-%m-%d--%I-%M-%p')"
	git branch "$backup_branch_name"
	echo "✅ Backed up branch to $backup_branch_name"
}

git_checkout_dirty() {
	target_branch_name=$1
	operation="git checkout $target_branch_name"
	git_do_while_dirty "$operation"
}
if [[ $SHELL_TYPE == "ZSH" ]]; then
	:
	# TODO: This is close, but not working perfectly
	# compdef _git git_checkout_dirty=git-checkout
fi

git_do_while_dirty() {
	git_operation="$*"
	IFS=

	# If no operation was provided, default to very last command
	if [[ -z "$git_operation" ]]; then
		git_operation=$(fc -ln -1)
		echo "No command passed. Did you want to retry your last command?"
		printf "\t%s\n" "$git_operation"
		while true; do
			printf "Retry? [Yy]es / ENTER, [Nn]o, [Cc]ancel\n"
			read -r answer
			case $answer in
				[Yy]*) break ;;
				"") break ;;
				[Nn]*) return 0 ;;
				[Cc]*) return 0 ;;
			esac
		done
	fi


	# If user forgot to include `git`, add it for them. E.g., passing `pull` instead of `git pull`
	if [[ $git_operation != git* ]]; then
		git_operation="git $git_operation"
	fi

	echo "Operation to try = '$git_operation'"

	# Error out when command is NOT run from root of git repo, as this can cause issues with things
	# like `git checkout ${PATHSPEC}`, as the paths git's stdout uses are relative to repo root,
	# even if you running command from subdirectory
	git_root=$(git rev-parse --show-toplevel)
	if [[ "$git_root" != "$PWD" ]]; then
		echo "ERROR: You are not running this command from the root of a git repository"
		echo "This can cause issues with things like \`git checkout\`, as the paths git's stdout"
		echo "uses are relative to repo root, even if you running command from subdirectory"
		echo "Current directory: $PWD"
		echo "Git root: $git_root"
		return 1
	fi

	git_operation_results=$($SHELL -c "$git_operation" 2>&1)

	# If operation was clean, nothing to do
	error_string_test=$(echo "$git_operation_results" | grep -E "error: Your local changes to the following files would be overwritten by")

	# TODO: Add check for `error: The following untracked working tree files would be overwritten by merge:`

	echo "$error_string_test"
	if [[ "$error_string_test" == "" ]]; then
		echo "Operation was clean"
		return 0
	fi

	# Get list of conflicting file paths
	dirty_files=$(echo "$git_operation_results" | grep -E -o "^[[:blank:]]+.*" | sed -e 's/^[[:space:]]*//')
	cat << EOF
========= DIRTY FILES =========
$dirty_files
===============================
EOF

	# Use stash to temporarily stash changes
	# Newer versions of git can support stashing just staged changes
	use_staged_stash=false
	git_version=$(git --version | grep -E -o "\d+\.\d+.\d+$")
	if [[ $(parse_version_string "$git_version") -ge $(parse_version_string "2.35") ]]; then
		echo "Found git version >= 2.3"
		echo "Your git version supports staged stashes."
		use_staged_stash=true
	else
		while true; do
			printf "Your git version does NOT support staged stashes. Continue? [Yy]es / ENTER, [Nn]o, [Cc]ancel\n"
			read -r answer
			case $answer in
				[Yy]*) break ;;
				"") break ;;
				[Nn]*) return 0 ;;
				[Cc]*) return 0 ;;
			esac
		done
	fi

	ITEMS_PRESERVED=0
	# Go through list of conflicting files and ask what the user wants to do
	preserve="unsure"
	# different fd (`<&9`) is to avoid conflict with inner `read`
	# https://stackoverflow.com/q/6911520/11447682
	while IFS= read -r dirty_file <&9; do
		if [[ $preserve == "unsure" ]]; then
			while true; do
				# Ask user what to do about this (and rest) of files
				printf "Keep changes to %s?\n" "$dirty_file"
				printf "[Aa]ll files, [Yy]es / ENTER, [Nn]o, / [Dd]rop+rest, [Pp]review, [Cc]ancel\n"
				read -r answer
				case $answer in
					[Aa]*) preserve="all" && break ;;
					[Yy]*) preserve="yes" && break ;;
					"") break ;;
					[Nn]*) preserve="no" && break ;;
					[Dd]*) preserve="none" && break ;;
					[Pp]*) git diff "$dirty_file" ;;
					[Cc]*) return 0 ;;
				esac
			done
		fi

		if [[ $preserve == "none" ]]; then
			git checkout "$dirty_file"
		elif [[ $preserve == "all" ]]; then
			git add "$dirty_file"
			ITEMS_PRESERVED=$((ITEMS_PRESERVED+1))
		else
			if [[ $preserve == "yes" ]]; then
				git add "$dirty_file"
				ITEMS_PRESERVED=$((ITEMS_PRESERVED+1))
			else
				git checkout "$dirty_file"
			fi
			# Reset for next go-around
			preserve="unsure"
		fi
	done 9<<< "$dirty_files"

	if [[ $ITEMS_PRESERVED -gt 0 ]]; then
		if [[ $use_staged_stash == "true" ]]; then
			git stash --staged
		else
			git stash
		fi
	fi

	# Actually do the thing
	$SHELL -c "$git_operation"

	if [[ $ITEMS_PRESERVED -gt 0 ]]; then
		git stash pop
	fi
}

# You can use this to delete branch names nested under a slash (or other patterns)
#	Example: `git_branch_delete_pattern feature-a/tmp/*`
git_branch_delete_pattern() {
	git_branch_pattern=$1
	matching_branches=$(git branch --list "$git_branch_pattern")
	echo "This will delete the following branches"
	echo "$matching_branches"
	hard_delete=0
	while true; do
		printf "Are you sure? [Yy]es / ENTER, [Hh]ard delete, [Cc]ancel / [Nn]o\n"
		read -r answer
		case $answer in
			[Yy]*) break ;;
			[Hh]*) hard_delete=1 && break ;;
			"") break ;;
			[Cc]*) return 0 ;;
			[Nn]*) return 0 ;;
		esac
	done
	if [[ $hard_delete == 1 ]]; then
		echo "$matching_branches" | xargs git branch -D
		return 0
	fi
	echo "$matching_branches" | xargs git branch -d
}

git_stats() {
	git fetch
	CURRENT_BRANCH=$(git_branch_name)
	REMOTE_BRANCH=$(git_remote_branch)
	remote_diff_stats=$(git diff --stat "$REMOTE_BRANCH" | tail -n 1)
	TRUNK_BRANCH=$(git_trunk_branch)
	trunk_diff_stats=$(git diff --staged --stat "origin/$TRUNK_BRANCH" | tail -n 1)
	behind_ahead=$(git_behind_ahead)
	cat <<- EOF
		Branch = $CURRENT_BRANCH
		Trunk Branch = $TRUNK_BRANCH
		Trunk Diff Stats = $trunk_diff_stats
		Remote Branch = $REMOTE_BRANCH
		Remote Diff Stats = $remote_diff_stats
		Behind / Ahead = $behind_ahead
	EOF
}

# Get information about the state of things while stopped during a rebase
git_rebase_info() {
	# TODO
	:
}

git_tree_view() {
	ALL=1
	while true; do
		printf "What to show? [Aa]ll / ENTER, Current [Bb]ranch\n"
		read -r answer
		case $answer in
			[Aa]*) break ;;
			"") break ;;
			[Bb]*) ALL=0 && break ;;
			[Cc]*) return 0 ;;
		esac
	done
	if [[ $ALL == 1 ]]; then
		git log --graph --oneline --decorate --all
	else
		git log --graph --oneline --decorate
	fi
}

docker_pick_container() {
	container_list=$(docker ps --format "table {{.ID}}\t{{.Image}}\t{{.Names}}")
	container=$(echo "$container_list" | fzf --height 40% --reverse --header-lines=1)
	container_id=$(echo "$container" | awk '{print $1}')
	echo "$container_id"
}

docker_exec_it() {
	CONTAINER_REF=$(docker_pick_container)
	docker exec -it "$CONTAINER_REF" bash
}

docker_get_working_dir() {
	CONTAINER_REF=$1
	docker inspect --format='{{json .Config.Labels}}' "$CONTAINER_REF" | jq '.["com.docker.compose.project.working_dir"]'
}

# Pick a small(ish) docker image; useful for various ephemeral purposes
docker_pick_minimal_image_name() {
	select image in "busybox (smallest, no bash)" "alpine (small, no bash)" "debian (w/bash)" "ubuntu (w/bash)"; do
		case $image in
			# https://hub.docker.com/_/busybox
			busybox*) echo "busybox" && break ;;
			# https://hub.docker.com/_/alpine
			alpine*) echo "alpine" && break ;;
			# https://hub.docker.com/_/debian
			debian*) echo "debian" && break ;;
			# https://hub.docker.com/_/ubuntu
			ubuntu*) echo "ubuntu" && break ;;
			*) echo "Invalid selection" ;;
		esac
	done
}

# Uses a temporary (small) docker container to mount a volume for inspection
docker_inspect_volume() {
	VOLUME_NAME=$1
	if ! (docker volume ls | grep "$VOLUME_NAME$" > /dev/null); then
		echo "Volume not found"
		return 1
	fi
	IMAGE_NAME=$(docker_pick_minimal_image_name)
	IMAGE_SHELL=$(echo "$IMAGE_NAME" | grep -q -E "busybox|alpine" && echo "sh" || echo "bash")
	cat <<- EOF
		Temp Image = $IMAGE_NAME
		Shell = $IMAGE_SHELL
		Volume = $VOLUME_NAME
		Container Mount = /tmp/volume

		Have fun inspecting!
	EOF
	docker run --rm -it -v "$VOLUME_NAME":/tmp/volume "$IMAGE_NAME" "$IMAGE_SHELL" -c "cd /tmp/volume; exec $IMAGE_SHELL"
}

docker_inspect_image() {
	: "${DOCKER_SHELL:="bash"}"
	all_images=$(docker image ls --format "table {{.Repository}}:{{.Tag}}\t{{.ID}}")
	selected_image=$(echo "$all_images" | fzf --height 40% --reverse --header-lines=1)
	image_id=$(echo "$selected_image" | awk '{print $2}')
	docker run --rm -it "$image_id" "/bin/$DOCKER_SHELL"
}

# Find the true global package dir / bin for a brew installed package
# e.g. `brew_find_global_pkd_dir fzf` -> `/usr/local/Cellar/fzf/0.45.0`
brew_find_global_pkd_dir() {
	PACKAGE_NAME=$1
	readlink -f "$(brew --prefix "$PACKAGE_NAME")"
}

npm_find_npx_global_pkg_dir() {
	PACKAGE_NAME=$1
	find "$HOME/.npm/_npx" -type d -name "$PACKAGE_NAME"
}

# NOTE: This is for packages installed with `-g`, not those installed via npx
# For npx, use `npm_find_npx_global_pkg_dir`, for which each package gets an isolated
# subdir, not a shared node_modules
npm_find_global_node_modules() {
	asdf_exec_with_global_version npm root -g
}

npm_find_global_pkg_dir() {
	PACKAGE_NAME=$1
	GLOBAL_NODE_MODULES=$(npm_find_global_node_modules)
	# Make sure to scan for symlinks as well, to handle `npm link` and friends
	found_dir=$(find -L "$GLOBAL_NODE_MODULES" -type d -depth 1 -name "$PACKAGE_NAME")
	if [[ -z "$found_dir" ]]; then
		echo "ERROR: Could not find $PACKAGE_NAME in global node_modules"
		return 1
	fi
	echo "$found_dir" | head -n 1
}

# Generate an ESM import statement, out of your global node_modules
# Pretty hacky: not many good reasons to use this, other than for fiddling around
# @see run_...in_global_node fns for a slightly better approach (but still hacky / just for fiddling)
scaffold_global_node_import() {
	PACKAGE_NAME=$1
	PACKAGE_DIR=$(npm_find_global_pkg_dir "$PACKAGE_NAME")
	copy_to_clipboard <<- EOF
	import {} from '$PACKAGE_DIR'
	EOF
}

run_file_in_global_node() {
	GLOBAL_NODE_MODULES=$(npm_find_global_node_modules)
	# TODO clean this up with piping?
	FILE_TO_EXEC="$1"
	FILENAME=$(basename "$FILE_TO_EXEC")
	# no-clobber
	cp -n "$FILE_TO_EXEC" "$GLOBAL_NODE_MODULES/"
	# WARNING: This might seem super hacky - why not just use `NODE_PATH=$GLOBAL_NODE_MODULES`?
	# Well, that *would* work, except for that they decided to ignore `NODE_PATH` when
	# moving to ESM `import` 🙃
	# https://nodejs.org/api/esm.html#esm_no_node_path
	(
		cd "$GLOBAL_NODE_MODULES" || exit
		node "$FILENAME"
	)
	rm "$GLOBAL_NODE_MODULES/$FILENAME"
}

run_raw_js_in_global_node() {
	RAW_CODE_TO_RUN=$1
	GLOBAL_NODE_MODULES=$(npm_find_global_node_modules)
	(
		cd "$GLOBAL_NODE_MODULES" || exit
		node --eval "$RAW_CODE_TO_RUN"
	)
}

repl_in_global_node() {
	GLOBAL_NODE_MODULES=$(npm_find_global_node_modules)
	pushd "$GLOBAL_NODE_MODULES" || exit
	node --experimental-repl-await
	popd || exit
}

# Execute a command with the global version of an asdf plugin, regardless of which dir
# you are in.
# @example `asdf_exec_with_global_version node --version`
asdf_exec_with_global_version() {
	# This is kind of hacky, but it works and asdf doesn't provide a "get global version" API
	# https://github.com/asdf-vm/asdf/issues/1340
	(cd /; asdf exec "$@")
	# Note: Above should pass through exit code, so no need to check and re-throw
}

# Note to self: you can use `--package` to avoid ambiguity around package name vs bin / entrypoint
npx_exec_global() {
	asdf_exec_with_global_version npx --no-install "$@"
}

npm_ls_global() {
	asdf_exec_with_global_version npm ls -g --depth=0 "$1"
}

# This is a workaround to tell the task runner that a given task is up-to-date,
# without actually running the task to generate the new fingerprint / checksum.
# Ideally, there would be a way to do this directly via the task cli (e.g. `task --mark-up-to-date`)
# See `scripts/task_mark_up_to_date.mjs` for full details`
task_mark_up_to_date() {
	: "${TASKFILE_PATH:="$PWD/Taskfile.yml"}"
	TASK_NAME=$1
	if [[ ! -f "$TASKFILE_PATH" ]]; then
		echo "ERROR: Could not find $TASKFILE_PATH"
		return 1
	fi
	if [[ -z "$TASK_NAME" ]]; then
		echo "ERROR: Please define TASK_NAME"
		return 1
	fi
	TASK_NAME=$TASK_NAME TASKFILE_PATH=$TASKFILE_PATH run_file_in_global_node "$HOME/scripts/task_mark_up_to_date.mjs"
}

# This might seem like a lot of code just to wrap ffmpeg's `scale`, but this:
# - Handles rounding auto-heights to be divisible by 2 (which ffmpeg does not)
# - Picks a `_resized` output filename based on the input
# - Prompts for target width if not provided, from selection
ffmpeg_resize() {
	INPUT_FILE=$1
	TARGET_WIDTH=$2
	INPUT_DIR=$(dirname "$INPUT_FILE")
	INPUT_FILE_EXT=$(basename "$INPUT_FILE" | sed -E 's/^.+(\.[^.]+)$/\1/')
	INPUT_FILE_NO_EXT=$(basename "$INPUT_FILE" | sed -E 's/\.[^.]+$//')
	: "${OUTPUT_FILE:="$INPUT_FILE_NO_EXT"_resized"$INPUT_FILE_EXT"}"

	# If target width, not provided, use choices
	if [[ -z "$TARGET_WIDTH" ]]; then
		printf "What should the target width be?\n\t[Aa])1920\n\t[Bb])1280\n\t[Cc])720\n\t[Dd])480\n"
		read -r answer
		case $answer in
			A|a) TARGET_WIDTH=1920 ;;
			B|b) TARGET_WIDTH=1280 ;;
			C|c) TARGET_WIDTH=720 ;;
			D|d) TARGET_WIDTH=480 ;;
			*) echo "Invalid selection" && return 1 ;;
		esac
	fi

	# Get width and height of input file
	INPUT_DIMENSIONS=$(ffprobe -v error -select_streams v -show_entries stream=width,height -of csv=p=0:s=x "$INPUT_FILE")
	print "INPUT_DIMENSIONS = $INPUT_DIMENSIONS"
	if ! TARGET_HEIGHT=$(INPUT_DIMENSIONS=$INPUT_DIMENSIONS TARGET_WIDTH=$TARGET_WIDTH node <<- "EOF"
	const regPatt = /(?<width>\d+)x(?<height>\d+)/i;
	const INPUT_DIMENSIONS = /** @type {`${string}x${string}`} */ (process.env.INPUT_DIMENSIONS);
	const TARGET_WIDTH = parseInt(process.env.TARGET_WIDTH);

	if (!regPatt.test(INPUT_DIMENSIONS)) {
		throw new Error(`Invalid input dimensions (${INPUT_DIMENSIONS})`);
	}

	if (Number.isNaN(TARGET_WIDTH)) {
		throw new Error(`Invalid target width (${TARGET_WIDTH})`);
	}

	const {
		groups: { width: _width, height: _height },
	} = regPatt.exec(INPUT_DIMENSIONS);
	const width = parseInt(_width);
	const height = parseInt(_height);

	let targetHeight = (TARGET_WIDTH * height) / width;

	// Handle rounding auto-heights to be divisible by 2
	if (targetHeight % 2 !== 0) {
		const roundedTargetHeight = Math.round(targetHeight / 2) * 2;
		console.warn(`Rounding auto-height to be divisible by 2: ${targetHeight} -> ${roundedTargetHeight}`);
		targetHeight = roundedTargetHeight;
	}

	console.log(targetHeight);
	EOF
	); then
		echo "ERROR: Could not parse input dimensions"
		return 1
	fi


	echo "Resizing $INPUT_FILE to $TARGET_WIDTH pixels wide (out = $INPUT_DIR/$OUTPUT_FILE)"
	ffmpeg -loglevel warning -stats -i "$INPUT_FILE" -vf scale="$TARGET_WIDTH:$TARGET_HEIGHT" "$INPUT_DIR/$OUTPUT_FILE"
	echo "Rendered to $INPUT_DIR/$OUTPUT_FILE"
	echo "✅ Done"
}


# This is currently pretty macoS specific
# Also, runs code that triggers OS permission checks, so will fail if denied
whats_up() {
	WINDOW_TITLE=$(cat << "EOF" | xargs -0 osascript -e
global frontApp, frontAppName, windowTitle

set windowTitle to ""
tell application "System Events"
	set frontApp to first application process whose frontmost is true
	set frontAppName to name of frontApp
	tell process frontAppName
		tell (1st window whose value of attribute "AXMain" is true)
			set windowTitle to value of attribute "AXTitle"
		end tell
	end tell
end tell

return {frontAppName, windowTitle}
EOF
)
	STATUS_STRING=$(cat << EOF
Active Window = $WINDOW_TITLE
EOF
)

	if (npx --package jtz-time-tracker-utils jttu --version > /dev/null); then
		STATUS_STRING=$(cat << EOF
$STATUS_STRING
==== Time Tracker ====
$(npx --package jtz-time-tracker-utils jttu harvest status)
======================
EOF
)
	fi
	echo "$STATUS_STRING"
}
