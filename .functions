#!/usr/bin/env bash
# shellcheck disable=SC2001
# shellcheck disable=SC2120
# shellcheck disable=SC2155
# set -x

# === Docs / Reusable Selection Lists ===
docs() {
	if [[ -d "$DOCS_DIR" ]]; then
		(
			cd "$DOCS_DIR" || return
			"$EDITOR" .
		)
	else
		open  "https://docs.joshuatz.com/"
	fi
}

fuzzy_preview() {
	local search_dir="$1"
	local search_pattern="$2"

	if ! [[ -d "$search_dir" ]]; then
		return 1
	fi

	local RG_ARGS=(
		"$search_dir"
		"--glob"
		'!**/node_modules/'
	)

	results=$(rg --files-with-matches -e "$search_pattern" "${RG_ARGS[@]}")

	if [[ -z "$ONLY_CONTENT" ]]; then
		# Check filenames too
		local filename_results=$(rg --files --glob "$search_pattern" "${RG_ARGS[@]}")
		if [[ -z "$results" ]]; then
			results="$filename_results"
		elif [[ -n "$filename_results" ]]; then
			results="$results\n$filename_results"
		fi
	fi

	if [[ -z "$results" ]]; then
		return 1
	fi

	# Display results with FZF, with a fancy preview pane
	echo "$results" | fzf --reverse --preview-window=wrap --preview "rg --with-filename --line-number --context=10 --no-heading --column --color=always --smart-case -e $search_pattern {}"
}

docs_fuzzy() {
	if ! [[ -d "$DOCS_DIR" ]]; then
		echo "DOCS_DIR is unset!"
		return 1
	fi
	fuzzy_preview "$DOCS_DIR" "$@"
}

SIGNALS_PICK_LIST=$(cat << "EOF"
9	KILL	(non-catchable, non-ignorable kill)
---	---	---
1	HUP	(hang up)
2	INT	(interrupt)
3	QUIT	(quit)
6	ABRT	(abort)
9	KILL	(non-catchable, non-ignorable kill)
14	ALRM	(alarm clock)
15	TERM	(software termination signal)
EOF
)

docs_signals() {
	echo "$SIGNALS_PICK_LIST"
}

# === Styling ===
# For ANSI, this is a helpful guide - https://gist.github.com/fnky/458719343aabd01cfb17a3a4f7296797
# However, `tput` seems to be generally preferred over ANSI escape sequences now
if (which tput >/dev/null) && [[ -n $TERM ]]; then
	STYLE_RESET="$(tput sgr0)"
fi
# === /Styling ===

get_shell_type() {
	# Make sure bash check comes first, to reduce issues when using subshells
	if [[ -n "$BASH_VERSION" ]] || echo $SHELL | grep --silent -E "\/bash$"; then
		echo "BASH"
	elif [[ -n "$ZSH_VERSION" ]] || echo $SHELL | grep --silent -E "\/zsh$"; then
		echo "ZSH"
		return
	fi
}
SHELL_TYPE=$(get_shell_type)

# You can use this to parse version strings and then use the resulting number for comparison
# Example:
#     if [[ $(parse_version_string $(git --version | grep -E -o "\d+\.\d+.\d+$")) -ge $(parse_version_string "2.39.0") ]]
# https://stackoverflow.com/a/37939589/11447682
function parse_version_string { echo "$@" | awk -F. '{ printf("%d%03d%03d%03d\n", $1,$2,$3,$4); }'; }

parse_version_string_extra() {
	parse_version_string "$(echo $1 | sed -E 's/^([0-9]+(\.[0-9]+)*)[^0-9]*.*/\1/')"
}


ARRAY_INDEX_START=0
if [[ "$SHELL_TYPE" == "ZSH" ]]; then
	# cmon y'all, can't we just agree on things for once?
	ARRAY_INDEX_START=1
	ZSH_VERSION_NUM=$ZSH_VERSION
elif [[ "$SHELL_TYPE" == "BASH" ]]; then
	BASH_VERSION_NUM=$(parse_version_string "$BASH_VERSION")
fi

# Useful for splitting with non-printable char, etc.
UNIT_SEPARATOR_CHAR=$'\x1F'

IS_MAC=0
if [[ "$OSTYPE" == "darwin"* ]]; then
	IS_MAC=1
fi
IS_WAYLAND=0
if [[ $IS_MAC -ne 1 ]] && (loginctl show-session "$(loginctl | grep $(whoami) | awk '{print $1}')" -p Type | grep -q wayland); then
	IS_WAYLAND=1
fi

# Expand ~
expand_path() {
	local INPUT_PATH=$1
	if [[ -z "$INPUT_PATH" ]]; then
		echo "ERROR: No path provided"
		return 1
	fi
	INPUT_PATH="${INPUT_PATH/#\~/$HOME}"
	echo "$INPUT_PATH"
}

symlink_resolve() {
	if [[ $IS_MAC -eq 1 ]]; then
		greadlink -f "$1"
		return
	fi
	readlink -f "$1"
}

# Not perfect across all OSes, but a "good enough" approach for most
get_computer_name() {
	if (which scutil > /dev/null); then
		scutil --get ComputerName
		return 0
	fi
	uname -n | sed -e 's/\.local$//'
}

pretty_path() {
	echo "$PATH" | tr ':' '\n'
}

augment_path() {
	local extra_path=$1
	shift
	local cmd=$*
	(
		PATH="$extra_path:$PATH"
		$SHELL -c "$cmd"
	)
}

check_args_for_value() {
	local search_value=$1
	shift
	for arg in "$@"; do
		if (echo "$arg" | grep -qx -- "$search_value"); then
			return 0
		fi
	done
	return 1
}

# A way to get the value from a dynamic variable name
# I.e., dereference from pointer to variable held as string name
# https://mywiki.wooledge.org/BashFAQ/006#Indirection
# https://stackoverflow.com/q/16553089/11447682
get_var_value() {
	local VAR_NAME="$1"
	if [[ "$SHELL_TYPE" == "ZSH" ]]; then
		# shellcheck disable=SC2296
		echo "${(P)VAR_NAME}"
	elif [[ "$SHELL_TYPE" == "BASH" ]]; then
		echo "${!VAR_NAME}"
	else
		echo "Not sure how to handle $SHELL_TYPE"
		exit 1
	fi
}

# https://mywiki.wooledge.org/BashFAQ/006#Indirection
# https://stackoverflow.com/q/16553089/11447682
set_var_value() {
	local VAR_NAME="$1"
	local VAR_VALUE=$2
	if [[ "$SHELL_TYPE" == "ZSH" ]]; then
		# shellcheck disable=SC2296
		# shellcheck disable=SC2086
		: ${(P)VAR_NAME::=VAR_VALUE}
	elif [[ "$SHELL_TYPE" == "BASH" ]]; then
		if [[ $BASH_VERSION_NUM -gt $(parse_version_string "4.2") ]]; then
			declare -g "${VAR_NAME}=$VAR_VALUE"
		elif [[ $BASH_VERSION_NUM -gt $(parse_version_string "3.1") ]]; then
			printf -v "$VAR_NAME" %s "$VAR_VALUE"
		else
			declare -- "${VAR_NAME}=$VAR_VALUE"
		fi
	else
		echo "Not sure how to handle $SHELL_TYPE"
		exit 1
	fi
}

debug_separator_ifs() {
	IFS_CHARS=$(printf '%s' "$IFS" | cat -e | head -n 1)
	echo "$IFS_CHARS"
}

trim_whitespace() {
	echo "$1" | awk 'NF{$1=$1;print}'
}

regex_to_sed() {
	# TODO
	:
}

remove_first_line() {
	echo "$1" | sed -r '1d;'
}

remove_last_line() {
	echo "$1" | sed -r '$d'
}

remove_first_and_last_line() {
	echo "$1" | sed -r '1d;$d'
}

reload() {
	if [[ $SHELL_TYPE == "ZSH" ]]; then
		# Note: Don't use source ~/.zshrc
		# See: https://github.com/ohmyzsh/ohmyzsh/wiki/FAQ#how-do-i-reload-the-zshrc-file
		exec zsh
	elif [[ $SHELL_TYPE == "BASH" ]]; then
		source ~/.bash_profile
	else
		echo "Not sure how to reload this shell"
	fi
}

alert() {
	msg="$1"
	# Hello? Is anyone home? It's me, your terminal.
	echo -e "\a"
	if [[ -n "$msg" ]]; then
		if (is_in_tmux); then
			tmux display-message "$1"
			return 0
		fi
		# TODO: Add styling
		echo "$1"
	fi
}

get_clipboard_contents() {
	if (which pbpaste > /dev/null); then
		pbpaste
	elif (which xclip > /dev/null); then
		xclip -selection clipboard -o
	elif (which wl-paste > /dev/null); then
		wl-paste
	else
		echo "ERROR: Could not find a clipboard utility"
	fi
}

get_clipboard_html() {
	if [[ $IS_MAC -ne 1 ]]; then
		# TODO: Linux support
		return 1
	fi

	# https://stackoverflow.com/a/24132171/11447682
	# The Perl part of this is to convert the hex string to a readable string
	osascript -e 'the clipboard as «class HTML»' | perl -ne 'print chr foreach unpack("C*",pack("H*",substr($_,11,-3)))'
}

_copy_to_clipboard() {
	if (which pbcopy > /dev/null); then
		pbcopy
	elif (which xclip > /dev/null); then
		xclip -selection clipboard
	elif (which wl-copy > /dev/null); then
		wl-copy
	else
		echo "ERROR: Could not find a clipboard utility"
	fi
}

# shellcheck disable=SC2120
copy_to_clipboard() {
	if [[ -n "$1" ]]; then
		# Suppress trailing line break while piping
		echo -n "$1" | _copy_to_clipboard
	else
		_copy_to_clipboard
	fi
}

# This only overwrites clipboard content if the selection is NOT empty
# It always return 0, so that it can be conveniently used with places
# that expect a copy command to always work
copy_to_clipboard_if_not_empty() {
	text="$1"
	# make sure to remove both space AND trailing line breaks
	if [[ -z $(trim_whitespace "$1") ]]; then
		alert "Empty Selection"
		return 0
	fi
	echo "$text" | copy_to_clipboard
	alert "Copied to clipboard"
}

copy_html_to_clipboard() {
	html="$1"
	plaintext="$2"
	# Fallback to HTML as plaintext if not set
	if [[ -z "$plaintext" ]]; then
		plaintext="$html"
	fi
	if [[ $IS_MAC -eq 1 ]]; then
		# If HTML is not prefixed with meta charset tag, add it
		if [[ -z "$NO_WRAP" ]] && (! echo "$html" | grep -q -E "^<meta charset"); then
			html="<meta charset=\"utf-8\">${html}"
		fi

		# https://stackoverflow.com/a/11089226/11447682
		# https://aaron.cc/copying-the-current-safari-tab-as-a-to-the-clipboard-as-a-clickable-link/
		html_hex=$(echo -n "$html" | hexdump -ve '1/1 "%.2x"')
		if [[ -n "$NO_PLAIN" ]]; then
			osascript <<- EOF
				set the clipboard to «data HTML${html_hex}»
			EOF
			return
		fi
		# Need to escape any inner double-quotes inside `plaintext` string, since
		# we are using`string:"${plaintext}"` as wrapper, or else this will error out.
		# E.g.: 6216:6226: syntax error: Expected “,” or “}” but found identifier. (-2741)
		local plaintext_escaped=$(echo "$plaintext" | sed 's/"/\\"/g')
		if ! (osascript <<- EOF
			set the clipboard to {«class HTML»:«data HTML${html_hex}», string:"${plaintext_escaped}"}
		EOF
		); then
			echo "AppleScript failed to set HTML"
			return 1
		fi
	else
		echo "$html" | xclip -selection clipboard -t text/html
	fi
}

copy_tab_to_clipboard() {
	printf "\t" | copy_to_clipboard
}

copy_last_command_to_clipboard() {
	last_command=$(fc -ln -1)
	echo "$last_command" | copy_to_clipboard
}

markdown_to_html_clipboard() {
	md="$1"
	# If no arg, grab from clipboard
	if [[ -z "$md" ]]; then
		md="$(get_clipboard_contents)"
	fi
	html=""
	if (which pandoc > /dev/null); then
		html=$(echo "$md" | pandoc -f gfm -t html)
	else
		html=$(npx marked --gfm -s "$md")
	fi
	copy_html_to_clipboard "$html" "$md"
	echo "✅ HTML copied to clipboard"
}

convert_clipboard_md_to_html() {
	markdown_to_html_clipboard "$(get_clipboard_contents)"
}

convert_clipboard_to_plaintext() {
	# Takes the clipboard contents and converts it to plaintext, in-place
	text=$(get_clipboard_contents)
	echo "$text" | copy_to_clipboard
}

convert_clipboard_html_to_md() {
	html=$(get_clipboard_html)
	echo "$html" | pandoc --from html --to gfm | copy_to_clipboard
}

firefox() {
	if [[ "IS_MAC" -eq 1 ]]; then
		/Applications/Firefox.app/Contents/MacOS/firefox "$@"
		return 0
	fi
	return 1
}

firefox_get_profile_dir() {
	if [[ $IS_MAC -ne 1 ]]; then
		# TODO: Linux support
		return 1
	fi
	local firefox_db_location=$(rg \
		--files \
		--no-ignore \
		--glob "**/Profiles/*.default-release/places.sqlite" \
		~/Library/Application\ Support/Firefox 2>/dev/null)
	# Error out on no matches, or greater than 1 match
	if [[ -z "$firefox_db_location" ]]; then
		echo "ERROR: Could not find Firefox DB location"
		return 1
	fi
	if [[ $(echo "$firefox_db_location" | wc -l) -gt 1 ]]; then
		# TODO: Support multiple profiles?
		echo "ERROR: Found more than one Firefox DB location"
		return 1
	fi
	dirname "$firefox_db_location"
}

# Convert Mozilla's non-standard LZ4 files (jsonlz4 or mozlz4) to JSON
# The special things about moz's lz4 implementation are:
# - Non-standard header - first 8 bytes, magic `mozLz40\0`
# - Uses blocks instead of frame (making it incompatible, as-is, with the
#   lz4 CLI)
moz_lz4json_to_json() {
	local mozlz4_file="$1"
	if ! [[ -f $mozlz4_file ]]; then
		echo "File $mozlz4_file does not exist"
		return 1
	fi
	# Check for magic header bytes
	if ! [[ $(head -c 7 "$mozlz4_file") == "mozLz40" ]]; then
		echo "Not a Mozilla LZ4 JSON file"
		return 1
	fi
	# Make sure mozlz4_file is full path
	mozlz4_file=$(realpath "$mozlz4_file")
	# Check for required python package
	ensure_pkg_in_dotfiles_venv "lz4"

	python_script=$(cat <<- EOF
	import lz4.block
	import json
	with open("$mozlz4_file", "rb") as f:
	    f.seek(8)
	    decompressed = lz4.block.decompress(f.read())
	    decoded = decompressed.decode("utf-8")
	    parsed_json = json.loads(decoded)
	    print(json.dumps(parsed_json, indent=2))
	EOF
	)

	mozlz4_file="$mozlz4_file" run_raw_python_in_dotfiles_venv "$python_script"
}

firefox_dump_restore_file() {
	# TODO
	:
}

# Copies the Firefox DB (`places.sqlite`) to a temp dir,
# to avoid lock issues / concurrency / corruption
firefox_get_temp_db_copy() {
	local VERBOSE=0
	if [[ $* == *--verbose* ]]; then
		VERBOSE=1
	fi
	local firefox_profile_dir=$(firefox_get_profile_dir)
	if ! [[ $? -eq 0 ]]; then
		return 1
	fi
	local firefox_db_location="$firefox_profile_dir/places.sqlite"
	[[ $VERBOSE -eq 1 ]] && echo "Firefox DB location(s) = $firefox_db_location"

	# Copy database to a temp directory to avoid lock issues / concurrency / corruption
	temp_dir=$(mktemp -d)
	temp_db_copy="$temp_dir/places.sqlite"
	[[ $VERBOSE -eq 1 ]] && echo "💾 Creating temporary copy of FF DB"
	cp "$firefox_db_location" "$temp_db_copy"

	echo "$temp_db_copy"
}

firefox_db_interact() {
	local VERBOSE=0
	if [[ $* == *--verbose* ]]; then
		VERBOSE=1
	fi
	local callback=$1
	if [[ -z "$callback" ]]; then
		echo "ERROR: No callback provided"
		return 1
	fi
	shift
	local temp_db_copy=$(firefox_get_temp_db_copy "")

	# Call our callback with the temporary db, to let it do whatever it wants
	$callback "$temp_db_copy"

	# Cleanup!
	[[ $VERBOSE -eq 1 ]] && echo "🗑️ Cleaning up temp DB copy"
	rm -f "$temp_db_copy"
	[[ $VERBOSE -eq 1 ]] && echo "✅ Firefox DB interaction complete"

}

# Get members of a firefox bookmarks group by group ID or name
# Returns joined rows as JSON
firefox_get_bookmark_group_members() {
	if ! (which sqlite3 > /dev/null); then
		echo "ERROR: sqlite3 not found"
		return 1
	fi
	local temp_db_copy=$(firefox_get_temp_db_copy)
	bookmark_group_name_or_id=$1
	GROUP_ID=$1
	IS_ID=$(echo "$bookmark_group_name_or_id" | grep -E -q "^[0-9]+$" && echo "true" || echo "false")
	if [[ "$IS_ID" == "false" ]]; then
		GROUP_ID=$(sqlite3 "$temp_db_copy" "SELECT id FROM moz_bookmarks WHERE title = '$bookmark_group_name_or_id';")
		if [[ -z "$GROUP_ID" ]]; then
			echo "ERROR: Could not find bookmark group '$bookmark_group_name_or_id'"
			return 1
		fi
	fi
	sqlite3 \
		"$temp_db_copy" \
		".mode json" \
		"SELECT * FROM moz_bookmarks JOIN moz_places ON moz_bookmarks.fk = moz_places.id WHERE moz_bookmarks.parent = '$GROUP_ID';"
	rm -f "$temp_db_copy"
}

chrome() {
	if [[ "IS_MAC" -eq 1 ]]; then
		: "${CHROME_BIN:="/Applications/Google Chrome.app/Contents/MacOS/Google Chrome"}"
		"$CHROME_BIN" "$@"
		return 0
	fi
	return 1
}

# Opens firefox, with each URL passed at the end, as a new tab
# Currently, with tree style tabs, the first URL becomes the root tab
# and any subsequent new tabs are loaded as children
# (TODO: Make this more flexible)
# See: http://kb.mozillazine.org/Command_line_arguments
firefox_with_tabs() {
	args=("-new-window")
	for arg in "$@"; do
		args+=("-new-tab" "-url" "$arg")
	done
	firefox "${args[@]}"
}

# Opens Chrome, with each URL passed at the end, as a new tab
# See: https://peter.sh/experiments/chromium-command-line-switches/
chrome_with_tabs() {
	args=("--new-window")
	for arg in "$@"; do
		args+=("$arg")
	done
	chrome "${args[@]}"
}

# This opens a new browser with a preset group of tabs, based on stdin JSON
# that matches the `browser-group.json` schema.
# See [browser-groups.json](./schemas/browser-groups.json).
# It defaults to Firefox - use `--chrome` to launch with Chrome instead.
open_browser_group_url() {
	local JSON=$1
	shift
	local BROWSER="firefox"
	if (check_args_for_value "--chrome" "$*"); then
		BROWSER="chrome"
	fi
	local OPEN_ALL=0
	if (check_args_for_value "--all" "$*"); then
		OPEN_ALL=1
	fi

	# Pass the list of tabs (URLS) to the browser
	local TAB_URLS=($(echo "$JSON" | jq -r ".tabs[].url"))
	# Check for empty array
	if [[ ${#TAB_URLS[@]} -eq 0 ]]; then
		echo "ERROR: No tabs found"
		return 1
	fi

	if [[ $OPEN_ALL -eq 1 ]]; then
		if [[ "$BROWSER" == "firefox" ]]; then
			firefox_with_tabs "${TAB_URLS[@]}"
		elif [[ "$BROWSER" == "chrome" ]]; then
			chrome_with_tabs "${TAB_URLS[@]}"
		fi
		return 0
	fi

	local SELECTED_TAB_URL=$(echo "$JSON" | jq -r '.tabs[] | "\(.notes) || \(.url)"' | fzf | awk -F '\\|\\|' '{print $2}')
	if [[ -n "$SELECTED_TAB_URL" ]]; then
		if [[ "$BROWSER" == "firefox" ]]; then
			firefox "$SELECTED_TAB_URL"
		elif [[ "$BROWSER" == "chrome" ]]; then
			chrome "$SELECTED_TAB_URL"
		fi
		return 0
	fi

	return 1
}

# Get nested workspace JSON by name, or with TUI selector
get_workspace_json() {
	local WORKSPACE_NAME=$1
	local CONSIDER_ONLY_ACTIVE_WORKSPACES=$(
		{ [[ -n "$ALL_WORKSPACES" ]] || [[ $* == *--all* ]]; } && echo "y" || echo "n"
	)
	local workspaces_file=~/.workspaces.json
	if ! [[ -f "$workspaces_file" ]]; then
		echo "ERROR: Could not find workspaces file at $workspaces_file"
		return 1
	fi
	local JSON=$(cat "$workspaces_file")
	local NAME_KEYS=()
	local NAME_KEYS_STR=$(echo "$JSON" | jq -r 'del(."$schema") | keys[]' 2>/dev/null)
	while IFS='' read -r line; do NAME_KEYS+=("$line"); done < <(echo "$NAME_KEYS_STR")
	# Check if WORKSPACE_NAME is valid (in list of keys)
	local FOUND_KEY=0
	for key in "${NAME_KEYS[@]}"; do
		if [[ "$key" == "$WORKSPACE_NAME" ]]; then
			FOUND_KEY=1
			break
		fi
	done

	# If key was not found, offer a selector TUI (preview is group config)
	if [[ $FOUND_KEY -eq 0 ]]; then
		if [[ "$CONSIDER_ONLY_ACTIVE_WORKSPACES" == "n" ]]; then
			NAME_KEYS_STR=$(echo "$JSON" | jq -r 'del(."$schema") | with_entries(select(.value.active == true)) | keys[]' 2>/dev/null)
		fi
		WORKSPACE_NAME=$(echo "$NAME_KEYS_STR" | fzf --preview "jq '.\"{}\"' $workspaces_file")
	fi

	if [[ -z "$WORKSPACE_NAME" ]]; then
		return 1
	fi


	echo "$JSON" | jq -r ".$WORKSPACE_NAME"
}

open_workspace() {
	local WORKSPACE_NAME=$1
	local WORKSPACE_JSON=$(get_workspace_json "$WORKSPACE_NAME")

	if [[ -z "$WORKSPACE_JSON" ]]; then
		return 1
	fi

	# Don't open slack by default - require `--with-slack`
	if (check_args_for_value "--with-slack"); then
		local first_slack_channel=$(echo "$WORKSPACE_JSON" | jq -r ".slackChannels[0]")
		if [[ "$first_slack_channel" != "null" ]]; then
			local TEAM_ID=$(echo "$first_slack_channel" | jq -r '.teamId')
			local CHANNEL_ID=$(echo "$first_slack_channel" | jq -r '.channelId')
			open "slack://channel?team=${TEAM_ID}&id=${CHANNEL_ID}"
		fi
	fi

	local first_ide_project_root=$(echo "$WORKSPACE_JSON" | jq -r ".ideProjectRoots[0]")
	if [[ "$first_ide_project_root" != "null" ]]; then
		code "$(expand_path "$first_ide_project_root")"
	fi

	local first_browser_group_json=$(echo "$WORKSPACE_JSON" | jq -r ".browserGroups[0]")
	if [[ "$first_browser_group_json" != "null" ]]; then
		open_browser_group_url "$first_browser_group_json" "--$BROWSER" --all
	fi

	local tmux_session_name=$(echo "$WORKSPACE_JSON" | jq -r ".preferredTmuxSessionName")
	if [[ "$tmux_session_name" != "null" ]]; then
		# Note: tmux_auto_open already gracefully handles if session is already open
		tmux_auto_open "$tmux_session_name"
	fi
}

open_workspace_url() {
	local WORKSPACE_NAME=""
	local PASS_THROUGH_ARGS=()
	while [[ ! $# -eq 0 ]]
	do
		case "$1" in
			-w|--workspace)
				WORKSPACE_NAME=$2
				shift
				shift
				;;
			*)
				PASS_THROUGH_ARGS+=("$1")
				shift
				;;
		esac
	done
	local WORKSPACE_JSON=$(get_workspace_json "$WORKSPACE_NAME")
	local first_browser_group_json=$(echo "$WORKSPACE_JSON" | jq -r ".browserGroups[0]")
	if [[ "$first_browser_group_json" != "null" ]]; then
		open_browser_group_url "$first_browser_group_json" "${PASS_THROUGH_ARGS[@]}"
	fi
}

date_iso() {
	# 2020-11-28T12:11:28Z
	date -u +"%Y-%m-%dT%H:%M:%SZ"
}

date_ms() {
	if which gdate > /dev/null; then
		gdate +%s%3N
	else
		date +%s000
		# echo "WARNING: gdate not found; faking millseconds from seconds"
	fi
}

# Like `touch` + `mkdir -p`: creates intermediate directories if they don't exist yet
make_file() {
	file_path=$1
	if [[ -e $file_path ]]; then
		echo "File already exists"
	else
		mkdir -p "$(dirname "$file_path")"
		touch "$file_path"
	fi
}

get_cpu_throttle_info() {
	if [[ $* == *--watch* ]]; then
		pmset -g thermlog
		return
	fi
	pmset -g therm
}

make_venv() {
	VENV_PATH=./.venv
	echo "Where should the virtual environment be created? (press enter to default to .venv)"
	read -r INPUT
	if [[ $INPUT != "" ]]; then
		VENV_PATH=$INPUT
	fi
	if [[ -d $VENV_PATH ]]; then
		echo "${VENV_PATH} already exists"
	else
		echo "Preparing virtual environment in ${VENV_PATH}"
		python3 -m venv $VENV_PATH
		source $VENV_PATH/bin/activate
	fi
}

check_venv() {
	which python | grep "$PWD"
}

# Generates the poetry named environment string
# Although this _can_ be used to check that the correct virtual environment is
# activated, it is generally much easier to just use a regular venv and point
# poetry to it (because then you can just do something like `which python | grep $PWD`)
# For implementation reference see
#   https://github.com/python-poetry/poetry/blob/7c86992909257caa4f51a50c001f5894bfe5065e/src/poetry/utils/env.py#L635
#   https://github.com/python-poetry/poetry/blob/7c86992909257caa4f51a50c001f5894bfe5065e/src/poetry/utils/env.py#L1212-L1220
generate_poetry_env_name_str() {
	PROJECT_NAME=$(basename "$PWD")
	if [[ -f pyproject.toml ]]; then
		PROJECT_NAME=$(poetry version | sed -E -n 's/(.+) [.0-9]+$/\1/p')
	fi
	PROJECT_NAME=$PROJECT_NAME python << "EOF"
import base64
import os
import re
import hashlib

# shim - re-implement poetry encode method
def encode(string: str):
	if isinstance(string, bytes):
		return string
	return string.encode("utf-8")

def generate_env_name(package_name: str, cwd: str) -> str:
	package_name = package_name.lower()
	sanitized_name = re.sub(r'[ $`!*@"\\\r\n\t]', "_", package_name)[:42]
	normalized_cwd = os.path.normcase(os.path.realpath(cwd))
	h_bytes = hashlib.sha256(encode(normalized_cwd)).digest()
	h_str = base64.urlsafe_b64encode(h_bytes).decode()[:8]
	return f"{sanitized_name}-{h_str}"

cwd = os.getcwd()
print(generate_env_name(os.environ["PROJECT_NAME"], cwd))
# Should print something like `project-name-ABCD1a-Z`
EOF
}

# Search for, and activate, a local python virtual environment
# @TODO - if python env is *already* activated, check if path matches, and if not
# 	deactivate and then activate
# @TODO - handle Poetry
activate() {
	fail=1
	possible_envs=(./venv ./.venv ./env ./.env)
	for env_dir in "${possible_envs[@]}"; do
		if [[ -e "$env_dir/bin/activate" ]]; then
			source "$env_dir/bin/activate"
			fail=0
			break
		fi
	done
	return $fail
}
# TODO set up auto-activate on every shell start

pip_upgrade() {
	python3 -m pip install --upgrade pip
}

# Like clear, but extra space to pad the start
wipe() {
	for run in {1..10}; do
		echo $'\n'
	done
	clear
}

render_image() {
	IMAGE_PATH=$1

	# Wezterm
	if (which wezterm > /dev/null) && (is_in_wezterm); then
		wezterm imgcat "$IMAGE_PATH"
		return
	fi

	# ImageMagick
	if (which display > /dev/null); then
		# Sometimes can be installed, but misconfigured. Can use a simple` --version`
		# check to verify
		if (display --version > /dev/null 2>&1); then
			display "$IMAGE_PATH"
			return
		else
			echo "WARNING: ImageMagick installed, but not configured correctly"
		fi
	fi

	if (which chafa > /dev/null); then
		chafa "$IMAGE_PATH"
		return
	fi

	echo "ERROR: Could not find a suitable image viewer"
	return 1
}

render_table() {
	local horizontal_scroll="true"
	if [[ $* == *--no-h-scroll* ]]; then
		horizontal_scroll="false"
	fi
	if (run_raw_cmd_in_dotfiles_venv 'pip show rich' > /dev/null); then
		# ellipsis (default) | fold | crop
		local overflow="ellipsis"
		if [[ $* == *--fold* ]] || [[ $horizontal_scroll == "true" ]]; then
			overflow="fold"
		fi
		local table_string="$1"
		local python_script=$(cat <<-EOF
		import os
		from rich.console import Console
		from rich.table import Table

		table_string = """$table_string"""
		rows = table_string.splitlines()
		header_row = rows[0]
		header_row_cells = rows[0].split('\t')
		rows = rows[1:]

		console_args = {}

		if "$horizontal_scroll" == "true":
		    # If horizontal scroll is on, we need to manually set shell args,
		    # since we lose them piping through less
		    console_args["color_system"] = "256"

		    # This is kind of hackish, but rich doesn't seem to have something
		    # like width=max, so this is a workaround
		    # Use actual total header char length, plus padding
		    header_row_char_length = sum(len(h_cell) for h_cell in header_row_cells) + (len(header_row_cells) * 8)
		    console_args["width"] = header_row_char_length


		console = Console(**console_args)


		table = Table(show_header=True, header_style="bold magenta")

		for header_cell in header_row_cells:
		    column_args = {"overflow": "$overflow"}
		    if "$horizontal_scroll" == "true":
		        # This is kind of hackish, but rich doesn't seem to have something
		        # like width=max, so this is a workaround
		        column_args["min_width"] = len(header_cell) + 2
		    table.add_column(header_cell, **column_args)
		for row in rows:
		    table.add_row(*row.split('\t'))
		console.print(table)
		EOF
		)
		if [[ $horizontal_scroll == "true" ]]; then
			run_raw_python_in_dotfiles_venv "$python_script" | less -R -S
		else
			run_raw_python_in_dotfiles_venv "$python_script"
		fi
		return 0
	fi

	if [[ $horizontal_scroll == "true" ]]; then
		echo "$table_string" | column -ts $'\t' | less -R -S
	else
		echo "$table_string" | column -ts $'\t'
	fi
}

render_json_as_table() {
	local json_string_or_file="$1"
	local json_string="$1"
	shift
	local ends_with_dot_json=$( (echo "$json_string_or_file" | grep -E '.*\.json$') && echo "true" || echo "false" )
	if [[ $ends_with_dot_json == "true" ]] && [[ -f "$json_string_or_file" ]]; then
		json_string=$(cat "$json_string_or_file")
	fi
	local json_as_table=$(echo "$json_string" | jq -r 'map( with_entries(  .value |= tostring  ) ) | (map(keys) | add | unique) as $cols | map(. as $row | $cols | map($row[.])) as $rows | $cols, $rows[] | @tsv')
	render_table "$json_as_table" "$@"
}

# Note: This is ZSH specific; todo - make agnostic?
reload_func() {
	unfunction "_$1" && compinit
}

normalize_name() {
	input_name="$1"
	# SPACE -> `-`
	# (anything else, non alpha-numeric) -> REMOVED
	echo "$input_name" | tr ' ' '-' | tr -cd '[:alnum:]-'
}

project_name() {
	project_dir=$1
	if [[ -z "$project_dir" ]]; then
		project_dir="$PWD"
	fi
	project_dirname=$(basename "$project_dir")

	# DEFAULT
	project_name="$project_dirname"

	# Is there a pyproject.toml file?
	if [[ -f "$project_dir/pyproject.toml" ]]; then
		project_name=$(poetry version | awk '{print $1}')
	# How about `package.json`?
	elif [[ -f "$project_dir/package.json" ]]; then
		project_name=$(jq -r '.name' "$project_dir/package.json")
	# How about a git remote / named repo?
	elif [[ -d "$project_dir/.git" ]]; then
		remote_url=$(git_remote_url)
		project_name=$(basename "$remote_url")
	fi

	echo "$project_name"
}

project_name_normalized() {
	project_name_raw=$(project_name "$1")
	normalize_name "$project_name_raw"
}

get_project_version() {
	local target_dir=.
	local used_cd=0
	if [[ -d $1 ]]; then
		target_dir=$1
		pushd $target_dir > /dev/null || return 1
		used_cd=1
	fi
	local found_versions=()

	if [[ -f "pyproject.toml" ]]; then
		found_version=$(poetry version | awk '{print $2}')
	elif [[ -f "package.json" ]]; then
		found_version=$(jq -r '.version' "package.json")
	fi
	if [[ -n "$found_version" ]]; then
		found_versions+=("$found_version")
	fi

	if [[ $used_cd -eq 1 ]]; then
		popd > /dev/null || return 1
	fi

	# Echo out array, joined with `\n`
	echo "${found_versions[@]}"
}

set_project_version() {
	:
	# npm version --no-git-tag-version $version_string ("v1.0.0" turns into "1.0.0")
	# poetry version $version_string  ("v1.0.0" turns into "v1.0.0", so you want to omit `v` prefix unless you actually want it to be in the string)
}

bump_project_version() {
	local target_dirs=()
	local new_version=-1
	while [[ ! $# -eq 0 ]]
	do
		if [[ -d "$1" ]]; then
			target_dirs+=("$1")
		else
			# If we are on the last variable, check if it matches semver
			if [[ $# -eq 1 ]] && [[ $1 =~ ^[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
				new_version=$1
			else
				echo "Last argument was neither a directory or version string"
				return 1
			fi
		fi
	done
	if [[ ${#target_dirs[@]} -eq 0 ]]; then
		target_dirs+=(".")
	fi
	if [[ $new_version -eq -1 ]]; then
		# Try to extract current version
		local current_version=-1
		echo "⚠️ Current version not specified. Trying to auto-extract..."
		local last_dir_with_version=""
		for target_dir in "${target_dirs[@]}"; do
			local extracted_version=$(get_project_version $target_dir)
			if [[ $? -eq 0 ]]; then
				# If we have already extracted a version, and this other directory doesn't match, we have a problem
				if ! [[ $current_version -ne -1 ]] && [[ $extracted_version != "$current_version" ]]; then
					echo "❌ Version $current_version was already found in $last_dir_with_version, but got conflicting version of $extracted_version in $target_dir"
					return 1
				elif [[ $current_version -eq -1 ]]; then
					current_version=$extracted_version
				fi
			fi
		done
		if [[ $current_version -eq -1 ]]; then
			echo "❌ Could not auto-extract current version"
		else
			echo "Detected / extracted version of $current_version. Is this correct? [Yy]es / [Nn]o?"
			read -r INPUT
			if [[ $INPUT =~ ^[Nn]$ ]]; then
				return 1
			fi
		fi

		# Determine new version from current version
		# ...
		# WIP / TODO
	fi
}

# @see https://www.nerdfonts.com/cheat-sheet for what is available
nerd_font() {
	case "$1" in
		cod_terminal_tmux) echo "\Uebc8" && return ;;
		*) echo "No mapping saved for $1" && return 1 ;;
	esac
}

is_in_wezterm() {
	if [[ -z "$WEZTERM_UNIX_SOCKET" ]]; then
		return 1
	fi
	return 0
}

# Sets a user variable inside the WezTerm variable space
# NOTE: This is _NOT_ setting a shell environment variable; rather,
# this sets it within the WezTerm managed variable list, which can
# be programmatically accessed (and also emits events when changed).
# @SEE https://wezfurlong.org/wezterm/recipes/passing-data.html#user-vars
wezterm_set_var() {
	if ! (which base64 > /dev/null); then
		echo "Must have base64 in path to encode variable value"
		return 1
	fi
	local var_name=$1
	local var_val_encoded=$(echo -n "$2" | base64)
	local var_setter_str=$(printf "\033]1337;SetUserVar=%s=%s\007" "$var_name" "$var_val_encoded")
	tmux_passthrough_escape "$var_setter_str"
}

wezterm_get_var() {
	if ! (is_in_wezterm); then
		return 1
	fi
	echo "@TODO"
}

set_title() {
	local title=$1
	if ($OH_MY_ZSH_ACTIVE) && [[ $DISABLE_AUTO_TITLE != true ]]; then
		echo "You have Oh-My-ZSH active, and DISABLE_AUTO_TITLE is NOT set to true"
		echo "  ^ Setting titles via ANSI sequences will have no effect, because ZSH will just override"
		return 1
	fi
	tmux_passthrough_escape "$(printf "\x1B]0;%s\x07" "$title")"
}

is_in_tmux() {
	if ! (which tmux > /dev/null); then
		return 1
	fi
	[[ -n "$TMUX" ]]
}

tmux_reload_config() {
	tmux source-file ~/.tmux.conf
}

tmux_inspect() {
	local session_name=$1
	if [[ -z "$session_name" ]]; then
		session_name=$(tmux_session_select)
	fi
	cat <<- EOF
	################################
	# TMUX Session =               #
	#    $session_name             #
	################################
	EOF
	local spacer=""
	echo "${spacer}Windows:"
	local all_windows_in_session=$(tmux list-windows -t "$session_name" -F "#{window_index} #{window_name}")
	spacer="  "
	for window_info in $all_windows_in_session; do
		local window_idx=$(echo "$window_info" | awk '{print $1}')
		local window_name=$(echo "$window_info" | awk '{print $2}')
		echo "${spacer}∟ $window_idx | $window_name"
		local all_panes_in_window=$(tmux list-panes -t "$session_name:$window_idx" -F "#{pane_index}")
		local pane_count=$(($(echo "$all_panes_in_window" | wc -l)))
		spacer="       "
		echo "${spacer}∟ # of Panes = $pane_count"
	done

}

tmux_get_active_session_name() {
	# Note: This is necessary because `tmux display-message -p "#S"` actually
	# does not throw outside of a tmux session - it just returns the last alive
	# session
	if ! (is_in_tmux); then
		return 1
	fi
	tmux display-message -p "#S"
}

tmux_generate_session_name() {
	tmux_session_name=$1
	if [[ -z "$tmux_session_name" ]]; then
		project_name=$(project_name_normalized "")
		tmux_session_name="$project_name"
		# Default to project name + end of branch name
		current_git_branch_name=$(git_branch_name 2>&1)
		if [[ $? -eq 0 ]]; then
			tmux_session_name="${tmux_session_name}-$(basename "$current_git_branch_name")"
		fi
	fi
	echo "$tmux_session_name"
}

tmux_session_select() {
	if [[ -n "$TMUX_SESSION" ]]; then
		echo "$TMUX_SESSION"
		return
	fi
	active_sessions=$(tmux list-sessions -F "#{session_name}" 2>/dev/null)
	selected_session=$(printf "%s\n" "${active_sessions[@]}" | fzf)
	echo "$selected_session"
}

tmux_session_select_or_current() {
	local current_tmux_session_name=$(tmux_get_active_session_name)
	if [[ $? -eq 0 ]] && [[ -n "$current_tmux_session_name" ]]; then
		echo "$current_tmux_session_name"
		return
	fi
	tmux_session_select
}

tmux_session_select_and_attach() {
	tmux_attach_with_init "$(tmux_session_select)"
}

tmux_window_select() {
	local selected_session=$(tmux_session_select)
	if [[ -z "$selected_session" ]]; then
		return
	fi
	local all_windows_in_session=$(tmux list-windows -t "$selected_session" -F "#{window_index} #{window_name}")
	local selected_window_index="0"
	# Only prompt for selection if > 1 window
	if [[ $(($(echo "$all_windows_in_session" | wc -l))) -gt 1 ]]; then
		selected_window_index=$(echo "$all_windows_in_session" | fzf | awk '{print $1}')
	fi
	echo "$selected_session:$selected_window_index"
}

tmux_new_window() {
	local selected_session=$(tmux_session_select_or_current)
	tmux new-window -t "$selected_session"
}

tmux_pane_select() {
	selected_window=$(tmux_window_select)
	all_panes_in_window=$(tmux list-panes -t "$selected_window" -F "#{pane_index}")
	selected_pane=$(echo "$all_panes_in_window" | fzf --preview "tmux capture-pane -t $selected_window.{} -pJS -10")
	echo "$selected_window.$selected_pane"
}

tmux_pane_zoom_toggle() {
	if (is_in_tmux); then
		tmux resize-pane -Z
		return
	fi
	local selected_pane=$(tmux_pane_select)
	tmux resize-pane -Z -t "$selected_pane"
}
alias tmux_zoom="tmux_pane_zoom_toggle"

tmux_kill_pane() {
	local pane=$(tmux_pane_select)
	if [[ -z "$pane" ]]; then
		return
	fi
	tmux kill-pane -t "$pane"
}

tmux_scrollback_dump() {
	: "${NUM_LINES:="500"}"
	pane=$(tmux_pane_select)
	if [[ -z "$pane" ]]; then
		return
	fi
	tmux capture-pane -t "$pane" -pJS "-$NUM_LINES"
}

tmux_do_in_session_for_all_panes() {
	# TODO: Add override env var to allow forcing send-keys, even if
	# stdin is being clobbered / hijacked (e.g. by active logging)
	local session_name=$1
	if (is_in_tmux); then
		session_name=$(tmux_get_active_session_name)
	else
		# Don't pass $1 (session_name) along to send-keys
		shift
	fi
	tmux set-window-option -t "$session_name" synchronize-panes on
	tmux send-keys -t "$session_name" "$@" C-m || true
	tmux set-window-option -t "$session_name" synchronize-panes off
}

# @See https://github.com/tmux/tmux/wiki/FAQ#what-is-the-passthrough-escape-sequence-and-how-do-i-use-it
tmux_passthrough_escape() {
	local string_to_wrap=$1
	if (is_in_tmux); then
		if ! (tmux show-options -g allow-passthrough | grep -q "on"); then
			echo "allow-passthrough must be set for ANSI escaping passthrough to work with tmux"
			return 1
		fi
		printf "\033Ptmux;\033%s\033\\" "$string_to_wrap"
		return 0
	fi
	echo -ne "$string_to_wrap"
}

tmux_attach_with_init() {
	local tmux_session_name=$1
	set_title "$(printf "%s %s" "\Uebc8" "$tmux_session_name")"
	tmux attach-session -t "$tmux_session_name"
}

tmux_auto_open() {
	local tmux_session_name=$(tmux_generate_session_name "$1")
	echo "Session name = $tmux_session_name"

	# Check if we are already in the session
	if [[ $(tmux_get_active_session_name) == "$tmux_session_name" ]]; then
		echo "Already in session"
		return
	fi

	# Search for active session first, and attach if exists
	if (tmux has-session -t "$tmux_session_name" 2>/dev/null); then
		echo "Attaching to existing session"
		tmux_attach_with_init "$tmux_session_name"
		return
	fi

	PANE_NUM=1
	select pane_config in "1 Pane" "2 Pane (H-Split)" "3 Pane (V, HH)"; do
		case $pane_config in
			"1 Pane") break ;;
			"2 Pane (H-Split)") PANE_NUM=2 && break ;;
			"3 Pane (V, HH)") PANE_NUM=3 && break ;;
		esac
	done
	echo "Creating new session ($tmux_session_name)"
	tmux new-session -s "$tmux_session_name" -d

	tmux set-environment -t "$tmux_session_name" JTZ_SESSION_NAME "$tmux_session_name"

	if [[ $PANE_NUM -gt 1 ]]; then
		tmux split-window -h -t "$tmux_session_name:0"
		# For 3-pane, v-split the first pane
		if [[ $PANE_NUM -eq 3 ]]; then
			tmux select-pane -t "$tmux_session_name":0.0
			tmux split-window -v -t "$tmux_session_name"
		fi
	fi

	# Loop through all panes and exec `activate`
	for pane_id in $(tmux list-panes -F "#{pane_id}" -t "$tmux_session_name"); do
		tmux send-keys -t "${tmux_session_name}:0.${pane_id}" activate C-m 2>&1
	done

	tmux select-pane -t "$tmux_session_name":0.0
	tmux_attach_with_init "$tmux_session_name"
}

# This function scans for active tmux sessions where at least one pane
# has a working directory scoped to the current one - which is useful if you
# forgot what you named the session, but remember where you were working in.
# If there are more than one matching sessions, it will let you select
# which one to attach to with `fzf`
tmux_auto_attach() {
	# Get the current working directory
	current_dir=$(pwd)

	# Get a list of all active tmux sessions
	active_sessions=()
	while IFS='' read -r line; do active_sessions+=("$line"); done < <(tmux list-sessions -F "#{session_name}" 2>/dev/null)

	# Loop through all sessions, and check if any of the panes have a
	# working directory that matches the current one
	matching_sessions=()
	for session in "${active_sessions[@]}"; do
		# Get list of pane paths
		pane_paths=()
		while IFS='' read -r line; do pane_paths+=("$line"); done  < <(tmux list-panes -t "$session" -F "#{pane_current_path}" 2>/dev/null)
		for pane_path in "${pane_paths[@]}"; do
			if [[ "$pane_path" == "$current_dir" ]]; then
				matching_sessions+=("$session")
				break
			fi
		done
	done

	declare -p matching_sessions

	# If there is only one matching session, attach to it
	if [[ ${#matching_sessions[@]} -eq 1 ]]; then
		matching_session_name=${matching_sessions[0+$ARRAY_INDEX_START]}
		echo "Found only 1 matching session ($matching_session_name). Auto-attaching now..."
		sleep 2
		tmux_attach_with_init "$matching_session_name"
		return
	fi

	# If there are multiple matching sessions, let the user select which one to attach to
	if [[ ${#matching_sessions[@]} -gt 1 ]]; then
		echo "More than one matching tmux session was found. Which would you like to attach to?"
		selected_session=$(printf "%s\n" "${matching_sessions[@]}" | fzf)
		if [[ -n "$selected_session" ]]; then
			tmux_attach_with_init "$selected_session"
			return
		fi
	fi

	# If no matching sessions, just open a new one
	echo "Could not find matching session"
	tmux_auto_open ""
}

tmux_auto_close() {
	tmux_session_name=$(tmux_generate_session_name "$1")
	if (tmux has-session -t "$tmux_session_name" 2>/dev/null); then
		echo "Killing session ('$tmux_session_name')"
		tmux kill-session -t "$tmux_session_name"
	else
		echo "No session to kill (could not find '$tmux_session_name')"
	fi
}

# Revert the last commit, but don't undo the changes
git_revert_last() {
	git reset HEAD~1
}

git_sha_short() {
	git rev-parse --short HEAD
}

git_sha_full() {
	git rev-parse HEAD
}

git_sha_both() {
	echo "$(git_sha_full)\t$(git_sha_short)"
}

git_has_lfs_files() {
	git lfs ls-files | grep -q .
}

git_trunk_branch() {
	git remote show origin | grep "HEAD branch" | cut -d ":" -f 2 | sed -e 's/^[[:space:]]*//'
}

git_root_dir() {
	git rev-parse --show-toplevel
}

git_repo_name() {
	remote_url=$(git_remote_url)
	basename "$remote_url"
}

git_repo_name_normalized() {
	normalize_name "$(git_repo_name)"
}

git_cd_root_dir() {
	cd "$(git_root_dir)" || exit
}

git_trunk_ahead_files() {
	TRUNK_BRANCH=$(git_trunk_branch)
	git fetch
	git --no-pager diff --name-only origin/"$TRUNK_BRANCH"...HEAD
}

# This should essentially be the file list of the diff for your `push`
git_local_ahead_of_remote_files() {
	CURRENT_BRANCH=$(git_branch_name)
	git fetch
	git --no-pager diff --name-only origin/"$CURRENT_BRANCH"...HEAD
}

git_update_local_trunk() {
	TRUNK_BRANCH=$(git_trunk_branch)
	CURRENT_BRANCH=$(git_branch_name)
	if [[ "$TRUNK_BRANCH" == "$CURRENT_BRANCH" ]]; then
		git pull
		return
	fi
	git fetch
	git fetch . origin/"$TRUNK_BRANCH":"$TRUNK_BRANCH"
}

git_behind_ahead_plain() {
	git fetch
	local TRUNK_BRANCH=$(git_trunk_branch)
	git rev-list --left-right --count origin/"$TRUNK_BRANCH"...HEAD
}

git_behind_ahead() {
	# Get the trunk / main branch in the repo (e.g. `main`)
	local TRUNK_BRANCH=$(git_trunk_branch)
	git fetch
	echo "Behind | Ahead"
	echo "      $(git_behind_ahead_plain)"
}



git_stat_live() {
	if [[ $* == *--summary ]]; then
		watch -n 2 -c "git diff --staged --stat  ':(exclude)package-lock.json' | tail -n 1"
	fi
	watch -n 2 -c "git diff --staged --stat  ':(exclude)package-lock.json'"
}

git_diff_live() {
	watch -n 2 -c "git diff --staged ':(exclude)package-lock.json'"
}

git_select_commit() {
	MAX_PAST_COMMITS_TO_LIST=40
	commits=$(git log --pretty=format:"%H %s" -n $MAX_PAST_COMMITS_TO_LIST)

	# Use fzf to interactively select a commit
	commit=$(echo "$commits" | fzf --height 70% --reverse --ansi)

	# Extract the commit hash from the selected line
	commit_hash=$(echo "$commit" | awk '{print $1}')

	echo "$commit_hash"
}

# Given a stash string like `stash@{0}: On main: do x and y`,
# extract out just the stash index
git_extract_stash_index() {
	stash_string="$1"
	echo "$stash_string" | grep -o -E "\{[0-9]+\}" | tr -d "{}"
}

git_stash_select() {
	stash_list=$(git stash list)
	# shellcheck disable=SC2016
	selected_stash=$(echo "$stash_list" | fzf \
		--height 70% \
		--reverse \
		--ansi \
		--preview "source ~/.zshrc && git stash show -p "'"$(git_extract_stash_index {})"'""
	)
	echo "$selected_stash"
}
alias git_select_stash="git_stash_select"
alias git_stash_list="git_stash_select"
alias git_stash_preview="git_stash_select"

git_copy_commit_sha() {
	commit_hash=$(git_select_commit)
	echo "$commit_hash" | copy_to_clipboard
}

git_copy_commit_msg() {
	commit_hash=$(git_select_commit)
	commit_msg=$(git log --pretty=format:"%B" -n 1 "$commit_hash")
	echo "$commit_msg" | copy_to_clipboard
}

# Use this to interactively select a past commit to target for `git commit --fixup=`
git_fixup() {
	commit_hash=$(git_select_commit)
	git commit --fixup="$commit_hash"
}


# TODO: This works, but really should be re-written in JS or Python
# (too many ZSH and bash workarounds, hard to read)
git_find_fixup_base() {
	MAX_PAST_COMMITS_TO_SCAN_PER_FIXUP=40
	LOG_DIVIDER="$UNIT_SEPARATOR_CHAR"
	seeking_commit_msgs=()
	commit_scan_counter=0
	# Iterate over all git log entries
	git log --pretty=format:"%H${LOG_DIVIDER}%s" | while read line
	do
		# Check if we already at limit and need to bail out
		commit_scan_counter=$((commit_scan_counter+1))
		if [[ $commit_scan_counter -gt $MAX_PAST_COMMITS_TO_SCAN_PER_FIXUP ]]; then
			echo "Could not find the ultimate fixup base, and limit of $MAX_PAST_COMMITS_TO_SCAN_PER_FIXUP scan commits reached"
			echo "Still seeking / could not find within limit:"
			printf "\t%s\n" "$(declare -p seeking_commit_msgs)"
			return 1
		fi

		# Extract out commit hash and message from git log line
		commit_hash=$(echo "$line" | awk -F"$LOG_DIVIDER" '{ print $1 }')
		commit_msg=$(echo "$line" | awk -F"$LOG_DIVIDER" '{ print $2 }')

		# Is this a `fixup! {original message}` commit?
		if [[ "$commit_msg" == "fixup! "* ]]; then
			# Add message, without `fixup! ` prefix, to search list
			target_commit_msg=${commit_msg#"fixup! "}
			seeking_commit_msgs+=("$target_commit_msg")

			# Reset the scan counter, so we can search x num past this new point
			commit_scan_counter=0
		elif [[ ${#seeking_commit_msgs[@]} -gt 0 ]]; then
			# Remove all fixups that fix this commit
			holes_count=0
			for ((i=0; i<${#seeking_commit_msgs[@]}; i++)); do
				if [[ ${seeking_commit_msgs[$i+$ARRAY_INDEX_START]} == "$commit_msg" ]]; then
					unset -v 'seeking_commit_msgs[$i+$ARRAY_INDEX_START]'
					holes_count=$((holes_count+1))
				fi
			done

			# Are we done yet?
			if [[ $holes_count -eq ${#seeking_commit_msgs[@]} ]]; then
				echo "${commit_hash}~1"
				return 0
			fi

			# Remove holes / sparse -> dense
			# Not double-quoting this is the easiest way to do this without
			# accidentally leaving empty strings
			# shellcheck disable=SC2128
			# shellcheck disable=SC2206
			seeking_commit_msgs=($seeking_commit_msgs)
		fi
	done
}

git_find_github_pr() {
	SHA=$1
	gh pr list --search "$SHA"
}

# Use this with `--fixup` commits, to auto-target the last commit before fixup
# with interactive rebase
# Options:
#	(flag) `--editor`: Don't skip the editor (_DO_ stop on editor)
git_auto_rebase() {
	local skip_editor=$([[ $* == *--editor ]] && echo "false" || echo "true")
	local new_target_base=$(git_find_fixup_base)

	if [[ $? -ne 0 ]]; then
		echo "$new_target_base"
		echo "Could not auto-find new base. Cancelling auto-rebase"
		return 1
	fi

	while true; do
		echo "Found target base:"
		printf "\t%s\n" "$new_target_base"
		printf "\t%s\n Target Base = " "$(git show --no-patch --oneline "$new_target_base" | cat)"
		printf "Continue? [Yy]es / ENTER, [Nn]o, [Cc]ancel\n"
		read -r answer
		case $answer in
			[Yy]*) break ;;
			"") break ;;
			[Nn]*) return 0 ;;
			[Cc]*) return 0 ;;
		esac
	done

	local git_version=$(git --version | grep -E -o "\d+\.\d+.\d+$")

	if [[ "$skip_editor" != "true" ]]; then
		git rebase --autosquash --interactive "$new_target_base"
		return
	fi

	# New in git 2.44 - auto-squash support in non-interactive mode
	if [[ $(parse_version_string "$git_version") -ge $(parse_version_string "2.44") ]]; then
		git rebase --autosquash "$new_target_base"
	else
		# Use `GIT_SEQUENCE_EDITOR=true` to skip editor
		GIT_SEQUENCE_EDITOR=true git rebase --autosquash --interactive "$new_target_base"
	fi

}


git_branch_name() {
	git rev-parse --abbrev-ref HEAD
}

# WARNING: This errors if no corresponding tag can be found
git_tag_name() {
	git describe --tags --abbrev=0
}

# NOTE: This returns the remote branch name, prefixed with the name of the remote itself
# E.g.
#	`origin/my-branch`
git_remote_branch() {
	# https://stackoverflow.com/a/9753364/11447682
	git for-each-ref --format='%(upstream:short)' "$(git symbolic-ref -q HEAD)"
}

git_remote_url() {
	git remote get-url origin
}

git_branch_backup() {
	# Default to current branch
	local branch_to_backup=$(git rev-parse --abbrev-ref HEAD)
	# Check if a different branch, other than the current, was specified to backup
	if [[ -n "$1" ]]; then
		if (git branch | grep --silent "$1"); then
			branch_to_backup="$1"
		else
			echo "Branch $1 does not exist"
			return 1
		fi
	fi
	backup_branch_name="backup/$branch_to_backup--$(date '+%Y-%m-%d--%I-%M-%p')"
	git branch "$branch_to_backup" "$backup_branch_name"
	echo "✅ Backed up branch $branch_to_backup to $backup_branch_name"
}
alias git_backup_branch="git_branch_backup"

git_checkout_dirty() {
	target_branch_name=$1
	operation="git checkout $target_branch_name"
	git_do_while_dirty "$operation"
}
if [[ $SHELL_TYPE == "ZSH" ]]; then
	:
	# TODO: This is close, but not working perfectly
	# compdef _git git_checkout_dirty=git-checkout
fi

git_sparse_checkout() {
	local OUT_DIR=""
	local REMOTE=""
	local BRANCH=""
	local SUB_PATHS=()

	while [[ ! $# -eq 0 ]]
	do
		case "$1" in
			-o|--out-dir)
				OUT_DIR=$2
				shift
				;;
			-r|--remote)
				REMOTE=$2
				shift
				;;
			-b|--branch)
				BRANCH=$2
				shift
				;;
			*)
				SUB_PATHS+=("$1")
				shift
				;;
		esac
		shift
	done

	local ERR=0
	if [[ -z "$REMOTE" ]]; then
		echo "You must specify the remote URL / source (-r / --remote)"
		ERR=1
	fi
	if [[ -z "$OUT_DIR" ]]; then
		echo "You must specify the destination directory (-o / --out-dir)"
		ERR=1
	fi
	[[ $ERR -eq 1 ]] && return 1

	local GIT_ARGS=(clone --filter=blob:none --no-checkout --depth 1)
	if [[ -n "$BRANCH" ]]; then
		GIT_ARGS+=(--branch "$BRANCH")
	fi
	GIT_ARGS+=(--sparse)

	# Clone into out_dir and cd to it
	git "${GIT_ARGS[@]}" "$REMOTE" "$OUT_DIR"
	pushd "$OUT_DIR" || exit

	# Selectively add the sub paths
	for sub_path in "${SUB_PATHS[@]}"; do
		git sparse-checkout add "$sub_path"
	done
	git checkout
	popd || exit
}

# TODO: would be nice if this could separately stash dropped changes (even if just in a patch file)
git_do_while_dirty() {
	git_operation="$*"
	IFS=

	# If no operation was provided, default to very last command
	if [[ -z "$git_operation" ]]; then
		git_operation=$(fc -ln -1)
		echo "No command passed. Did you want to retry your last command?"
		printf "\t%s\n" "$git_operation"
		while true; do
			printf "Retry? [Yy]es / ENTER, [Nn]o, [Cc]ancel\n"
			read -r answer
			case $answer in
				[Yy]*) break ;;
				"") break ;;
				[Nn]*) return 0 ;;
				[Cc]*) return 0 ;;
			esac
		done
	fi


	# If user forgot to include `git`, add it for them. E.g., passing `pull` instead of `git pull`
	if [[ $git_operation != git* ]]; then
		git_operation="git $git_operation"
	fi

	echo "Operation to try = '$git_operation'"

	# Error out when command is NOT run from root of git repo, as this can cause issues with things
	# like `git checkout ${PATHSPEC}`, as the paths git's stdout uses are relative to repo root,
	# even if you running command from subdirectory
	git_root=$(git rev-parse --show-toplevel)
	if [[ "$git_root" != "$PWD" ]]; then
		echo "ERROR: You are not running this command from the root of a git repository"
		echo "This can cause issues with things like \`git checkout\`, as the paths git's stdout"
		echo "uses are relative to repo root, even if you running command from subdirectory"
		echo "Current directory: $PWD"
		echo "Git root: $git_root"
		return 1
	fi

	git_operation_results=$($SHELL -c "$git_operation" 2>&1)

	# If operation was clean, nothing to do
	error_string_test=$(echo "$git_operation_results" | grep -E "error: Your local changes to the following files would be overwritten by")

	# TODO: Add check for `error: The following untracked working tree files would be overwritten by merge:`

	echo "$error_string_test"
	if [[ "$error_string_test" == "" ]]; then
		echo "✅🚀 Operation was clean"
		return 0
	fi

	# Get list of conflicting file paths
	dirty_files=$(echo "$git_operation_results" | grep -E -o "^[[:blank:]]+.*" | sed -e 's/^[[:space:]]*//')
	cat << EOF
========= DIRTY FILES =========
$dirty_files
===============================
EOF

	# Use stash to temporarily stash changes
	# Newer versions of git can support stashing just staged changes
	use_staged_stash=false
	git_version=$(git --version | grep -E -o "\d+\.\d+.\d+")
	if [[ $(parse_version_string "$git_version") -ge $(parse_version_string "2.35") ]]; then
		echo "Found git version >= 2.3"
		echo "💡 Your git version supports staged stashes."
		use_staged_stash=true
	else
		while true; do
			printf "⚠️ Your git version does NOT support staged stashes. Continue? [Yy]es / ENTER, [Nn]o, [Cc]ancel\n"
			read -r answer
			case $answer in
				[Yy]*) break ;;
				"") break ;;
				[Nn]*) return 0 ;;
				[Cc]*) return 0 ;;
			esac
		done
	fi

	ITEMS_PRESERVED=0
	# Go through list of conflicting files and ask what the user wants to do
	preserve="unsure"
	# different fd (`<&9`) is to avoid conflict with inner `read`
	# https://stackoverflow.com/q/6911520/11447682
	while IFS= read -r dirty_file <&9; do
		if [[ $preserve == "unsure" ]]; then
			while true; do
				# Ask user what to do about this (and rest) of files
				printf "❔ Keep changes to %s?\n" "$dirty_file"
				printf "[Aa]ll files, [Yy]es / ENTER, [Nn]o, / [Dd]rop+rest, [Pp]review, [Cc]ancel\n"
				read -r answer
				case $answer in
					[Aa]*) preserve="all" && break ;;
					[Yy]*) preserve="yes" && break ;;
					"") break ;;
					[Nn]*) preserve="no" && break ;;
					[Dd]*) preserve="none" && break ;;
					[Pp]*) git diff "$dirty_file" ;;
					[Cc]*) return 0 ;;
				esac
			done
		fi

		if [[ $preserve == "none" ]]; then
			git checkout "$dirty_file"
		elif [[ $preserve == "all" ]]; then
			git add "$dirty_file"
			ITEMS_PRESERVED=$((ITEMS_PRESERVED+1))
		else
			if [[ $preserve == "yes" ]]; then
				git add "$dirty_file"
				ITEMS_PRESERVED=$((ITEMS_PRESERVED+1))
			else
				git checkout "$dirty_file"
				# There is an edge-case where this can fail; if the file that is conflicting
				# is a previously / currently untracked file, but the upstream is now tracking
				# it / has added it, then `git checkout file` will not work, because it isn't
				# in git to begin with, but at the same time, you can't git pull if it now
				# exists in the upstream.
				# In this scenario, [...] TODO
			fi
			# Reset for next go-around
			preserve="unsure"
		fi
	done 9<<< "$dirty_files"

	if [[ $ITEMS_PRESERVED -gt 0 ]]; then
		if [[ $use_staged_stash == "true" ]]; then
			git stash --staged
			# TODO
			# git stash --staged -m "TODO gen message"
		else
			git stash
		fi
	fi

	# Actually do the thing
	$SHELL -c "$git_operation"

	if [[ $ITEMS_PRESERVED -gt 0 ]]; then
		git stash pop
	fi
}

# You can use this to delete branch names nested under a slash (or other patterns)
#	Example: `git_branch_delete_pattern feature-a/tmp/*`
git_branch_delete_pattern() {
	git_branch_pattern=$1
	matching_branches=$(git branch --list "$git_branch_pattern")
	echo "This will delete the following branches"
	echo "$matching_branches"
	hard_delete=0
	while true; do
		printf "Are you sure? [Yy]es / ENTER, [Hh]ard delete, [Cc]ancel / [Nn]o\n"
		read -r answer
		case $answer in
			[Yy]*) break ;;
			[Hh]*) hard_delete=1 && break ;;
			"") break ;;
			[Cc]*) return 0 ;;
			[Nn]*) return 0 ;;
		esac
	done
	if [[ $hard_delete == 1 ]]; then
		echo "$matching_branches" | xargs git branch -D
		return 0
	fi
	echo "$matching_branches" | xargs git branch -d
}

git_stats() {
	git fetch
	local CURRENT_BRANCH=$(git_branch_name)
	local REMOTE_BRANCH=$(git_remote_branch)
	local TRUNK_BRANCH=$(git_trunk_branch)
	local trunk_diff_stats=$(git diff --staged --stat "origin/$TRUNK_BRANCH" | tail -n 1)

	local remote_diff_stats=""
	if [[ -n "$REMOTE_BRANCH" ]]; then
		remote_diff_stats=$(git diff --stat "$REMOTE_BRANCH" | tail -n 1)
	else
		REMOTE_BRANCH="(UNSET)"
		remote_diff_stats="NA"
	fi

	cat <<- EOF
		+=====================================================================================
		|                                      |
		|   .oooooo.     ooooo  ooooooooooooo  |  Branch = $CURRENT_BRANCH
		|  d8P'   Y8b     888   8    888    8  |  Trunk Branch = $TRUNK_BRANCH
		|  888            888        888       |    Trunk Diff Stats = $trunk_diff_stats
		|  888            888        888       |  Remote Branch = ${REMOTE_BRANCH}
		|  888     ooooo  888        888       |    Remote Diff Stats = ${remote_diff_stats}
		|  .88.    .88'   888        888       |    Behind / Ahead =
		|  .Y8bood8P.    o888o      o888o      |      Behind | Ahead
		|                                      |         $(git_behind_ahead_plain)
		|                                      |
		+=====================================================================================
	EOF
}

# Display most touched and/or most recently touched
git_heatmap() {
	echo "TODO"
}

# Get information about the state of things while stopped during a rebase
git_rebase_info() {
	# TODO
	:
}

git_tree_view() {
	ALL=1
	while true; do
		printf "What to show? [Aa]ll / ENTER, Current [Bb]ranch\n"
		read -r answer
		case $answer in
			[Aa]*) break ;;
			"") break ;;
			[Bb]*) ALL=0 && break ;;
			[Cc]*) return 0 ;;
		esac
	done
	if [[ $ALL == 1 ]]; then
		git log --graph --oneline --decorate --all
	else
		git log --graph --oneline --decorate
	fi
}


# Program to pack an entire repo, WITH TRACKING, into a single compressed tarball.
# Supports git LFS!
# To use, unpack and then git clone the unpacked dir
git_pack_to_tarball_with_tracking() {
	local ARCHIVE_PATH="$1"
	local TRUNK_BRANCH=$(git_trunk_branch)

	# Error out when command is NOT run from root of git repo, as this tends to complicate things
	local git_root=$(git rev-parse --show-toplevel)
	if [[ "$git_root" != "$PWD" ]]; then
		echo "ERROR: You are not running this command from the root of a git repository"
		echo "Current directory: $PWD"
		echo "Git root: $git_root"
		return 1
	fi

	# If ARCHIVE_PATH was not specified, default to repo / project name, plus hash, plus ext
	if [[ -z "$ARCHIVE_PATH" ]]; then
		ARCHIVE_PATH="$(project_name_normalized)___$(git_sha_full).tar.gz"
		echo "Defaulting output filename to $ARCHIVE_PATH"
	fi

	local TMP_DIR=$(mktemp -d)
	echo "🔗 Temp dir for bundling = $TMP_DIR"

	echo "At a minimum, there are $(git ls-files | wc -l) files to clone and pack"
	local HAS_LFS_FILES=0

	if (git_has_lfs_files); then
		echo "📎 Git LFS files detected"
		HAS_LFS_FILES=1
	fi

	# For backing up source code PLUS actual git history (`.git`) our options are actually pretty limited,
	# because
	# - `git archive` only archives files based on `.gitignore`; does not include `.git` objects
	# - `git bundle` does include git objects, but does not work well with git LFS (which we use for large files)
	# So, instead use "bare" repo folders to clone
	local BARE_REPO_DIR_NAME=$(git_repo_name_normalized)
	mkdir -p "$TMP_DIR/$BARE_REPO_DIR_NAME"
	local GIT_BARE_REMOTE_PATH="file://$TMP_DIR/$BARE_REPO_DIR_NAME"
	pushd "$TMP_DIR/$BARE_REPO_DIR_NAME" || exit
	echo "🏗️ Initializing temp bare repository"
	git init --bare
	popd || exit

	git remote add git-bare-clone "$GIT_BARE_REMOTE_PATH"

	if [[ $HAS_LFS_FILES -eq 1 ]]; then
		echo "🔁 Making sure LFS is up-to-date"
		git lfs fetch --all
	fi

	echo "💾 Cloning to temp bare repo..."
	git push git-bare-clone "$TRUNK_BRANCH"

	if [[ $HAS_LFS_FILES -eq 1 ]]; then
		echo "  ↳ 💾 Pushing LFS objects to temp bare clone"
		git lfs push --all git-bare-clone
	fi

	local UNPACKED_SIZE=$(du -hs "$TMP_DIR/$BARE_REPO_DIR_NAME")

	# Detach
	git remote remove git-bare-clone
	# Pack
	echo "🔎 Unpacked dirname will be $BARE_REPO_DIR_NAME"
	echo "📦 Packing into tarball..."
	echo "📦 ..."
	echo "📦 ......"
	echo "📦 ........."
	tar --cd "$TMP_DIR" -czf "$TMP_DIR/git-repository.tar.gz" "$BARE_REPO_DIR_NAME"

	# Move file, cleanup
	echo "💾 Copying tarball to final location"
	mv "$TMP_DIR/git-repository.tar.gz" "$ARCHIVE_PATH"
	local PACKED_SIZE=$(du -hs "$ARCHIVE_PATH")
	rm -rf "$TMP_DIR"

	echo "✅ Done! Tarball exported and temp dir deleted."
	echo "  ↳ Final Path = $ARCHIVE_PATH"
	echo "     ↳ Packed Size = $PACKED_SIZE"
	echo "  ↳ Unpacked name = $BARE_REPO_DIR_NAME"
	echo "     ↳ Unpacked Size = $UNPACKED_SIZE"
}

docker_pick_container_full() {
	local multi=$([[ -n "$multi" ]] && echo "true" || echo "false")
	# TODO support picking non-active containers
	# TODO add fzf preview (show more details?)
	local container_list=$(docker ps --format "table {{.ID}}\t{{.Image}}\t{{.Names}}")
	local fzf_args=("--header-lines=1" "--reverse")
	if [[ "$multi" == "true" ]]; then
		fzf_args+=("-m")
	fi
	local container=$(echo "$container_list" | fzf "${fzf_args[@]}")
	if [[ -z "$container" ]]; then
		return 1
	fi
	echo "$container" # ID | Image |  Name
}

docker_pick_container() {
	local container=$(docker_pick_container_full)
	if [[ -z "$container" ]]; then
		return 1
	fi
	local container_id=$(echo "$container" | awk '{print $1}')
	echo "$container_id"
}

docker_pick_image() {
	all_images=$(docker image ls --format "table {{.Repository}}:{{.Tag}}\t{{.ID}}")
	selected_image=$(echo "$all_images" | fzf --height 40% --reverse --header-lines=1)
	if [[ -z "$selected_image" ]]; then
		return 1
	fi
	image_id=$(echo "$selected_image" | awk '{print $2}')
	echo "$image_id"
}

docker_stop() {
	# TODO add `--all` flag
	local containers_str=$(multi=1 docker_pick_container_full)
	if [[ -z "$containers_str" ]]; then
		return 1
	fi
	while IFS='' read -r line; do containers+=("$line"); done < <(echo "$containers_str")
	for container_line in "${containers[@]}"; do
		local container_id=$(echo "$container_line" | awk '{print $1}')
		local container_name=$(echo "$container_line" | awk '{print $3}')
		echo "Stopping $container_name ($container_id)"
		docker stop "$container_id"
	done
}

docker_restart() {
	local HARD_RESTART=$([[ $* == *--hard* ]] && echo "true" || echo "false")
	local EXTRA_ARGS=()
	if [[ $* == *--detach* ]]; then
		EXTRA_ARGS+=("-d")
	fi
	local container=$(docker_pick_container_full)
	if [[ -z "$container" ]]; then
		return 1
	fi
	local container_id=$(echo "$container" | awk '{print $1}')
	local container_name=$(echo "$container" | awk '{print $3}')
	echo "Restarting $container_name ($container_id)"

	if [[ "$HARD_RESTART" == "true" ]]; then
		docker stop "$container_id"
		docker start --force-recreate "${EXTRA_ARGS[@]}" "$container_id"
	else
		docker restart "$container_id"
	fi
}

docker_copy_to_container() {
	local host_source="$1"
	local container_destination="${2:="/tmp/"}"
	if [[ -z "$host_source" ]]; then
		echo "No source file specified"
		return 1
	fi
	if [[ ! -e "$host_source" ]]; then
		echo "Source file does not exist"
		return 1
	fi
	[[ -z "$CONTAINER_REF" ]] && local CONTAINER_REF="$(docker_pick_container)"
	if [[ -z "$CONTAINER_REF" ]]; then
		return 1
	fi
	echo "Copying $host_source to $CONTAINER_REF:$container_destination"
	docker cp "$host_source" "$CONTAINER_REF:$container_destination"
}
alias docker_copy="docker_copy_to_container"

# Note: For debugging usage, the new `docker debug` command looks promising,
# but requires a paid plan to use
docker_exec_it() {
	local CONTAINER_REF=$CONTAINER_REF
	if [[ -z "$CONTAINER_REF" ]]; then
		CONTAINER_REF=$(docker_pick_container)
	fi
	if [[ -z "$CONTAINER_REF" ]]; then
		return 1
	fi
	local TARGET_BIN=$1
	if [[ -z "$TARGET_BIN" ]]; then
		TARGET_BIN="bash"
	fi
	if [[ "$TARGET_BIN" == "bash" ]]; then
		# Try first, to see if we should fall back to sh
		docker exec "$CONTAINER_REF" bash --help > /dev/null
		if [[ $? -ne 0 ]]; then
			echo "Falling back to sh, bash not found"
			TARGET_BIN="sh"
		fi
	fi
	docker exec -it "$CONTAINER_REF" "$TARGET_BIN"
}

docker_get_working_dir() {
	CONTAINER_REF=$1
	docker inspect --format='{{json .Config.Labels}}' "$CONTAINER_REF" | jq '.["com.docker.compose.project.working_dir"]'
}

# Pick a small(ish) docker image; useful for various ephemeral purposes
docker_pick_minimal_image_name() {
	select image in "busybox (smallest, no bash)" "alpine (small, no bash)" "debian (w/bash)" "ubuntu (w/bash)"; do
		case $image in
			# https://hub.docker.com/_/busybox
			busybox*) echo "busybox" && break ;;
			# https://hub.docker.com/_/alpine
			alpine*) echo "alpine" && break ;;
			# https://hub.docker.com/_/debian
			debian*) echo "debian" && break ;;
			# https://hub.docker.com/_/ubuntu
			ubuntu*) echo "ubuntu" && break ;;
			*) echo "Invalid selection" ;;
		esac
	done
}

# Uses a temporary (small) docker container to mount a volume for inspection
docker_inspect_volume() {
	VOLUME_NAME=$1
	if ! (docker volume ls | grep "$VOLUME_NAME$" > /dev/null); then
		echo "Volume not found"
		return 1
	fi
	IMAGE_NAME=$(docker_pick_minimal_image_name)
	IMAGE_SHELL=$(echo "$IMAGE_NAME" | grep -q -E "busybox|alpine" && echo "sh" || echo "bash")
	cat <<- EOF
		Temp Image = $IMAGE_NAME
		Shell = $IMAGE_SHELL
		Volume = $VOLUME_NAME
		Container Mount = /tmp/volume

		Have fun inspecting!
	EOF
	docker run --rm -it -v "$VOLUME_NAME":/tmp/volume "$IMAGE_NAME" "$IMAGE_SHELL" -c "cd /tmp/volume; exec $IMAGE_SHELL"
}

docker_list_binds() {
	CONTAINER_REF=$(docker_pick_container)
	docker inspect --format='{{json .HostConfig.Binds}}' "$CONTAINER_REF" | jq
}

docker_is_image_available_locally() {
	local IMAGE_REF="$1"
	docker image inspect "$IMAGE_REF" > /dev/null
}

# For docker container names, only "[a-zA-Z0-9][a-zA-Z0-9_.-]" are allowed.
docker_normalize_name_container() {
	local CONTAINER_NAME=$1
	# Replace `:` with `-`
	CONTAINER_NAME="$(echo "$CONTAINER_NAME" | sed -e 's/:/-/g')"
	# For everything else, just remove char entirely
	CONTAINER_NAME="$(echo "$CONTAINER_NAME" | sed -e 's/[^a-zA-Z0-9_.-]//g')"
	echo "$CONTAINER_NAME"
}

docker_image_exec() {
	local image_id=$1
	if [[ -n "$image_id" ]] && ! (echo "$image_id" | grep -q -E "^-"); then
		shift
	else
		image_id=$(docker_pick_image)
	fi
	if [[ -z "$image_id" ]]; then
		return 1
	fi
	local CONTAINER_NAME=$(docker_normalize_name_container "$image_id-$(date_ms)")
	local DOCKER_SHELL="$DOCKER_SHELL"
	if [[ -z $DOCKER_SHELL ]]; then
		DOCKER_SHELL="bash"
	fi
	docker run --name "$CONTAINER_NAME" --rm -it "$@" "$image_id" "/bin/$DOCKER_SHELL"
}
alias docker_exec_image="docker_image_exec"
alias docker_run_image_interactive="docker_exec_image"

# Throwaway container for PostgreSQL
docker_temp_pg() {
	local IMAGE_NAME="postgres:latest"
	local HOST_PORT="5432"
	# Check for already bound
	if (find_pid_by_port "$HOST_PORT"); then
		echo "Port $HOST_PORT is already bound; using randomized port"
		docker_image_exec "$IMAGE_NAME" -p 5432 "$@"
		return 0
	fi
	docker_image_exec "$IMAGE_NAME" -p "$HOST_PORT:5432" "$@"
}

# Execs pg_dump inside a given Docker container, and then copies the backup out
# of the container before deleting
# TODO: Would be cool to rework this to handle a bunch of different DB formats
pg_dump_container() {
	local db_user
	local db_pass
	local db_name
	local container_ref

	while [[ ! $# -eq 0 ]]
	do
		case "$1" in
			-c|--container)
				INSTANCE_ID=$2
				shift
				;;
			-u|--username)
				db_user=$2
				shift
				;;
			-p|--password)
				db_pass=$2
				shift
				;;
			-d|--database)
				db_name=$2
				shift
				;;
			*)
				echo "Invalid option ${1}"
				;;
		esac
		shift
	done

	if [[ -z $container_ref ]]; then
		container_ref=$(docker_pick_container)
		if [[ -z $container_ref ]]; then
			return 1
		fi
	fi

	DUMP_DB_DIR="/tmp/pg_dump_temp"
	DUMP_DB_PATH="${DUMP_DB_DIR}/${db_name}__dump.sql"
	PG_DUMP_SCRIPT=$(cat <<- EOF
	mkdir -p "$DUMP_DB_DIR"
	PGPASSWORD="$db_pass" pg_dump -U $db_user $db_name > "$DUMP_DB_PATH"
	if ! [[ -s $DUMP_DB_PATH  ]]; then
		exit 1
	fi
	EOF
	)
	echo "🚀 Running backup script"
	if ! docker exec "$container_ref" /bin/bash -c "$PG_DUMP_SCRIPT"; then
		echo "🚨 Backup failed"
		return 1
	fi
	echo "💾 Copying backup out of container"
	docker cp "$container_ref:$DUMP_DB_PATH" .
	echo "🗑️ Cleaning up"
	docker exec "$container_ref" /bin/bash -c "rm -f $DUMP_DB_PATH"
}

docker_inspect_image() {
	image_id=$(docker_pick_image)
	docker inspect "$image_id"
}
alias docker_inspect_image_interactive="docker_inspect_image | jless"

docker_inspect_image_init() {
	local image_json=$(docker_inspect_image)
	echo "$image_json" | jq '.[0].Config | {Cmd, Entrypoint}'
}

docker_inspect_container() {
	CONTAINER_REF=$(docker_pick_container)
	docker inspect "$CONTAINER_REF"
}
alias docker_inspect_container_interactive="docker_inspect_container | jless"

docker_inspect_container_init() {
	local CONTAINER_REF=$(docker_pick_container)
	docker inspect "$CONTAINER_REF" | jq '.[0].Config | {Cmd, Entrypoint}'
}

docker_inspect_networks() {
	local combined_network_json=""
	# NOTE: We can't simply use `docker network ls --format json`, because
	# this doesn't output as much info as `docker network inspect`
	local combined_network_json=""
	for docker_network_id in $(docker network ls | sed -r '1d;' | awk '{print $1}'); do
		# Note: `sed` usage is to remove first and last lines, since Docker
		# wraps output in array (`[]`) for some reason
		local network_json=$(docker network inspect "$docker_network_id" | sed -r '1d;$d')
		if [[ $combined_network_json != "" ]]; then
			combined_network_json="${combined_network_json},"
		fi
		combined_network_json="${combined_network_json}${network_json}"
	done
	render_json_as_table "[${combined_network_json}]"
}

docker_log_follow() {
	CONTAINER_REF=$(docker_pick_container)
	docker logs -f "$CONTAINER_REF"
}

run_raw_cmd_in_dotfiles_venv() {
	local RAW_CMD_TO_RUN=$1
	if ! [[ -d "$DOTFILES_DIR" ]]; then
		return 1
	fi
	(
		cd "$DOTFILES_DIR" || exit
		activate || exit
		$SHELL -c "$RAW_CMD_TO_RUN"
	)
}

run_raw_python_in_dotfiles_venv() {
	local RAW_CODE_TO_RUN=$1
	if ! [[ -d "$DOTFILES_DIR" ]]; then
		return 1
	fi
	(
		cd "$DOTFILES_DIR" || exit
		activate || exit
		python3 -c "$RAW_CODE_TO_RUN"
	)
}

ensure_pkg_in_dotfiles_venv() {
	pkg_name="$1"
	if ! (run_raw_cmd_in_dotfiles_venv "pip show $pkg_name" > /dev/null); then
		echo "$pkg_name is not installed. Would you like to install it in the dotfiles venv? [Yy]es / [Nn]o"
		read -r answer
		case $answer in
			[Yy]*)
				run_raw_cmd_in_dotfiles_venv "pip install $pkg_name"
				return 0
				;;
			*)
				return 1
				;;
		esac
	fi

	return 0
}


# In a sub-shell, run a command in different directory, and then switch back
exec_in() {
	if ! [[ -d $1 ]]; then
		echo "Invalid directory ($1)"
		return 1
	fi
	if [[ $# -le 1 ]]; then
		echo "Not enough arguments"
		return 1
	fi
	if ! (
		pushd "$1" > /dev/null || exit
		shift
		$SHELL -c "$*"
		popd > /dev/null || exit
	); then
		return 1
	fi
}

# Find the true global package dir / bin for a brew installed package
# e.g. `brew_find_global_pkd_dir fzf` -> `/usr/local/Cellar/fzf/0.45.0`
brew_find_global_pkd_dir() {
	PACKAGE_NAME=$1
	readlink -f "$(brew --prefix "$PACKAGE_NAME")"
}

npm_find_npx_global_pkg_dir() {
	PACKAGE_NAME=$1
	find "$HOME/.npm/_npx" -type d -name "$PACKAGE_NAME"
}

# NOTE: This is for packages installed with `-g`, not those installed via npx
# For npx, use `npm_find_npx_global_pkg_dir`, for which each package gets an isolated
# subdir, not a shared node_modules
npm_find_global_node_modules() {
	asdf_exec_with_global_version npm root -g
}

npm_find_global_pkg_dir() {
	PACKAGE_NAME=$1
	GLOBAL_NODE_MODULES=$(npm_find_global_node_modules)
	# Make sure to scan for symlinks as well, to handle `npm link` and friends
	found_dir=$(find -L "$GLOBAL_NODE_MODULES" -type d -depth 1 -name "$PACKAGE_NAME")
	if [[ -z "$found_dir" ]]; then
		echo "ERROR: Could not find $PACKAGE_NAME in global node_modules"
		return 1
	fi
	echo "$found_dir" | head -n 1
}

# Generate an ESM import statement, out of your global node_modules
# Pretty hacky: not many good reasons to use this, other than for fiddling around
# @see run_...in_global_node fns for a slightly better approach (but still hacky / just for fiddling)
scaffold_global_node_import() {
	PACKAGE_NAME=$1
	PACKAGE_DIR=$(npm_find_global_pkg_dir "$PACKAGE_NAME")
	copy_to_clipboard <<- EOF
	import {} from '$PACKAGE_DIR'
	EOF
}

run_file_in_global_node() {
	GLOBAL_NODE_MODULES=$(npm_find_global_node_modules)
	# TODO clean this up with piping?
	FILE_TO_EXEC="$1"
	FILENAME=$(basename "$FILE_TO_EXEC")
	# no-clobber
	cp -n "$FILE_TO_EXEC" "$GLOBAL_NODE_MODULES/"
	# WARNING: This might seem super hacky - why not just use `NODE_PATH=$GLOBAL_NODE_MODULES`?
	# Well, that *would* work, except for that they decided to ignore `NODE_PATH` when
	# moving to ESM `import` 🙃
	# https://nodejs.org/api/esm.html#esm_no_node_path
	(
		cd "$GLOBAL_NODE_MODULES" || exit
		node "$FILENAME"
	)
	rm "$GLOBAL_NODE_MODULES/$FILENAME"
}

run_raw_js_in_global_node() {
	RAW_CODE_TO_RUN=$1
	GLOBAL_NODE_MODULES=$(npm_find_global_node_modules)
	(
		cd "$GLOBAL_NODE_MODULES" || exit
		node --eval "$RAW_CODE_TO_RUN"
	)
}

repl_in_global_node() {
	GLOBAL_NODE_MODULES=$(npm_find_global_node_modules)
	pushd "$GLOBAL_NODE_MODULES" || exit
	node --experimental-repl-await
	popd || exit
}

# Execute a command with the global version of an asdf plugin, regardless of which dir
# you are in.
# @example `asdf_exec_with_global_version node --version`
asdf_exec_with_global_version() {
	# This is kind of hacky, but it works and asdf doesn't provide a "get global version" API
	# https://github.com/asdf-vm/asdf/issues/1340
	(cd /; asdf exec "$@")
	# Note: Above should pass through exit code, so no need to check and re-throw
}

# E.g. `asdf_get_true_path golang``
asdf_get_true_path() {
	asdf where "$1"
}

lint_versions() {
	if ! [[ -f ".tool-versions" ]]; then
		return 1
	fi
	#TODO
}

local_web_server_dir() {
	local serve_dir="$PWD"
	if [[ -d $1 ]]; then
		serve_dir=$1
		shift
	fi
	if [[ "$serve_dir" == "." ]]; then
		echo "Do not use '.' as serving directory; it will serve full drive"
		return 1
	fi
	asdf_exec_with_global_version npx local-web-server --directory "$serve_dir" "$@"
}

# Note to self: you can use `--package` to avoid ambiguity around package name vs bin / entrypoint
npx_exec_global() {
	asdf_exec_with_global_version npx --no-install "$@"
}

npm_ls_global() {
	asdf_exec_with_global_version npm ls -g --depth=0 "$1"
}

find_proc_by_port() {
	PORT=$1
	lsof -i :"$PORT"
}

find_proc_by_name() {
	local PROC_NAME=$1
	ps aux | grep "$PROC_NAME"
}

find_pid_by_port() {
	PORT=$1
	lsof -t -i :"$PORT"
}

get_proc_info_by_pid() {
	PID=$1
	ps -p "$PID" -o pid,ppid,pgid,command
}

get_proc_info_by_port() {
	PORT=$1
	PID=$(find_pid_by_port "$PORT")

	if [[ -z "$PID" ]]; then
		echo "No process found on port $PORT"
		return 1
	fi

	get_proc_info_by_pid "$PID"
}

kill_procs_by_pid_interactive() {
	local SELECTED_SIG=$(fzf --reverse <<< "$SIGNALS_PICK_LIST" | awk '{print $1}')
	if [[ -z "$SELECTED_SIG" ]] || [[ "$SELECTED_SIG" == "---" ]]; then
		return 1
	fi
	for PID in "$@"; do
		kill -"$SELECTED_SIG" "$PID"
	done
}

kill_procs_locking_file() {
	local file_path=$1
	if [[ -z "$file_path" ]]; then
		echo "No file_path specified"
		return 1
	fi
	local fuser_output=$(fuser "$file_path")
	# /file/path/string 1234
	# or, if no PID is locking
	# /file/path/string
	# TODO
}

# This is a workaround to tell the task runner that a given task is up-to-date,
# without actually running the task to generate the new fingerprint / checksum.
# Ideally, there would be a way to do this directly via the task cli (e.g. `task --mark-up-to-date`)
# See `scripts/task_mark_up_to_date.mjs` for full details`
task_mark_up_to_date() {
	local TASKFILE_PATH
	TASKFILE_PATH="${TASKFILE_PATH:="$PWD/Taskfile.yml"}"
	local TASK_NAME=$1
	if [[ ! -f "$TASKFILE_PATH" ]]; then
		echo "ERROR: Could not find $TASKFILE_PATH"
		return 1
	fi
	if [[ -z "$TASK_NAME" ]]; then
		echo "ERROR: Please define TASK_NAME"
		return 1
	fi
	TASK_NAME=$TASK_NAME TASKFILE_PATH=$TASKFILE_PATH run_file_in_global_node "$HOME/scripts/task_mark_up_to_date.mjs"
}

# This might seem like a lot of code just to wrap ffmpeg's `scale`, but this:
# - Handles rounding auto-heights to be divisible by 2 (which ffmpeg does not)
# - Picks a `_resized` output filename based on the input
# - Prompts for target width if not provided, from selection
ffmpeg_resize() {
	INPUT_FILE=$1
	TARGET_WIDTH=$2
	INPUT_DIR=$(dirname "$INPUT_FILE")
	INPUT_FILE_EXT=$(basename "$INPUT_FILE" | sed -E 's/^.+(\.[^.]+)$/\1/')
	INPUT_FILE_NO_EXT=$(basename "$INPUT_FILE" | sed -E 's/\.[^.]+$//')
	: "${OUTPUT_FILE:="$INPUT_FILE_NO_EXT"_resized"$INPUT_FILE_EXT"}"

	# If target width, not provided, use choices
	if [[ -z "$TARGET_WIDTH" ]]; then
		printf "What should the target width be?\n\t[Aa])1920\n\t[Bb])1280\n\t[Cc])720\n\t[Dd])480\n"
		read -r answer
		case $answer in
			A|a) TARGET_WIDTH=1920 ;;
			B|b) TARGET_WIDTH=1280 ;;
			C|c) TARGET_WIDTH=720 ;;
			D|d) TARGET_WIDTH=480 ;;
			*) echo "Invalid selection" && return 1 ;;
		esac
	fi

	# Get width and height of input file
	INPUT_DIMENSIONS=$(ffprobe -v error -select_streams v -show_entries stream=width,height -of csv=p=0:s=x "$INPUT_FILE")
	print "INPUT_DIMENSIONS = $INPUT_DIMENSIONS"
	if ! TARGET_HEIGHT=$(INPUT_DIMENSIONS=$INPUT_DIMENSIONS TARGET_WIDTH=$TARGET_WIDTH node <<- "EOF"
	const regPatt = /(?<width>\d+)x(?<height>\d+)/i;
	const INPUT_DIMENSIONS = /** @type {`${string}x${string}`} */ (process.env.INPUT_DIMENSIONS);
	const TARGET_WIDTH = parseInt(process.env.TARGET_WIDTH);

	if (!regPatt.test(INPUT_DIMENSIONS)) {
		throw new Error(`Invalid input dimensions (${INPUT_DIMENSIONS})`);
	}

	if (Number.isNaN(TARGET_WIDTH)) {
		throw new Error(`Invalid target width (${TARGET_WIDTH})`);
	}

	const {
		groups: { width: _width, height: _height },
	} = regPatt.exec(INPUT_DIMENSIONS);
	const width = parseInt(_width);
	const height = parseInt(_height);

	let targetHeight = (TARGET_WIDTH * height) / width;

	// Handle rounding auto-heights to be divisible by 2
	if (targetHeight % 2 !== 0) {
		const roundedTargetHeight = Math.round(targetHeight / 2) * 2;
		console.warn(`Rounding auto-height to be divisible by 2: ${targetHeight} -> ${roundedTargetHeight}`);
		targetHeight = roundedTargetHeight;
	}

	console.log(targetHeight);
	EOF
	); then
		echo "ERROR: Could not parse input dimensions"
		return 1
	fi


	echo "Resizing $INPUT_FILE to $TARGET_WIDTH pixels wide (out = $INPUT_DIR/$OUTPUT_FILE)"
	ffmpeg -loglevel warning -stats -i "$INPUT_FILE" -vf scale="$TARGET_WIDTH:$TARGET_HEIGHT" "$INPUT_DIR/$OUTPUT_FILE"
	echo "Rendered to $INPUT_DIR/$OUTPUT_FILE"
	echo "✅ Done"
}

px_from_rem() {
	REM=$1
	echo "$((16 * REM))"
}

rem_from_px() {
	PX=$1
	echo "$((PX / 16))"
}

curl_post_json_file() {
	URL=$1
	JSON_FILE_PATH=$2
	if ! [[ -f $JSON_FILE_PATH ]]; then
		echo "ERROR: Could not find JSON file at $JSON_FILE_PATH"
		return 1
	fi
	shift 2
	curl -X POST -H "Content-Type: application/json" -d @"$JSON_FILE_PATH" "$@" "$URL"
}

aws_list_profiles() {
	aws configure list-profiles
}

# Connect to an AWS EC2 Instance, via instance-connect
# Remember: You can use`AWS_PROFILE=${name}` to set the AWS credential profile
# to use for all the AWS commands
aws_ec2_instance_connect_send_pub_key() {
	local EC2_USERNAME="ec2-user"
	while [[ ! $# -eq 0 ]]
	do
		case "$1" in
			-i|--instance-id)
				INSTANCE_ID=$2
				shift
				;;
			-u|--user|--username)
				EC2_USERNAME=$2
				shift
				;;
			-pub|--public-key)
				PUBLIC_KEY=$2
				shift
				;;
			*)
				echo "Invalid option ${1}"
				;;
		esac
		shift
	done

	if ! (which aws > /dev/null); then
		echo "ERROR: AWS CLI not found"
		return 1
	fi

	# Check format
	if ! [[ $INSTANCE_ID =~ ^i-[a-z0-9]+$ ]]; then
		echo "Invalid instance ID format. Should be I-123abc455"
		return 1
	fi

	if ! [[ -f $PUBLIC_KEY ]]; then
		echo "ERROR: Could not find public and/or private key"
		return 1
	fi

	# Send public key
	aws ec2-instance-connect \
		send-ssh-public-key \
			--no-paginate \
			--instance-id "$INSTANCE_ID" \
			--instance-os-user "$EC2_USERNAME" \
			--ssh-public-key "file://${PUBLIC_KEY}" | cat > /dev/null

	if [[ $? -ne 0 ]]; then
		echo "ERROR: Could not send public key"
		return 1
	fi
}

aws_ec2_instance_get_public_dns_addr() {
	aws ec2 describe-instances --instance-ids "$1" --query 'Reservations[*].Instances[*].[PublicDnsName]' --output text
}

aws_ec2_instance_connect_ssh() {
	local HELP=$(cat <<- "EOF"
	TODO
	EOF
	)
	local EC2_USERNAME="ec2-user"
	local USE_TEMP_KEY_PAIR=0
	local USE_DEFAULT_KEY_PAIR=0
	local PORT_BINDINGS=()
	local PRIVATE_KEY=""
	local PUBLIC_KEY=""
	while [[ ! $# -eq 0 ]]
	do
		case "$1" in
			-i|--instance-id)
				INSTANCE_ID=$2
				shift
				;;
			-u|--user|--username)
				EC2_USERNAME=$2
				shift
				;;
			-p|--port)
				PORT_BINDINGS+=("$2")
				shift
				;;
			-pk|--private-key)
				PRIVATE_KEY=$2
				shift
				;;
			-pub|--public-key)
				PUBLIC_KEY=$2
				shift
				;;
			-dkp|--default-key-pair)
				USE_DEFAULT_KEY_PAIR=1
				shift
				;;
			-h|--help)
				echo "$HELP"
				return
				;;
			*)
				echo "Invalid option ${1}"
				;;
		esac
		shift
	done

	local tmp_dir
	if ! [[ -f $PUBLIC_KEY ]] || ! [[ -f $PRIVATE_KEY ]]; then
		if [[ $USE_DEFAULT_KEY_PAIR -eq 1 ]]; then
			PRIVATE_KEY="$HOME/.ssh/id_rsa"
			PUBLIC_KEY="$HOME/.ssh/id_rsa.pub"
		else
			echo "🔐 Generating temporary key pair"
			USE_TEMP_KEY_PAIR=1
			tmp_dir=$(mktemp -d)
			ssh-keygen -t rsa -b 4096 -C "TEMPORARY key for EC2 Instance Connect" -N "" -f "$tmp_dir/tmp_key"
			PRIVATE_KEY="$tmp_dir/tmp_key"
			PUBLIC_KEY="$tmp_dir/tmp_key.pub"
		fi
	fi

	if ! [[ -f $PUBLIC_KEY ]] || ! [[ -f $PRIVATE_KEY ]]; then
		echo "Couldn't find public key and/or private key"
		return 1
	fi

	# Push public key before establishing SSH
	if ! (aws_ec2_instance_connect_send_pub_key --instance-id "$INSTANCE_ID" --username "$EC2_USERNAME" --public-key "$PUBLIC_KEY"); then
		return 1
	fi

	local SSH_ARGS=(-o ServerAliveInterval=20 -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -i "$PRIVATE_KEY")
	if [[ ${#PORT_BINDINGS[@]} -gt 0 ]]; then
		for PORT_BINDING in "${PORT_BINDINGS[@]}"; do
			SSH_ARGS+=(-L "\*:$PORT_BINDING:localhost:$PORT_BINDING")
		done
	fi

	# Establish SSH connection
	local DNS_ADDR=$(aws_ec2_instance_get_public_dns_addr "$INSTANCE_ID")
	SSH_ARGS+=("${EC2_USERNAME}@${DNS_ADDR}")
	declare -p SSH_ARGS
	ssh "${SSH_ARGS[@]}"

	# Cleanup
	if [[ $USE_TEMP_KEY_PAIR -eq 1 ]] && [[ -d "$tmp_dir" ]]; then
		echo "🗑️ Deleting temporary key pair"
		rm -r "$tmp_dir"
	fi
}

tensorjs_keras_converter() {
	local raw_model_path=$1
	if ! [[ -f "$raw_model_path" ]]; then
		echo "Could not find model at $raw_model_path"
		return 1
	fi
	local raw_model_name=$(basename $raw_model_path)
	out_dir_name=tfjs_generated
	out_dir="./${out_dir_name}"
	mkdir "$out_dir" || true
	local converter_args=(
		"tensorflowjs_converter"
		"--input_format=keras"
		"/tmp/${raw_model_name}"
		"/tmp/${out_dir_name}"
	)
	docker run --rm -t \
		-v "${raw_model_path}:/tmp/${raw_model_name}" \
		-v "${out_dir}:/tmp/${out_dir_name}" \
		"jtz-reg/jtz/tensorflowjs" \
		"${converter_args[@]}"
}

large_llm_query() {
	export LC_ALL="C"
	unset IFS
	TEMP_DIR_PATH=$(mktemp -d)
	echo "Using temporary directory $TEMP_DIR_PATH"
	BANNED_FILE_PATTERNS=(
		".env"
		"scratch.py"
	)
	# In addition to text/* (e.g. text/plain, text/x-shellscript)
	EXTRA_ACCEPTED_MIME_TYPES=(
		"application/json"
		"application/ld+json"
	)
	TEMP_PROMPT_FILE="$TEMP_DIR_PATH/.prompt.txt"
	touch "$TEMP_PROMPT_FILE"
	DEBUG=0

	if [[ -z "$GOOGLE_GEMINI_API_KEY" ]]; then
		GOOGLE_GEMINI_API_KEY=$(op item get 'Google_Gemini_API_Key' --vault Private --fields 'credential')
	fi
	if [[ -z "$GOOGLE_GEMINI_API_KEY" ]]; then
		echo "ERROR: Could not find Google_Gemini_API_Key"
		return 1
	fi

	# Hardcode for now
	MODEL="gemini"

	FILENAMES_PASSED_VIA_ARG=()
	RIPGREP_ARGS=()
	GLOB=""
	QUESTION=""
	LLM_PROMPT=""
	while [[ ! $# -eq 0 ]]; do
		case "$1" in
			-rg|--ripgrep-args)
				# Turn string into args arr
				declare -a RIPGREP_ARGS=($(echo $2 | awk '{for(i=1;i<=NF;i++) print $i}'))
				declare -p RIPGREP_ARGS
				shift
				;;
			-g|--glob)
				GLOB=$2
				shift
				;;
			-q|--question)
				QUESTION=$2
				shift
				;;
			-p|--prompt)
				LLM_PROMPT=$2
				shift
				;;
			-m|--model)
				MODEL=$2
				shift
				;;
			-d|--debug)
				DEBUG=1
				;;
			*)
				if [[ -f "$1" ]]; then
					FILENAMES_PASSED_VIA_ARG+=("$1")
				else
					echo "Invalid option ${1}"
				fi
				;;
		esac
		shift
	done

	if [[ $MODEL != "gemini" ]]; then
		echo "Not yet implemented support for $MODEL"
		return 1
	fi

	if [[ ${#FILENAMES_PASSED_VIA_ARG[@]} -eq 0  ]] && [[ -z "$GLOB" ]] && [[ ${#RIPGREP_ARGS[@]} -eq 0 ]]; then
		echo "What different search terms should be used to search?"
		echo "Press enter to add another, type EOF to end query"
		AT_LEAST_ONE_SEARCH_DONE=0
		RIPGREP_ARGS+=("-l" "-i")
		while true; do
			read -r SEARCH_TERM
			if [[ -z "$SEARCH_TERM" ]] || [[ "$SEARCH_TERM" == "EOF" ]]; then
				break
			fi
			AT_LEAST_ONE_SEARCH_DONE=1
			RIPGREP_ARGS+=("-e" "$SEARCH_TERM")
		done
		if [[ $AT_LEAST_ONE_SEARCH_DONE -eq 0 ]]; then
			echo "ERROR: Must provide at least one search term"
			return 1
		fi
	fi

	if [[ ${#FILENAMES_PASSED_VIA_ARG[@]} -eq 0  ]] && [[ -z "$GLOB" ]] && [[ ${#RIPGREP_ARGS[@]} -eq 0 ]]; then
		echo "ERROR: Must provide ripgrep arguments (-rg / --ripgrep-args), glob (-g / --glob), or filenames."
		return 1
	fi

	# If neither `--prompt` nor `--question` was not passed, ask user / read from stdin
	if [[ -z "$LLM_PROMPT" ]] && [[ -z "$QUESTION" ]]; then
		echo "Enter question:"
		read -r QUESTION
		if [[ -z "$QUESTION" ]]; then
			echo "ERROR: Must provide a question (or prompt, with --prompt)"
			return 1
		fi
	fi

	# Make sure `--file` is included in args
	# If not, PREpend it as first arg
	# if [[ ! " ${RIPGREP_ARGS[*]} " =~ " --files " ]]; then
	# 	RIPGREP_ARGS=("--files" "${RIPGREP_ARGS[@]}")
	# fi

	# Prepare base prompt / prefix
	if [[ -z "$LLM_PROMPT" ]]; then
		cat > "$TEMP_PROMPT_FILE" <<- EOF
		You are an expert programmer, and someone has asked you to answer the following

		Question: $QUESTION

		You need to answer - preferably ONLY with references to the below reference material. Try to be as accurate as possible; cite files used to form your answer, and even line numbers if possible.

		Each file below is separated like so:

		---
		File: FILE_NAME
		FILE_CONTENTS
		---

		Here is the reference material / files:

		---
		EOF
	else
		echo "$LLM_PROMPT" > "$TEMP_PROMPT_FILE"
	fi

	dump_file_to_prompt() {
		FILE_PATH=$1
		if ! [[ -f $FILE_PATH ]]; then
			return 0
		fi
		# Check for binary / non-plain-text (against `ACCEPTED_FILE_MATCHES`)
		FILE_MIME_TYPE=$(file -b --mime-type $FILE_PATH)
		if [[ " ${BANNED_FILE_PATTERNS[*]} " =~ " ${FILE_PATH} " ]]; then
			echo "WARNING: Skipping $FILE_PATH; banned file pattern found"
			return 0
		fi
		if ! [[ $FILE_MIME_TYPE == "text/"*  ]] && ! [[ " ${EXTRA_ACCEPTED_MIME_TYPES[*]} " =~ " ${FILE_MIME_TYPE} " ]]; then
			echo "WARNING: Skipping $FILE_PATH; non-parseable mime-type found ($FILE_MIME_TYPE)"
			return 0
		fi
		echo "Dumping file to prompt: $FILE_PATH"
		FILE_CONTENTS_WITH_LINE_NUMBERS=$(cat -n "$FILE_PATH")
		# Remove leading indent
		# shellcheck disable=SC2001
		FILE_CONTENTS_WITH_LINE_NUMBERS=$(echo "$FILE_CONTENTS_WITH_LINE_NUMBERS" | sed 's/^[[:space:]]*//')
		cat >> "$TEMP_PROMPT_FILE" <<- EOF
		File: $FILE_PATH
		$FILE_CONTENTS_WITH_LINE_NUMBERS
		---
		EOF
	}

	# Iterate  over files
	for FILE_PATH in "${FILENAMES_PASSED_VIA_ARG[@]}"; do
		dump_file_to_prompt "$FILE_PATH"
	done
	if [[ -n $GLOB ]]; then
		if [[ $SHELL_TYPE != "ZSH" ]]; then
			echo "TODO verify glob behavior in other shells"
			return 1
		fi

		# Note: `~` for glob expansion is a zsh-ism
		# shellcheck disable=SC2296
		# shellcheck disable=SC2206
		FILE_LIST=(${~GLOB})

		for FILE_PATH in "${FILE_LIST[@]}"; do
			dump_file_to_prompt "$FILE_PATH"
		done
	else
		declare -p RIPGREP_ARGS
		for FILE_PATH in $(rg "${RIPGREP_ARGS[@]}"); do
			# TODO support partial file extraction, so to save on some tokens
			# e.g., include X number of lines around search term(s)
			dump_file_to_prompt "$FILE_PATH"
		done
	fi

	cat <<- EOF
	Prompt Stats:
		Line Count = $(wc -l < "$TEMP_PROMPT_FILE")
		Word Count = $(wc -w < "$TEMP_PROMPT_FILE")
	EOF

	# Warning: Technically, this could be done in pure bash, but there are a lot of oddities around
	# escaping, line breaks, and space expansion across shells, that makes this really error-prone
	# Leaving this partial attempt commented out for now
	# ESCAPED_PROMPT_STRING=$(cat $TEMP_PROMPT_FILE | jq -Rsa .)
	## Keep line breaks as literal line breaks / escaped
	# ESCAPED_PROMPT_STRING_FINAL=$(LC_ALL=en_US.UTF-8 echo "$ESCAPED_PROMPT_STRING" | sed 's/$/\\\\n/' | tr -d '\n')

	# Also worth noting that we are actually double-escaping here, due to the nature
	# of the heredoc and having to escape the shell first

	POST_BODY=$(TEMP_PROMPT_FILE=$TEMP_PROMPT_FILE node <<- EOF
	let TEMP_PROMPT_FILE_CONTENTS = require('fs').readFileSync(process.env.TEMP_PROMPT_FILE, 'utf8');
	// Remove any CR (e.g., from a CRLF file dumped to prompt)
	TEMP_PROMPT_FILE_CONTENTS = TEMP_PROMPT_FILE_CONTENTS.replace(/\r/g, '');
	// Double escape tabs
	TEMP_PROMPT_FILE_CONTENTS = TEMP_PROMPT_FILE_CONTENTS.replace(/\t/g, '\\\\t');
	// Double backslashes
	TEMP_PROMPT_FILE_CONTENTS = TEMP_PROMPT_FILE_CONTENTS.replace(/\\\\/g, '\\\\\\\\');
	// Double escape newlines to avoid shell expansion
	TEMP_PROMPT_FILE_CONTENTS = TEMP_PROMPT_FILE_CONTENTS.replace(/\n/g, '\\\\n');
	console.log(JSON.stringify({
		contents: [{
			parts: [{
				text: TEMP_PROMPT_FILE_CONTENTS
			}]
		}]
	}));
	EOF
	)

	echo "$POST_BODY" > "$TEMP_DIR_PATH/.prompt_req.json"

	while true; do
		printf "Are you sure you want to send off the prompt? [Yy]es / ENTER, [Cc]ancel / [Nn]o\n"
		read -r answer
		case $answer in
			[Yy]*) break ;;
			"") break ;;
			[Cc]*) return 0 ;;
			[Nn]*) return 0 ;;
		esac
	done

	# Actually make request
	# Make sure to use `-d @file` to avoid "argument list too long"
	response=$(curl "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?key=$GOOGLE_GEMINI_API_KEY" \
		-H 'Content-Type: application/json' \
		-X POST \
		-d @"$TEMP_DIR_PATH/.prompt_req.json"
	)
	echo "$response" > "$TEMP_DIR_PATH/.prompt_res.json"

	# Combine all `candidates.contents.parts[].text`
	# Double-escape line breaks again
	response=$response node <<- EOF
	let combined = '';
	const response = JSON.parse(process.env.response);
	response.candidates.forEach(can => {
		if (can.finishReason !== 'STOP') {
			console.warn('Unusual finish reason:', can.finishReason);
			return;
		}
		can.content.parts.forEach(p => {
			combined += p.text;
		})
	});
	if (combined) {
		console.log('===== Server Response =====');
		console.log(combined);
		console.log('=============================')
	}
	EOF

	# If response errored out and/or parsing failed dump response
	if [[ $? -ne 0 ]]; then
		echo "Error parsing response"
		echo "$response"
		return 1
	fi

	echo "Done!"
	if [[ $DEBUG -eq 1 ]]; then
		echo "You can inspect the full prompt and response in $TEMP_DIR_PATH"
	else
		rm -r "$TEMP_DIR_PATH"
		echo "Deleted temporary prompt files"
	fi
}

llm_toolkit() {
	local start_dir=$PWD
	local repo_dir=/Users/joshua/jtzdev/llm-toolkit
	(
		cd "$repo_dir" || exit
		activate
		cd "$start_dir" || exit
		python3 $repo_dir/backend/cli.py "$@"
	)
}

llm_toolkit_question_from_plaintext() {
	local plaintext_file=$1
	llm_toolkit question "$(cat "$plaintext_file")"
}

get_cert_fingerprint() {
	local CERT_FILE=$1
	if ! [[ -f "$CERT_FILE" ]]; then
		echo "Could not find $CERT_FILE"
		return 1
	fi
	openssl x509 -pubkey -noout -in "$CERT_FILE" | openssl pkey -pubin -outform der | openssl dgst -sha256 -binary | openssl enc -base64
}

# Open a browser, pre-configured to temporarily trust a local SSL cert file
trust_cert_fingerprint() {
	local CERT_FILE=$1
	local CERT_FINGERPRINT=$(get_cert_fingerprint "$CERT_FILE")

	if (check_args_for_value "--chrome" "$*"); then
		chrome --ignore-certificate-errors-spki-list="$CERT_FINGERPRINT" --user-data-dir=/tmp
		return 0
	fi

	echo "TODO: Add Firefox support. This might not even be possible - need to comb through https://wiki.mozilla.org/Firefox/CommandLineOptions"
	return 1
}

compose_ssl_cert_query() {
	local CERT_FILE_OR_DOMAIN_URL=$1
	local CERT_FILE=$1
	shift
	if ! [[ -f "$CERT_FILE_OR_DOMAIN_URL" ]]; then
		local CERT_FILE=$(mktemp)
		# Remap 'https://example.com' -> 'example.com:443'
		openssl s_client -connect "$CERT_FILE_OR_DOMAIN_URL" </dev/null 2>/dev/null > "$CERT_FILE"
	fi
	openssl x509 -pubkey -in "$CERT_FILE" "$@"
}

SSH_PUBLIC_KEY_START_PATTERN="^ssh-[a-zA-Z]{2,}[a-zA-Z0-9-]*"

get_cert_type() {
	local cert_file_or_url="$1"
	if [[ $1 =~ ^https://.* ]]; then
		echo "URL"
		return
	elif [[ -f "$cert_file_or_url" ]]; then
		if (file "$cert_file_or_url" | grep --silent "SSH"); then
			if (grep --silent -E "^-----BEGIN OPENSSH PRIVATE KEY-----" "$cert_file_or_url"); then
				echo "SSH:PRIVATE"
				return
			elif (grep --silent -E "$SSH_PUBLIC_KEY_START_PATTERN" "$cert_file_or_url"); then
				echo "SSH:PUBLIC"
				return
			fi
			# Unknown format
			return 1
		elif (file "$cert_file_or_url" | grep --silent "PEM"); then
			echo "SSL:PUBLIC"
			return
		# This makes some assumptions
		elif (file "$cert_file_or_url" | grep --silent "ASCII text") && (grep --silent -E "^-----BEGIN PRIVATE KEY-----" "$cert_file_or_url"); then
			echo "SSL:PRIVATE"
			return
		fi
	fi

	# Unknown format
	return 1
}

get_cert_info() {
	local cert_file_or_url="$1"
	echo "🧠 Determining type of $cert_file_or_url ..."
	local cert_type=$(get_cert_type "$cert_file_or_url")


	if ! [[ $? -eq 0 ]]; then
		echo "Could not determine the type of certificate. Is $cert_file_or_url a valid input"
	fi

	echo "ℹ️ Type mapped as $cert_type"
	echo "🔨 Extracting information for $cert_type"

	# SSL
	if [[ $cert_type == "SSL:PUBLIC" ]] || [[ $cert_type == "SSL:PRIVATE" ]]; then
		echo "🔨 Extracting SSL cert info"
		compose_ssl_cert_query "$cert_file_or_url" -text -pubkey
		return
	fi

	# SSH
	if [[ $cert_type == "SSH:PUBLIC" ]] || [[ $cert_type == "SSH:PRIVATE" ]]; then
		ssh-keygen -lf "$cert_file_or_url"
		return
	fi

	# Unknown type / unmapped type
	echo "Could not determine how to extract info from $cert_type, $cert_file_or_url"
	return 1
}

is_cert_not_expired() {
	compose_ssl_cert_query "$1" -noout -checkend 0
}

get_registered_custom_uri_hyperlink_schemes() {
	if [[ $IS_MAC -ne 1 ]]; then
		# TODO: Linux support
		return 1
	fi

	# https://apple.stackexchange.com/a/397188/428959
	/System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/LaunchServices.framework/Versions/A/Support/lsregister  -dump URLSchemeBinding
}

get_local_ip() {
	for interface in en0 en1
	do
		local local_ip_addr=$(ipconfig getifaddr "$interface")
		if [[ $? -eq 0 ]]; then
			echo "$local_ip_addr"
			return 0
		fi
	done
	return 1
}

# This is currently pretty macoS specific
# Also, runs code that triggers OS permission checks, so will fail if denied
whats_up() {
	WINDOW_TITLE=$(cat << "EOF" | xargs -0 osascript -e
global frontApp, frontAppName, windowTitle

set windowTitle to ""
tell application "System Events"
	set frontApp to first application process whose frontmost is true
	set frontAppName to name of frontApp
	tell process frontAppName
		tell (1st window whose value of attribute "AXMain" is true)
			set windowTitle to value of attribute "AXTitle"
		end tell
	end tell
end tell

return {frontAppName, windowTitle}
EOF
)
	STATUS_STRING=$(cat << EOF
Active Window = $WINDOW_TITLE
EOF
)

	if (npx --package jtz-time-tracker-utils jttu --version > /dev/null); then
		STATUS_STRING=$(cat << EOF
$STATUS_STRING
==== Time Tracker ====
$(npx --package jtz-time-tracker-utils jttu harvest status)
======================
EOF
)
	fi
	echo "$STATUS_STRING"
}
